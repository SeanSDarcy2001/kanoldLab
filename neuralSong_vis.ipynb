{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralSong_vis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBdR11xC9OlGxSNOIlA2qF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanSDarcy2001/kanoldLab/blob/main/neuralSong_vis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kQKFDnal0gix"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tifffile import imread\n",
        "from os import listdir\n",
        "from pymatreader import read_mat\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from pathlib import Path\n",
        "\n",
        "#paths\n",
        "tiffs = Path(\"tiffs\")\n",
        "sound = Path(\"sound_file_2022-07-12_16-39-18_cs_17_T5_s2\")\n",
        "stimHist = Path(\"stimHistory_17t5.mat\")\n",
        "specs = Path(\"specs\")\n",
        "\n",
        "def sequence(start, end):\n",
        "    res = []\n",
        "    diff = 1\n",
        "    x = start\n",
        "    while x <= end:\n",
        "        res.append(x)\n",
        "        x += diff\n",
        "    return res\n",
        "\n",
        "class NeuralDataset(Dataset) :\n",
        "#tiff_path is path to .tiff files containing widefield images\n",
        "#spec_path is path to spectrograms\n",
        "#timeStamps is .mat file that is stims x nReps, containing frame info\n",
        "  def __init__(self, tiff_path, spec_path, timeStamps, transforms = None):\n",
        "    self.tiffs = listdir(tiff_path)\n",
        "    self.specs = listdir(spec_path)\n",
        "    self.timeStamps = read_mat(timeStamps)\n",
        "    self.transform = transforms\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.specs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #load 30 image stack, tiffs in 9798 n stacks\n",
        "    reps = []\n",
        "    for i in range(2) :\n",
        "        start = self.timeStamps[idx, i]\n",
        "        end = self.timeStamps[idx, i] + 30\n",
        "\n",
        "        #basically figures out what stack the start and end frames are in\n",
        "        if start > 9798 or end > 9798 :\n",
        "            tempStart = start\n",
        "            counterS = 0\n",
        "            tempEnd = end\n",
        "            counterE = 0\n",
        "            while tempStart > 9798 :\n",
        "                counterS += 1\n",
        "                tempStart -= 9798\n",
        "            while tempEnd > 9798 :\n",
        "                counterE += 1\n",
        "                tempEnd -= 9798\n",
        "\n",
        "        #if start and end of sequence are in same stack\n",
        "        if counterE == counterS :\n",
        "            seq = sequence(tempStart, tempEnd)\n",
        "            neurons = imread(self.tiffs[counterS], key = seq)\n",
        "            neurons = ToTensor()(neurons)\n",
        "            reps.append(neurons)\n",
        "        #if they are in different stacks\n",
        "        #to test\n",
        "        else :\n",
        "            seq = sequence(tempStart, 9798)\n",
        "            neurons_stack1 = imread(self.tiffs[counterS], key = seq)\n",
        "            seq = sequence(1, tempEnd)\n",
        "            neurons_stack2 = imread(self.tiffs[counterE], key = seq)\n",
        "            neurons = ToTensor()(neurons_stack1 + neurons_stack2)\n",
        "            reps.append(neurons)\n",
        "        \n",
        "    spec = torchvision.io.read_image(self.specs[idx])\n",
        "    neurons = torch.stack(reps[0], reps[1], 0)\n",
        "    return neurons, spec\n",
        "\n",
        "\n",
        "dataset = NeuralDataset(tiffs, specs, stimHist)"
      ]
    }
  ]
}