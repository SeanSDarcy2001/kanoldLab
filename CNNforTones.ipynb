{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNforTones.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4JhvfnyqWqNULMcMTKpqe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanSDarcy2001/kanoldLab/blob/main/CNNforTones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mat73\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "tg609yOENcx_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralDataset(Dataset) :\n",
        "  def __init__(self, frames, tones, transforms = None):\n",
        "    self.img_labels = tones\n",
        "    self.frames = frames\n",
        "    self.transform = transforms\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.img_labels[0, :])\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    frame = torch.unsqueeze(self.frames[:, :, idx], 0)\n",
        "    labels = self.img_labels[:, idx]\n",
        "    return frame, labels"
      ],
      "metadata": {
        "id": "ubm-5Wc0NgjI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zyViAHFL68Ck",
        "outputId": "9e03d3b4-7b0a-4380-9f51-f99479a02e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Input shape: (330, 330)\n",
            "Training dataset size: 744 Testing dataset size: 216\n",
            "Epoch: 0\n",
            "Frame 0 of 744\n",
            "Loss: 2.8940823078155518\n",
            "Frame 1 of 744\n",
            "Loss: 4895.86279296875\n",
            "Frame 2 of 744\n",
            "Loss: 36779.140625\n",
            "Frame 3 of 744\n",
            "Loss: 11437.57421875\n",
            "Frame 4 of 744\n",
            "Loss: 511.4212951660156\n",
            "Frame 5 of 744\n",
            "Loss: 1249.1456298828125\n",
            "Frame 6 of 744\n",
            "Loss: 553.764892578125\n",
            "Frame 7 of 744\n",
            "Loss: 802.2243041992188\n",
            "Frame 8 of 744\n",
            "Loss: 679.436767578125\n",
            "Frame 9 of 744\n",
            "Loss: 732.7804565429688\n",
            "Frame 10 of 744\n",
            "Loss: 438.1293640136719\n",
            "Frame 11 of 744\n",
            "Loss: 514.3187866210938\n",
            "Frame 12 of 744\n",
            "Loss: 252.5225372314453\n",
            "Frame 13 of 744\n",
            "Loss: 238.5362548828125\n",
            "Frame 14 of 744\n",
            "Loss: 208.86070251464844\n",
            "Frame 15 of 744\n",
            "Loss: 224.4539794921875\n",
            "Frame 16 of 744\n",
            "Loss: 199.0028533935547\n",
            "Frame 17 of 744\n",
            "Loss: 156.97132873535156\n",
            "Frame 18 of 744\n",
            "Loss: 137.8588409423828\n",
            "Frame 19 of 744\n",
            "Loss: 272.9247741699219\n",
            "Frame 20 of 744\n",
            "Loss: 45.676025390625\n",
            "Frame 21 of 744\n",
            "Loss: 51.158138275146484\n",
            "Frame 22 of 744\n",
            "Loss: 33.406864166259766\n",
            "Frame 23 of 744\n",
            "Loss: 70.94257354736328\n",
            "Frame 24 of 744\n",
            "Loss: 65.10528564453125\n",
            "Frame 25 of 744\n",
            "Loss: 50.82297897338867\n",
            "Frame 26 of 744\n",
            "Loss: 53.97494888305664\n",
            "Frame 27 of 744\n",
            "Loss: 57.53632736206055\n",
            "Frame 28 of 744\n",
            "Loss: 56.14731979370117\n",
            "Frame 29 of 744\n",
            "Loss: 41.53563690185547\n",
            "Frame 30 of 744\n",
            "Loss: 30.980073928833008\n",
            "Frame 31 of 744\n",
            "Loss: 40.15998077392578\n",
            "Frame 32 of 744\n",
            "Loss: 12.386996269226074\n",
            "Frame 33 of 744\n",
            "Loss: 8.324516296386719\n",
            "Frame 34 of 744\n",
            "Loss: 2.7675228118896484\n",
            "Frame 35 of 744\n",
            "Loss: 9.533169746398926\n",
            "Frame 36 of 744\n",
            "Loss: 3.1019933223724365\n",
            "Frame 37 of 744\n",
            "Loss: 2.803187131881714\n",
            "Frame 38 of 744\n",
            "Loss: 2.7718944549560547\n",
            "Frame 39 of 744\n",
            "Loss: 2.724093198776245\n",
            "Frame 40 of 744\n",
            "Loss: 2.7692883014678955\n",
            "Frame 41 of 744\n",
            "Loss: 9.488924980163574\n",
            "Frame 42 of 744\n",
            "Loss: 2.7989370822906494\n",
            "Frame 43 of 744\n",
            "Loss: 2.780832529067993\n",
            "Frame 44 of 744\n",
            "Loss: 2.798658609390259\n",
            "Frame 45 of 744\n",
            "Loss: 2.779240608215332\n",
            "Frame 46 of 744\n",
            "Loss: 2.773883819580078\n",
            "Frame 47 of 744\n",
            "Loss: 2.7745416164398193\n",
            "Frame 48 of 744\n",
            "Loss: 2.8106203079223633\n",
            "Frame 49 of 744\n",
            "Loss: 2.794409990310669\n",
            "Frame 50 of 744\n",
            "Loss: 2.7574987411499023\n",
            "Frame 51 of 744\n",
            "Loss: 2.7709083557128906\n",
            "Frame 52 of 744\n",
            "Loss: 2.867699384689331\n",
            "Frame 53 of 744\n",
            "Loss: 1.552751898765564\n",
            "Frame 54 of 744\n",
            "Loss: 19.784692764282227\n",
            "Frame 55 of 744\n",
            "Loss: 10.599468231201172\n",
            "Frame 56 of 744\n",
            "Loss: 2.808251142501831\n",
            "Frame 57 of 744\n",
            "Loss: 2.778247117996216\n",
            "Frame 58 of 744\n",
            "Loss: 2.7652359008789062\n",
            "Frame 59 of 744\n",
            "Loss: 2.793985366821289\n",
            "Frame 60 of 744\n",
            "Loss: 2.771953821182251\n",
            "Frame 61 of 744\n",
            "Loss: 2.7466866970062256\n",
            "Frame 62 of 744\n",
            "Loss: 2.768230676651001\n",
            "Frame 63 of 744\n",
            "Loss: 2.8018672466278076\n",
            "Frame 64 of 744\n",
            "Loss: 2.7926857471466064\n",
            "Frame 65 of 744\n",
            "Loss: 2.812715530395508\n",
            "Frame 66 of 744\n",
            "Loss: 2.7774362564086914\n",
            "Frame 67 of 744\n",
            "Loss: 2.7953290939331055\n",
            "Frame 68 of 744\n",
            "Loss: 2.7576959133148193\n",
            "Frame 69 of 744\n",
            "Loss: 6.294069290161133\n",
            "Frame 70 of 744\n",
            "Loss: 3.2750070095062256\n",
            "Frame 71 of 744\n",
            "Loss: 2.770909309387207\n",
            "Frame 72 of 744\n",
            "Loss: 2.8060731887817383\n",
            "Frame 73 of 744\n",
            "Loss: 2.7827093601226807\n",
            "Frame 74 of 744\n",
            "Loss: 2.7826850414276123\n",
            "Frame 75 of 744\n",
            "Loss: 2.772202730178833\n",
            "Frame 76 of 744\n",
            "Loss: 2.7670087814331055\n",
            "Frame 77 of 744\n",
            "Loss: 2.8054616451263428\n",
            "Frame 78 of 744\n",
            "Loss: 2.7863051891326904\n",
            "Frame 79 of 744\n",
            "Loss: 2.8127877712249756\n",
            "Frame 80 of 744\n",
            "Loss: 2.7846462726593018\n",
            "Frame 81 of 744\n",
            "Loss: 2.7805862426757812\n",
            "Frame 82 of 744\n",
            "Loss: 2.803534746170044\n",
            "Frame 83 of 744\n",
            "Loss: 2.7490015029907227\n",
            "Frame 84 of 744\n",
            "Loss: 2.755894422531128\n",
            "Frame 85 of 744\n",
            "Loss: 2.7847421169281006\n",
            "Frame 86 of 744\n",
            "Loss: 2.7732760906219482\n",
            "Frame 87 of 744\n",
            "Loss: 2.7681379318237305\n",
            "Frame 88 of 744\n",
            "Loss: 2.7919623851776123\n",
            "Frame 89 of 744\n",
            "Loss: 2.755894899368286\n",
            "Frame 90 of 744\n",
            "Loss: 2.813552141189575\n",
            "Frame 91 of 744\n",
            "Loss: 2.793135404586792\n",
            "Frame 92 of 744\n",
            "Loss: 2.764317274093628\n",
            "Frame 93 of 744\n",
            "Loss: 2.802131414413452\n",
            "Frame 94 of 744\n",
            "Loss: 2.790308713912964\n",
            "Frame 95 of 744\n",
            "Loss: 2.770189046859741\n",
            "Frame 96 of 744\n",
            "Loss: 2.765446901321411\n",
            "Frame 97 of 744\n",
            "Loss: 2.8072426319122314\n",
            "Frame 98 of 744\n",
            "Loss: 2.7782163619995117\n",
            "Frame 99 of 744\n",
            "Loss: 2.790247917175293\n",
            "Frame 100 of 744\n",
            "Loss: 2.7702105045318604\n",
            "Frame 101 of 744\n",
            "Loss: 2.7509281635284424\n",
            "Frame 102 of 744\n",
            "Loss: 2.768710136413574\n",
            "Frame 103 of 744\n",
            "Loss: 2.771791458129883\n",
            "Frame 104 of 744\n",
            "Loss: 2.773404121398926\n",
            "Frame 105 of 744\n",
            "Loss: 2.7737350463867188\n",
            "Frame 106 of 744\n",
            "Loss: 2.7734534740448\n",
            "Frame 107 of 744\n",
            "Loss: 2.7808735370635986\n",
            "Frame 108 of 744\n",
            "Loss: 2.753459930419922\n",
            "Frame 109 of 744\n",
            "Loss: 2.7739007472991943\n",
            "Frame 110 of 744\n",
            "Loss: 2.769477128982544\n",
            "Frame 111 of 744\n",
            "Loss: 2.753291368484497\n",
            "Frame 112 of 744\n",
            "Loss: 2.760085344314575\n",
            "Frame 113 of 744\n",
            "Loss: 2.7623136043548584\n",
            "Frame 114 of 744\n",
            "Loss: 2.789306402206421\n",
            "Frame 115 of 744\n",
            "Loss: 2.8159008026123047\n",
            "Frame 116 of 744\n",
            "Loss: 2.776505470275879\n",
            "Frame 117 of 744\n",
            "Loss: 2.796628713607788\n",
            "Frame 118 of 744\n",
            "Loss: 2.7805395126342773\n",
            "Frame 119 of 744\n",
            "Loss: 2.775049924850464\n",
            "Frame 120 of 744\n",
            "Loss: 2.7884976863861084\n",
            "Frame 121 of 744\n",
            "Loss: 2.7724220752716064\n",
            "Frame 122 of 744\n",
            "Loss: 2.7947006225585938\n",
            "Frame 123 of 744\n",
            "Loss: 2.7720863819122314\n",
            "Frame 124 of 744\n",
            "Loss: 2.7339107990264893\n",
            "Frame 125 of 744\n",
            "Loss: 2.7770473957061768\n",
            "Frame 126 of 744\n",
            "Loss: 2.785137891769409\n",
            "Frame 127 of 744\n",
            "Loss: 2.749143600463867\n",
            "Frame 128 of 744\n",
            "Loss: 2.837125062942505\n",
            "Frame 129 of 744\n",
            "Loss: 2.7673416137695312\n",
            "Frame 130 of 744\n",
            "Loss: 2.7782344818115234\n",
            "Frame 131 of 744\n",
            "Loss: 2.77337646484375\n",
            "Frame 132 of 744\n",
            "Loss: 2.7715113162994385\n",
            "Frame 133 of 744\n",
            "Loss: 2.7633731365203857\n",
            "Frame 134 of 744\n",
            "Loss: 2.7751615047454834\n",
            "Frame 135 of 744\n",
            "Loss: 2.81181263923645\n",
            "Frame 136 of 744\n",
            "Loss: 2.808621644973755\n",
            "Frame 137 of 744\n",
            "Loss: 2.752054214477539\n",
            "Frame 138 of 744\n",
            "Loss: 2.772723436355591\n",
            "Frame 139 of 744\n",
            "Loss: 2.8105618953704834\n",
            "Frame 140 of 744\n",
            "Loss: 2.7524101734161377\n",
            "Frame 141 of 744\n",
            "Loss: 2.772427558898926\n",
            "Frame 142 of 744\n",
            "Loss: 2.7522048950195312\n",
            "Frame 143 of 744\n",
            "Loss: 2.7931954860687256\n",
            "Frame 144 of 744\n",
            "Loss: 2.7581472396850586\n",
            "Frame 145 of 744\n",
            "Loss: 2.749687910079956\n",
            "Frame 146 of 744\n",
            "Loss: 2.803727865219116\n",
            "Frame 147 of 744\n",
            "Loss: 2.73974609375\n",
            "Frame 148 of 744\n",
            "Loss: 2.776737928390503\n",
            "Frame 149 of 744\n",
            "Loss: 2.804577589035034\n",
            "Frame 150 of 744\n",
            "Loss: 2.759549140930176\n",
            "Frame 151 of 744\n",
            "Loss: 2.7891552448272705\n",
            "Frame 152 of 744\n",
            "Loss: 2.81555438041687\n",
            "Frame 153 of 744\n",
            "Loss: 2.7625153064727783\n",
            "Frame 154 of 744\n",
            "Loss: 2.747544527053833\n",
            "Frame 155 of 744\n",
            "Loss: 2.826310873031616\n",
            "Frame 156 of 744\n",
            "Loss: 2.7605459690093994\n",
            "Frame 157 of 744\n",
            "Loss: 2.7208049297332764\n",
            "Frame 158 of 744\n",
            "Loss: 2.7789249420166016\n",
            "Frame 159 of 744\n",
            "Loss: 2.804453134536743\n",
            "Frame 160 of 744\n",
            "Loss: 2.782503843307495\n",
            "Frame 161 of 744\n",
            "Loss: 2.7433128356933594\n",
            "Frame 162 of 744\n",
            "Loss: 2.788362741470337\n",
            "Frame 163 of 744\n",
            "Loss: 2.7915890216827393\n",
            "Frame 164 of 744\n",
            "Loss: 2.749497175216675\n",
            "Frame 165 of 744\n",
            "Loss: 2.7841427326202393\n",
            "Frame 166 of 744\n",
            "Loss: 2.7558224201202393\n",
            "Frame 167 of 744\n",
            "Loss: 2.732520341873169\n",
            "Frame 168 of 744\n",
            "Loss: 2.811974287033081\n",
            "Frame 169 of 744\n",
            "Loss: 2.7962944507598877\n",
            "Frame 170 of 744\n",
            "Loss: 2.771127939224243\n",
            "Frame 171 of 744\n",
            "Loss: 2.7953879833221436\n",
            "Frame 172 of 744\n",
            "Loss: 2.7715537548065186\n",
            "Frame 173 of 744\n",
            "Loss: 2.798250198364258\n",
            "Frame 174 of 744\n",
            "Loss: 2.769505500793457\n",
            "Frame 175 of 744\n",
            "Loss: 2.7857513427734375\n",
            "Frame 176 of 744\n",
            "Loss: 2.8041913509368896\n",
            "Frame 177 of 744\n",
            "Loss: 2.7428858280181885\n",
            "Frame 178 of 744\n",
            "Loss: 2.7745704650878906\n",
            "Frame 179 of 744\n",
            "Loss: 2.7829370498657227\n",
            "Frame 180 of 744\n",
            "Loss: 2.74578595161438\n",
            "Frame 181 of 744\n",
            "Loss: 2.7283620834350586\n",
            "Frame 182 of 744\n",
            "Loss: 2.8013229370117188\n",
            "Frame 183 of 744\n",
            "Loss: 2.7683022022247314\n",
            "Frame 184 of 744\n",
            "Loss: 2.7485809326171875\n",
            "Frame 185 of 744\n",
            "Loss: 2.7344391345977783\n",
            "Frame 186 of 744\n",
            "Loss: 2.7952003479003906\n",
            "Frame 187 of 744\n",
            "Loss: 2.717395544052124\n",
            "Frame 188 of 744\n",
            "Loss: 2.775132417678833\n",
            "Frame 189 of 744\n",
            "Loss: 2.7839200496673584\n",
            "Frame 190 of 744\n",
            "Loss: 2.836514711380005\n",
            "Frame 191 of 744\n",
            "Loss: 2.791529893875122\n",
            "Frame 192 of 744\n",
            "Loss: 2.768233060836792\n",
            "Frame 193 of 744\n",
            "Loss: 2.783910036087036\n",
            "Frame 194 of 744\n",
            "Loss: 2.768528699874878\n",
            "Frame 195 of 744\n",
            "Loss: 2.770120620727539\n",
            "Frame 196 of 744\n",
            "Loss: 2.7693116664886475\n",
            "Frame 197 of 744\n",
            "Loss: 2.7527167797088623\n",
            "Frame 198 of 744\n",
            "Loss: 2.7684953212738037\n",
            "Frame 199 of 744\n",
            "Loss: 2.8677146434783936\n",
            "Frame 200 of 744\n",
            "Loss: 2.7932627201080322\n",
            "Frame 201 of 744\n",
            "Loss: 2.7673604488372803\n",
            "Frame 202 of 744\n",
            "Loss: 2.8170902729034424\n",
            "Frame 203 of 744\n",
            "Loss: 2.771204710006714\n",
            "Frame 204 of 744\n",
            "Loss: 2.803497076034546\n",
            "Frame 205 of 744\n",
            "Loss: 2.765326738357544\n",
            "Frame 206 of 744\n",
            "Loss: 2.8233118057250977\n",
            "Frame 207 of 744\n",
            "Loss: 2.7558603286743164\n",
            "Frame 208 of 744\n",
            "Loss: 2.751004934310913\n",
            "Frame 209 of 744\n",
            "Loss: 2.833660840988159\n",
            "Frame 210 of 744\n",
            "Loss: 2.7896616458892822\n",
            "Frame 211 of 744\n",
            "Loss: 2.7849857807159424\n",
            "Frame 212 of 744\n",
            "Loss: 2.7499542236328125\n",
            "Frame 213 of 744\n",
            "Loss: 2.7730350494384766\n",
            "Frame 214 of 744\n",
            "Loss: 2.760756492614746\n",
            "Frame 215 of 744\n",
            "Loss: 2.7362213134765625\n",
            "Frame 216 of 744\n",
            "Loss: 2.7342536449432373\n",
            "Frame 217 of 744\n",
            "Loss: 2.765981912612915\n",
            "Frame 218 of 744\n",
            "Loss: 2.784137010574341\n",
            "Frame 219 of 744\n",
            "Loss: 2.7255353927612305\n",
            "Frame 220 of 744\n",
            "Loss: 2.75046443939209\n",
            "Frame 221 of 744\n",
            "Loss: 2.7915267944335938\n",
            "Frame 222 of 744\n",
            "Loss: 2.7623822689056396\n",
            "Frame 223 of 744\n",
            "Loss: 2.797717332839966\n",
            "Frame 224 of 744\n",
            "Loss: 2.7666923999786377\n",
            "Frame 225 of 744\n",
            "Loss: 2.7411181926727295\n",
            "Frame 226 of 744\n",
            "Loss: 2.767596483230591\n",
            "Frame 227 of 744\n",
            "Loss: 2.813476800918579\n",
            "Frame 228 of 744\n",
            "Loss: 2.757073402404785\n",
            "Frame 229 of 744\n",
            "Loss: 2.7841262817382812\n",
            "Frame 230 of 744\n",
            "Loss: 2.781562089920044\n",
            "Frame 231 of 744\n",
            "Loss: 2.7673797607421875\n",
            "Frame 232 of 744\n",
            "Loss: 2.770390748977661\n",
            "Frame 233 of 744\n",
            "Loss: 2.7686214447021484\n",
            "Frame 234 of 744\n",
            "Loss: 2.8396100997924805\n",
            "Frame 235 of 744\n",
            "Loss: 2.763172149658203\n",
            "Frame 236 of 744\n",
            "Loss: 2.8391196727752686\n",
            "Frame 237 of 744\n",
            "Loss: 2.832226514816284\n",
            "Frame 238 of 744\n",
            "Loss: 2.6928205490112305\n",
            "Frame 239 of 744\n",
            "Loss: 2.812802314758301\n",
            "Frame 240 of 744\n",
            "Loss: 2.7290830612182617\n",
            "Frame 241 of 744\n",
            "Loss: 2.715261697769165\n",
            "Frame 242 of 744\n",
            "Loss: 2.8463757038116455\n",
            "Frame 243 of 744\n",
            "Loss: 2.7276713848114014\n",
            "Frame 244 of 744\n",
            "Loss: 2.727980375289917\n",
            "Frame 245 of 744\n",
            "Loss: 2.725942611694336\n",
            "Frame 246 of 744\n",
            "Loss: 2.8418617248535156\n",
            "Frame 247 of 744\n",
            "Loss: 2.8360469341278076\n",
            "Training Loss: 248.15246334527768\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.05107526881720429\n",
            "Test Accuracy: 0.046296296296296294\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss: 2.7516210079193115\n",
            "Frame 21 of 744\n",
            "Loss: 2.7177608013153076\n",
            "Frame 22 of 744\n",
            "Loss: 2.778850793838501\n",
            "Frame 23 of 744\n",
            "Loss: 2.8042240142822266\n",
            "Frame 24 of 744\n",
            "Loss: 2.78631591796875\n",
            "Frame 25 of 744\n",
            "Loss: 2.7496185302734375\n",
            "Frame 26 of 744\n",
            "Loss: 2.765126943588257\n",
            "Frame 27 of 744\n",
            "Loss: 2.7998201847076416\n",
            "Frame 28 of 744\n",
            "Loss: 2.7614641189575195\n",
            "Frame 29 of 744\n",
            "Loss: 2.74633526802063\n",
            "Frame 30 of 744\n",
            "Loss: 2.8096072673797607\n",
            "Frame 31 of 744\n",
            "Loss: 2.7240846157073975\n",
            "Frame 32 of 744\n",
            "Loss: 2.77719783782959\n",
            "Frame 33 of 744\n",
            "Loss: 2.8206193447113037\n",
            "Frame 34 of 744\n",
            "Loss: 2.765766143798828\n",
            "Frame 35 of 744\n",
            "Loss: 2.8101022243499756\n",
            "Frame 36 of 744\n",
            "Loss: 2.7876131534576416\n",
            "Frame 37 of 744\n",
            "Loss: 2.803056478500366\n",
            "Frame 38 of 744\n",
            "Loss: 2.7530853748321533\n",
            "Frame 39 of 744\n",
            "Loss: 2.7703802585601807\n",
            "Frame 40 of 744\n",
            "Loss: 2.7684268951416016\n",
            "Frame 41 of 744\n",
            "Loss: 2.7711360454559326\n",
            "Frame 42 of 744\n",
            "Loss: 2.7662456035614014\n",
            "Frame 43 of 744\n",
            "Loss: 2.773972511291504\n",
            "Frame 44 of 744\n",
            "Loss: 2.7445201873779297\n",
            "Frame 45 of 744\n",
            "Loss: 2.854262113571167\n",
            "Frame 46 of 744\n",
            "Loss: 2.7618398666381836\n",
            "Frame 47 of 744\n",
            "Loss: 2.7355992794036865\n",
            "Frame 48 of 744\n",
            "Loss: 2.8193531036376953\n",
            "Frame 49 of 744\n",
            "Loss: 2.7232987880706787\n",
            "Frame 50 of 744\n",
            "Loss: 2.826960325241089\n",
            "Frame 51 of 744\n",
            "Loss: 2.8365418910980225\n",
            "Frame 52 of 744\n",
            "Loss: 2.8411500453948975\n",
            "Frame 53 of 744\n",
            "Loss: 2.837015151977539\n",
            "Frame 54 of 744\n",
            "Loss: 2.756305694580078\n",
            "Frame 55 of 744\n",
            "Loss: 2.8318710327148438\n",
            "Frame 56 of 744\n",
            "Loss: 2.7422876358032227\n",
            "Frame 57 of 744\n",
            "Loss: 2.7707393169403076\n",
            "Frame 58 of 744\n",
            "Loss: 2.802875518798828\n",
            "Frame 59 of 744\n",
            "Loss: 2.848466634750366\n",
            "Frame 60 of 744\n",
            "Loss: 2.7400245666503906\n",
            "Frame 61 of 744\n",
            "Loss: 2.776060104370117\n",
            "Frame 62 of 744\n",
            "Loss: 2.762432336807251\n",
            "Frame 63 of 744\n",
            "Loss: 2.8173110485076904\n",
            "Frame 64 of 744\n",
            "Loss: 2.7124340534210205\n",
            "Frame 65 of 744\n",
            "Loss: 2.816179037094116\n",
            "Frame 66 of 744\n",
            "Loss: 2.7173774242401123\n",
            "Frame 67 of 744\n",
            "Loss: 2.7686691284179688\n",
            "Frame 68 of 744\n",
            "Loss: 2.732727289199829\n",
            "Frame 69 of 744\n",
            "Loss: 2.794356107711792\n",
            "Frame 70 of 744\n",
            "Loss: 2.7621066570281982\n",
            "Frame 71 of 744\n",
            "Loss: 2.9009227752685547\n",
            "Frame 72 of 744\n",
            "Loss: 2.7268283367156982\n",
            "Frame 73 of 744\n",
            "Loss: 2.7483463287353516\n",
            "Frame 74 of 744\n",
            "Loss: 2.7351253032684326\n",
            "Frame 75 of 744\n",
            "Loss: 2.7644176483154297\n",
            "Frame 76 of 744\n",
            "Loss: 2.730297327041626\n",
            "Frame 77 of 744\n",
            "Loss: 2.776447057723999\n",
            "Frame 78 of 744\n",
            "Loss: 2.7019855976104736\n",
            "Frame 79 of 744\n",
            "Loss: 2.8106749057769775\n",
            "Frame 80 of 744\n",
            "Loss: 2.739564895629883\n",
            "Frame 81 of 744\n",
            "Loss: 2.7927186489105225\n",
            "Frame 82 of 744\n",
            "Loss: 2.7108373641967773\n",
            "Frame 83 of 744\n",
            "Loss: 2.744471788406372\n",
            "Frame 84 of 744\n",
            "Loss: 2.804027795791626\n",
            "Frame 85 of 744\n",
            "Loss: 2.7948150634765625\n",
            "Frame 86 of 744\n",
            "Loss: 2.747586250305176\n",
            "Frame 87 of 744\n",
            "Loss: 2.70151424407959\n",
            "Frame 88 of 744\n",
            "Loss: 2.7982780933380127\n",
            "Frame 89 of 744\n",
            "Loss: 2.7180230617523193\n",
            "Frame 90 of 744\n",
            "Loss: 2.7727317810058594\n",
            "Frame 91 of 744\n",
            "Loss: 2.8385984897613525\n",
            "Frame 92 of 744\n",
            "Loss: 2.8082892894744873\n",
            "Frame 93 of 744\n",
            "Loss: 2.867814302444458\n",
            "Frame 94 of 744\n",
            "Loss: 2.7110188007354736\n",
            "Frame 95 of 744\n",
            "Loss: 2.8314597606658936\n",
            "Frame 96 of 744\n",
            "Loss: 2.777912139892578\n",
            "Frame 97 of 744\n",
            "Loss: 2.8048832416534424\n",
            "Frame 98 of 744\n",
            "Loss: 2.730724573135376\n",
            "Frame 99 of 744\n",
            "Loss: 2.6984035968780518\n",
            "Frame 100 of 744\n",
            "Loss: 2.8279731273651123\n",
            "Frame 101 of 744\n",
            "Loss: 2.8044703006744385\n",
            "Frame 102 of 744\n",
            "Loss: 2.839869260787964\n",
            "Frame 103 of 744\n",
            "Loss: 2.8096981048583984\n",
            "Frame 104 of 744\n",
            "Loss: 2.7478229999542236\n",
            "Frame 105 of 744\n",
            "Loss: 2.793600082397461\n",
            "Frame 106 of 744\n",
            "Loss: 2.7791061401367188\n",
            "Frame 107 of 744\n",
            "Loss: 2.7169017791748047\n",
            "Frame 108 of 744\n",
            "Loss: 2.8044376373291016\n",
            "Frame 109 of 744\n",
            "Loss: 2.787921667098999\n",
            "Frame 110 of 744\n",
            "Loss: 2.7805888652801514\n",
            "Frame 111 of 744\n",
            "Loss: 2.825359582901001\n",
            "Frame 112 of 744\n",
            "Loss: 2.7650434970855713\n",
            "Frame 113 of 744\n",
            "Loss: 2.8312790393829346\n",
            "Frame 114 of 744\n",
            "Loss: 2.811129331588745\n",
            "Frame 115 of 744\n",
            "Loss: 2.785187005996704\n",
            "Frame 116 of 744\n",
            "Loss: 2.8011982440948486\n",
            "Frame 117 of 744\n",
            "Loss: 2.6877334117889404\n",
            "Frame 118 of 744\n",
            "Loss: 2.7838926315307617\n",
            "Frame 119 of 744\n",
            "Loss: 2.7447240352630615\n",
            "Frame 120 of 744\n",
            "Loss: 2.8011035919189453\n",
            "Frame 121 of 744\n",
            "Loss: 2.7759196758270264\n",
            "Frame 122 of 744\n",
            "Loss: 2.824469804763794\n",
            "Frame 123 of 744\n",
            "Loss: 2.748856544494629\n",
            "Frame 124 of 744\n",
            "Loss: 2.785426378250122\n",
            "Frame 125 of 744\n",
            "Loss: 2.7352144718170166\n",
            "Frame 126 of 744\n",
            "Loss: 2.8555784225463867\n",
            "Frame 127 of 744\n",
            "Loss: 2.8590996265411377\n",
            "Frame 128 of 744\n",
            "Loss: 2.8342602252960205\n",
            "Frame 129 of 744\n",
            "Loss: 2.7374465465545654\n",
            "Frame 130 of 744\n",
            "Loss: 2.776934862136841\n",
            "Frame 131 of 744\n",
            "Loss: 2.698230743408203\n",
            "Frame 132 of 744\n",
            "Loss: 2.7745800018310547\n",
            "Frame 133 of 744\n",
            "Loss: 2.7893564701080322\n",
            "Frame 134 of 744\n",
            "Loss: 2.806748390197754\n",
            "Frame 135 of 744\n",
            "Loss: 2.723766565322876\n",
            "Frame 136 of 744\n",
            "Loss: 2.7067630290985107\n",
            "Frame 137 of 744\n",
            "Loss: 2.8224480152130127\n",
            "Frame 138 of 744\n",
            "Loss: 2.811687469482422\n",
            "Frame 139 of 744\n",
            "Loss: 2.764967679977417\n",
            "Frame 140 of 744\n",
            "Loss: 2.788283348083496\n",
            "Frame 141 of 744\n",
            "Loss: 2.8449866771698\n",
            "Frame 142 of 744\n",
            "Loss: 2.8895931243896484\n",
            "Frame 143 of 744\n",
            "Loss: 2.7797882556915283\n",
            "Frame 144 of 744\n",
            "Loss: 2.7755892276763916\n",
            "Frame 145 of 744\n",
            "Loss: 2.7633345127105713\n",
            "Frame 146 of 744\n",
            "Loss: 2.725126028060913\n",
            "Frame 147 of 744\n",
            "Loss: 2.838486433029175\n",
            "Frame 148 of 744\n",
            "Loss: 2.8717708587646484\n",
            "Frame 149 of 744\n",
            "Loss: 2.7454967498779297\n",
            "Frame 150 of 744\n",
            "Loss: 2.7882585525512695\n",
            "Frame 151 of 744\n",
            "Loss: 2.8253555297851562\n",
            "Frame 152 of 744\n",
            "Loss: 2.790522813796997\n",
            "Frame 153 of 744\n",
            "Loss: 2.7860822677612305\n",
            "Frame 154 of 744\n",
            "Loss: 2.7613980770111084\n",
            "Frame 155 of 744\n",
            "Loss: 2.819422483444214\n",
            "Frame 156 of 744\n",
            "Loss: 2.783499002456665\n",
            "Frame 157 of 744\n",
            "Loss: 2.7775895595550537\n",
            "Frame 158 of 744\n",
            "Loss: 2.817471742630005\n",
            "Frame 159 of 744\n",
            "Loss: 2.7587928771972656\n",
            "Frame 160 of 744\n",
            "Loss: 2.7850208282470703\n",
            "Frame 161 of 744\n",
            "Loss: 2.764385938644409\n",
            "Frame 162 of 744\n",
            "Loss: 2.7693169116973877\n",
            "Frame 163 of 744\n",
            "Loss: 2.768286943435669\n",
            "Frame 164 of 744\n",
            "Loss: 2.7718565464019775\n",
            "Frame 165 of 744\n",
            "Loss: 2.7817869186401367\n",
            "Frame 166 of 744\n",
            "Loss: 2.731557846069336\n",
            "Frame 167 of 744\n",
            "Loss: 2.749471426010132\n",
            "Frame 168 of 744\n",
            "Loss: 2.7922849655151367\n",
            "Frame 169 of 744\n",
            "Loss: 2.788858652114868\n",
            "Frame 170 of 744\n",
            "Loss: 2.7718279361724854\n",
            "Frame 171 of 744\n",
            "Loss: 2.670604705810547\n",
            "Frame 172 of 744\n",
            "Loss: 2.823125123977661\n",
            "Frame 173 of 744\n",
            "Loss: 2.7949631214141846\n",
            "Frame 174 of 744\n",
            "Loss: 2.7496776580810547\n",
            "Frame 175 of 744\n",
            "Loss: 2.8083980083465576\n",
            "Frame 176 of 744\n",
            "Loss: 2.80324387550354\n",
            "Frame 177 of 744\n",
            "Loss: 2.757153272628784\n",
            "Frame 178 of 744\n",
            "Loss: 2.7850258350372314\n",
            "Frame 179 of 744\n",
            "Loss: 2.6963841915130615\n",
            "Frame 180 of 744\n",
            "Loss: 2.7929766178131104\n",
            "Frame 181 of 744\n",
            "Loss: 2.7268917560577393\n",
            "Frame 182 of 744\n",
            "Loss: 2.7929656505584717\n",
            "Frame 183 of 744\n",
            "Loss: 2.7477664947509766\n",
            "Frame 184 of 744\n",
            "Loss: 2.811628580093384\n",
            "Frame 185 of 744\n",
            "Loss: 2.7417290210723877\n",
            "Frame 186 of 744\n",
            "Loss: 2.752378463745117\n",
            "Frame 187 of 744\n",
            "Loss: 2.8239755630493164\n",
            "Frame 188 of 744\n",
            "Loss: 2.731081962585449\n",
            "Frame 189 of 744\n",
            "Loss: 2.804316759109497\n",
            "Frame 190 of 744\n",
            "Loss: 2.802875280380249\n",
            "Frame 191 of 744\n",
            "Loss: 2.772892713546753\n",
            "Frame 192 of 744\n",
            "Loss: 2.8368427753448486\n",
            "Frame 193 of 744\n",
            "Loss: 2.7572343349456787\n",
            "Frame 194 of 744\n",
            "Loss: 2.74210524559021\n",
            "Frame 195 of 744\n",
            "Loss: 2.801027536392212\n",
            "Frame 196 of 744\n",
            "Loss: 2.8225669860839844\n",
            "Frame 197 of 744\n",
            "Loss: 2.797528028488159\n",
            "Frame 198 of 744\n",
            "Loss: 2.814167022705078\n",
            "Frame 199 of 744\n",
            "Loss: 2.809499740600586\n",
            "Frame 200 of 744\n",
            "Loss: 2.756242036819458\n",
            "Frame 201 of 744\n",
            "Loss: 2.7885119915008545\n",
            "Frame 202 of 744\n",
            "Loss: 2.81573486328125\n",
            "Frame 203 of 744\n",
            "Loss: 2.6955440044403076\n",
            "Frame 204 of 744\n",
            "Loss: 2.803579330444336\n",
            "Frame 205 of 744\n",
            "Loss: 2.8453400135040283\n",
            "Frame 206 of 744\n",
            "Loss: 2.762913703918457\n",
            "Frame 207 of 744\n",
            "Loss: 2.7759525775909424\n",
            "Frame 208 of 744\n",
            "Loss: 2.7101595401763916\n",
            "Frame 209 of 744\n",
            "Loss: 2.6995861530303955\n",
            "Frame 210 of 744\n",
            "Loss: 2.765481948852539\n",
            "Frame 211 of 744\n",
            "Loss: 2.7795372009277344\n",
            "Frame 212 of 744\n",
            "Loss: 2.8371028900146484\n",
            "Frame 213 of 744\n",
            "Loss: 2.8114559650421143\n",
            "Frame 214 of 744\n",
            "Loss: 2.7950212955474854\n",
            "Frame 215 of 744\n",
            "Loss: 2.79348087310791\n",
            "Frame 216 of 744\n",
            "Loss: 2.7425127029418945\n",
            "Frame 217 of 744\n",
            "Loss: 2.8314437866210938\n",
            "Frame 218 of 744\n",
            "Loss: 2.7321841716766357\n",
            "Frame 219 of 744\n",
            "Loss: 2.726177453994751\n",
            "Frame 220 of 744\n",
            "Loss: 2.790811777114868\n",
            "Frame 221 of 744\n",
            "Loss: 2.7985565662384033\n",
            "Frame 222 of 744\n",
            "Loss: 2.7474987506866455\n",
            "Frame 223 of 744\n",
            "Loss: 2.809354066848755\n",
            "Frame 224 of 744\n",
            "Loss: 2.7667319774627686\n",
            "Frame 225 of 744\n",
            "Loss: 2.822368860244751\n",
            "Frame 226 of 744\n",
            "Loss: 2.7946557998657227\n",
            "Frame 227 of 744\n",
            "Loss: 2.7111213207244873\n",
            "Frame 228 of 744\n",
            "Loss: 2.7781436443328857\n",
            "Frame 229 of 744\n",
            "Loss: 2.740766763687134\n",
            "Frame 230 of 744\n",
            "Loss: 2.706975221633911\n",
            "Frame 231 of 744\n",
            "Loss: 2.716712713241577\n",
            "Frame 232 of 744\n",
            "Loss: 2.788304328918457\n",
            "Frame 233 of 744\n",
            "Loss: 2.8187007904052734\n",
            "Frame 234 of 744\n",
            "Loss: 2.8586671352386475\n",
            "Frame 235 of 744\n",
            "Loss: 2.8769168853759766\n",
            "Frame 236 of 744\n",
            "Loss: 2.826352834701538\n",
            "Frame 237 of 744\n",
            "Loss: 2.8121538162231445\n",
            "Frame 238 of 744\n",
            "Loss: 2.72407603263855\n",
            "Frame 239 of 744\n",
            "Loss: 2.757495164871216\n",
            "Frame 240 of 744\n",
            "Loss: 2.7697060108184814\n",
            "Frame 241 of 744\n",
            "Loss: 2.7387282848358154\n",
            "Frame 242 of 744\n",
            "Loss: 2.7807867527008057\n",
            "Frame 243 of 744\n",
            "Loss: 2.760751962661743\n",
            "Frame 244 of 744\n",
            "Loss: 2.7736618518829346\n",
            "Frame 245 of 744\n",
            "Loss: 2.7739126682281494\n",
            "Frame 246 of 744\n",
            "Loss: 2.758066177368164\n",
            "Frame 247 of 744\n",
            "Loss: 2.801320791244507\n",
            "Training Loss: 2.7789351469086063\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.04838709677419354\n",
            "Test Accuracy: 0.046296296296296294\n",
            "Epoch: 5\n",
            "Frame 0 of 744\n",
            "Loss: 2.7704296112060547\n",
            "Frame 1 of 744\n",
            "Loss: 2.7587268352508545\n",
            "Frame 2 of 744\n",
            "Loss: 2.7822234630584717\n",
            "Frame 3 of 744\n",
            "Loss: 2.776197671890259\n",
            "Frame 4 of 744\n",
            "Loss: 2.798184394836426\n",
            "Frame 5 of 744\n",
            "Loss: 2.785708427429199\n",
            "Frame 6 of 744\n",
            "Loss: 2.748760461807251\n",
            "Frame 7 of 744\n",
            "Loss: 2.84621524810791\n",
            "Frame 8 of 744\n",
            "Loss: 2.8095619678497314\n",
            "Frame 9 of 744\n",
            "Loss: 2.87695050239563\n",
            "Frame 10 of 744\n",
            "Loss: 2.7977073192596436\n",
            "Frame 11 of 744\n",
            "Loss: 2.719590425491333\n",
            "Frame 12 of 744\n",
            "Loss: 2.699144124984741\n",
            "Frame 13 of 744\n",
            "Loss: 2.7062129974365234\n",
            "Frame 14 of 744\n",
            "Loss: 2.735786199569702\n",
            "Frame 15 of 744\n",
            "Loss: 2.7914578914642334\n",
            "Frame 16 of 744\n",
            "Loss: 2.761976480484009\n",
            "Frame 17 of 744\n",
            "Loss: 2.806849241256714\n",
            "Frame 18 of 744\n",
            "Loss: 2.761427640914917\n",
            "Frame 19 of 744\n",
            "Loss: 2.7741947174072266\n",
            "Frame 20 of 744\n",
            "Loss: 2.7699737548828125\n",
            "Frame 21 of 744\n",
            "Loss: 2.784276008605957\n",
            "Frame 22 of 744\n",
            "Loss: 2.7767322063446045\n",
            "Frame 23 of 744\n",
            "Loss: 2.7173030376434326\n",
            "Frame 24 of 744\n",
            "Loss: 2.753690719604492\n",
            "Frame 25 of 744\n",
            "Loss: 2.7724828720092773\n",
            "Frame 26 of 744\n",
            "Loss: 2.806992769241333\n",
            "Frame 27 of 744\n",
            "Loss: 2.704061269760132\n",
            "Frame 28 of 744\n",
            "Loss: 2.8458545207977295\n",
            "Frame 29 of 744\n",
            "Loss: 2.748969316482544\n",
            "Frame 30 of 744\n",
            "Loss: 2.758976697921753\n",
            "Frame 31 of 744\n",
            "Loss: 2.712332010269165\n",
            "Frame 32 of 744\n",
            "Loss: 2.7772982120513916\n",
            "Frame 33 of 744\n",
            "Loss: 2.7413558959960938\n",
            "Frame 34 of 744\n",
            "Loss: 2.784897804260254\n",
            "Frame 35 of 744\n",
            "Loss: 2.7635059356689453\n",
            "Frame 36 of 744\n",
            "Loss: 2.7035961151123047\n",
            "Frame 37 of 744\n",
            "Loss: 2.771479845046997\n",
            "Frame 38 of 744\n",
            "Loss: 2.7592532634735107\n",
            "Frame 39 of 744\n",
            "Loss: 2.734656572341919\n",
            "Frame 40 of 744\n",
            "Loss: 2.7799999713897705\n",
            "Frame 41 of 744\n",
            "Loss: 2.7039592266082764\n",
            "Frame 42 of 744\n",
            "Loss: 2.8363378047943115\n",
            "Frame 43 of 744\n",
            "Loss: 2.7179877758026123\n",
            "Frame 44 of 744\n",
            "Loss: 2.8164279460906982\n",
            "Frame 45 of 744\n",
            "Loss: 2.8077104091644287\n",
            "Frame 46 of 744\n",
            "Loss: 2.670440435409546\n",
            "Frame 47 of 744\n",
            "Loss: 2.7565128803253174\n",
            "Frame 48 of 744\n",
            "Loss: 2.8000991344451904\n",
            "Frame 49 of 744\n",
            "Loss: 2.72575306892395\n",
            "Frame 50 of 744\n",
            "Loss: 2.702442169189453\n",
            "Frame 51 of 744\n",
            "Loss: 2.7299344539642334\n",
            "Frame 52 of 744\n",
            "Loss: 2.7839181423187256\n",
            "Frame 53 of 744\n",
            "Loss: 2.822484254837036\n",
            "Frame 54 of 744\n",
            "Loss: 2.7718451023101807\n",
            "Frame 55 of 744\n",
            "Loss: 2.7916595935821533\n",
            "Frame 56 of 744\n",
            "Loss: 2.7799527645111084\n",
            "Frame 57 of 744\n",
            "Loss: 2.733527183532715\n",
            "Frame 58 of 744\n",
            "Loss: 2.792306900024414\n",
            "Frame 59 of 744\n",
            "Loss: 2.7670652866363525\n",
            "Frame 60 of 744\n",
            "Loss: 2.7621583938598633\n",
            "Frame 61 of 744\n",
            "Loss: 2.667956590652466\n",
            "Frame 62 of 744\n",
            "Loss: 2.7914531230926514\n",
            "Frame 63 of 744\n",
            "Loss: 2.819281816482544\n",
            "Frame 64 of 744\n",
            "Loss: 2.7881155014038086\n",
            "Frame 65 of 744\n",
            "Loss: 2.6749331951141357\n",
            "Frame 66 of 744\n",
            "Loss: 2.7028610706329346\n",
            "Frame 67 of 744\n",
            "Loss: 2.74035906791687\n",
            "Frame 68 of 744\n",
            "Loss: 2.722799301147461\n",
            "Frame 69 of 744\n",
            "Loss: 2.753328561782837\n",
            "Frame 70 of 744\n",
            "Loss: 2.6306028366088867\n",
            "Frame 71 of 744\n",
            "Loss: 2.6679465770721436\n",
            "Frame 72 of 744\n",
            "Loss: 2.8951613903045654\n",
            "Frame 73 of 744\n",
            "Loss: 2.9035227298736572\n",
            "Frame 74 of 744\n",
            "Loss: 2.829188108444214\n",
            "Frame 75 of 744\n",
            "Loss: 2.7179489135742188\n",
            "Frame 76 of 744\n",
            "Loss: 2.6746997833251953\n",
            "Frame 77 of 744\n",
            "Loss: 2.7333953380584717\n",
            "Frame 78 of 744\n",
            "Loss: 2.817756414413452\n",
            "Frame 79 of 744\n",
            "Loss: 2.6319894790649414\n",
            "Frame 80 of 744\n",
            "Loss: 2.812741994857788\n",
            "Frame 81 of 744\n",
            "Loss: 2.717491865158081\n",
            "Frame 82 of 744\n",
            "Loss: 2.7726166248321533\n",
            "Frame 83 of 744\n",
            "Loss: 2.7983272075653076\n",
            "Frame 84 of 744\n",
            "Loss: 2.8099281787872314\n",
            "Frame 85 of 744\n",
            "Loss: 2.8243911266326904\n",
            "Frame 86 of 744\n",
            "Loss: 2.793225049972534\n",
            "Frame 87 of 744\n",
            "Loss: 2.7210376262664795\n",
            "Frame 88 of 744\n",
            "Loss: 2.790609359741211\n",
            "Frame 89 of 744\n",
            "Loss: 2.875519037246704\n",
            "Frame 90 of 744\n",
            "Loss: 2.7484371662139893\n",
            "Frame 91 of 744\n",
            "Loss: 2.8391053676605225\n",
            "Frame 92 of 744\n",
            "Loss: 2.8717129230499268\n",
            "Frame 93 of 744\n",
            "Loss: 2.7842581272125244\n",
            "Frame 94 of 744\n",
            "Loss: 2.867048978805542\n",
            "Frame 95 of 744\n",
            "Loss: 2.792196273803711\n",
            "Frame 96 of 744\n",
            "Loss: 2.7818405628204346\n",
            "Frame 97 of 744\n",
            "Loss: 2.84848690032959\n",
            "Frame 98 of 744\n",
            "Loss: 2.7254021167755127\n",
            "Frame 99 of 744\n",
            "Loss: 2.9234564304351807\n",
            "Frame 100 of 744\n",
            "Loss: 2.7860019207000732\n",
            "Frame 101 of 744\n",
            "Loss: 2.730074167251587\n",
            "Frame 102 of 744\n",
            "Loss: 2.882020950317383\n",
            "Frame 103 of 744\n",
            "Loss: 2.830786943435669\n",
            "Frame 104 of 744\n",
            "Loss: 2.7979862689971924\n",
            "Frame 105 of 744\n",
            "Loss: 2.706859588623047\n",
            "Frame 106 of 744\n",
            "Loss: 2.8724911212921143\n",
            "Frame 107 of 744\n",
            "Loss: 2.7054660320281982\n",
            "Frame 108 of 744\n",
            "Loss: 2.88824725151062\n",
            "Frame 109 of 744\n",
            "Loss: 2.831439733505249\n",
            "Frame 110 of 744\n",
            "Loss: 2.828693151473999\n",
            "Frame 111 of 744\n",
            "Loss: 2.7132110595703125\n",
            "Frame 112 of 744\n",
            "Loss: 2.8028602600097656\n",
            "Frame 113 of 744\n",
            "Loss: 2.885749578475952\n",
            "Frame 114 of 744\n",
            "Loss: 2.7113540172576904\n",
            "Frame 115 of 744\n",
            "Loss: 2.7782907485961914\n",
            "Frame 116 of 744\n",
            "Loss: 2.835042715072632\n",
            "Frame 117 of 744\n",
            "Loss: 2.788005828857422\n",
            "Frame 118 of 744\n",
            "Loss: 2.820518732070923\n",
            "Frame 119 of 744\n",
            "Loss: 2.783026695251465\n",
            "Frame 120 of 744\n",
            "Loss: 2.7710113525390625\n",
            "Frame 121 of 744\n",
            "Loss: 2.765312433242798\n",
            "Frame 122 of 744\n",
            "Loss: 2.7690649032592773\n",
            "Frame 123 of 744\n",
            "Loss: 2.748316764831543\n",
            "Frame 124 of 744\n",
            "Loss: 2.759188413619995\n",
            "Frame 125 of 744\n",
            "Loss: 2.801260232925415\n",
            "Frame 126 of 744\n",
            "Loss: 2.8929736614227295\n",
            "Frame 127 of 744\n",
            "Loss: 2.7301132678985596\n",
            "Frame 128 of 744\n",
            "Loss: 2.8078575134277344\n",
            "Frame 129 of 744\n",
            "Loss: 2.871644973754883\n",
            "Frame 130 of 744\n",
            "Loss: 2.800593137741089\n",
            "Frame 131 of 744\n",
            "Loss: 2.7915866374969482\n",
            "Frame 132 of 744\n",
            "Loss: 2.7482187747955322\n",
            "Frame 133 of 744\n",
            "Loss: 2.8239715099334717\n",
            "Frame 134 of 744\n",
            "Loss: 2.8571834564208984\n",
            "Frame 135 of 744\n",
            "Loss: 2.770097494125366\n",
            "Frame 136 of 744\n",
            "Loss: 2.727328062057495\n",
            "Frame 137 of 744\n",
            "Loss: 2.7646830081939697\n",
            "Frame 138 of 744\n",
            "Loss: 2.8061559200286865\n",
            "Frame 139 of 744\n",
            "Loss: 2.6905548572540283\n",
            "Frame 140 of 744\n",
            "Loss: 2.8325140476226807\n",
            "Frame 141 of 744\n",
            "Loss: 2.8056886196136475\n",
            "Frame 142 of 744\n",
            "Loss: 2.7543303966522217\n",
            "Frame 143 of 744\n",
            "Loss: 2.7506086826324463\n",
            "Frame 144 of 744\n",
            "Loss: 2.8144404888153076\n",
            "Frame 145 of 744\n",
            "Loss: 2.740281820297241\n",
            "Frame 146 of 744\n",
            "Loss: 2.7818219661712646\n",
            "Frame 147 of 744\n",
            "Loss: 2.7155215740203857\n",
            "Frame 148 of 744\n",
            "Loss: 2.740846633911133\n",
            "Frame 149 of 744\n",
            "Loss: 2.8268604278564453\n",
            "Frame 150 of 744\n",
            "Loss: 2.8123905658721924\n",
            "Frame 151 of 744\n",
            "Loss: 2.816110849380493\n",
            "Frame 152 of 744\n",
            "Loss: 2.7425472736358643\n",
            "Frame 153 of 744\n",
            "Loss: 2.8434343338012695\n",
            "Frame 154 of 744\n",
            "Loss: 2.8580782413482666\n",
            "Frame 155 of 744\n",
            "Loss: 2.8079938888549805\n",
            "Frame 156 of 744\n",
            "Loss: 2.7365970611572266\n",
            "Frame 157 of 744\n",
            "Loss: 2.7012367248535156\n",
            "Frame 158 of 744\n",
            "Loss: 2.7739267349243164\n",
            "Frame 159 of 744\n",
            "Loss: 2.752756118774414\n",
            "Frame 160 of 744\n",
            "Loss: 2.843444585800171\n",
            "Frame 161 of 744\n",
            "Loss: 2.802797317504883\n",
            "Frame 162 of 744\n",
            "Loss: 2.795626401901245\n",
            "Frame 163 of 744\n",
            "Loss: 2.7350471019744873\n",
            "Frame 164 of 744\n",
            "Loss: 2.74462628364563\n",
            "Frame 165 of 744\n",
            "Loss: 2.860008478164673\n",
            "Frame 166 of 744\n",
            "Loss: 2.8032238483428955\n",
            "Frame 167 of 744\n",
            "Loss: 2.7869765758514404\n",
            "Frame 168 of 744\n",
            "Loss: 2.70108962059021\n",
            "Frame 169 of 744\n",
            "Loss: 2.7218847274780273\n",
            "Frame 170 of 744\n",
            "Loss: 2.7789907455444336\n",
            "Frame 171 of 744\n",
            "Loss: 2.7213640213012695\n",
            "Frame 172 of 744\n",
            "Loss: 2.748258352279663\n",
            "Frame 173 of 744\n",
            "Loss: 2.8393714427948\n",
            "Frame 174 of 744\n",
            "Loss: 2.8142502307891846\n",
            "Frame 175 of 744\n",
            "Loss: 2.7944552898406982\n",
            "Frame 176 of 744\n",
            "Loss: 2.7025890350341797\n",
            "Frame 177 of 744\n",
            "Loss: 2.855740785598755\n",
            "Frame 178 of 744\n",
            "Loss: 2.735600709915161\n",
            "Frame 179 of 744\n",
            "Loss: 2.801832914352417\n",
            "Frame 180 of 744\n",
            "Loss: 2.7538883686065674\n",
            "Frame 181 of 744\n",
            "Loss: 2.793919801712036\n",
            "Frame 182 of 744\n",
            "Loss: 2.836329698562622\n",
            "Frame 183 of 744\n",
            "Loss: 2.7376978397369385\n",
            "Frame 184 of 744\n",
            "Loss: 2.831571578979492\n",
            "Frame 185 of 744\n",
            "Loss: 2.84499454498291\n",
            "Frame 186 of 744\n",
            "Loss: 2.830139398574829\n",
            "Frame 187 of 744\n",
            "Loss: 2.703916549682617\n",
            "Frame 188 of 744\n",
            "Loss: 2.745973587036133\n",
            "Frame 189 of 744\n",
            "Loss: 2.795537233352661\n",
            "Frame 190 of 744\n",
            "Loss: 2.7769222259521484\n",
            "Frame 191 of 744\n",
            "Loss: 2.692958116531372\n",
            "Frame 192 of 744\n",
            "Loss: 2.790534734725952\n",
            "Frame 193 of 744\n",
            "Loss: 2.718223810195923\n",
            "Frame 194 of 744\n",
            "Loss: 2.7674179077148438\n",
            "Frame 195 of 744\n",
            "Loss: 2.8458449840545654\n",
            "Frame 196 of 744\n",
            "Loss: 2.7536637783050537\n",
            "Frame 197 of 744\n",
            "Loss: 2.8419017791748047\n",
            "Frame 198 of 744\n",
            "Loss: 2.837395429611206\n",
            "Frame 199 of 744\n",
            "Loss: 2.799466371536255\n",
            "Frame 200 of 744\n",
            "Loss: 2.7660720348358154\n",
            "Frame 201 of 744\n",
            "Loss: 2.715439558029175\n",
            "Frame 202 of 744\n",
            "Loss: 2.802483558654785\n",
            "Frame 203 of 744\n",
            "Loss: 2.786883592605591\n",
            "Frame 204 of 744\n",
            "Loss: 2.769599199295044\n",
            "Frame 205 of 744\n",
            "Loss: 2.8548669815063477\n",
            "Frame 206 of 744\n",
            "Loss: 2.7773211002349854\n",
            "Frame 207 of 744\n",
            "Loss: 2.8262598514556885\n",
            "Frame 208 of 744\n",
            "Loss: 2.734919548034668\n",
            "Frame 209 of 744\n",
            "Loss: 2.750823974609375\n",
            "Frame 210 of 744\n",
            "Loss: 2.7544028759002686\n",
            "Frame 211 of 744\n",
            "Loss: 2.724269151687622\n",
            "Frame 212 of 744\n",
            "Loss: 2.772211790084839\n",
            "Frame 213 of 744\n",
            "Loss: 2.804809331893921\n",
            "Frame 214 of 744\n",
            "Loss: 2.745211601257324\n",
            "Frame 215 of 744\n",
            "Loss: 2.760503053665161\n",
            "Frame 216 of 744\n",
            "Loss: 2.786064386367798\n",
            "Frame 217 of 744\n",
            "Loss: 2.7518246173858643\n",
            "Frame 218 of 744\n",
            "Loss: 2.800739288330078\n",
            "Frame 219 of 744\n",
            "Loss: 2.752866744995117\n",
            "Frame 220 of 744\n",
            "Loss: 2.7435200214385986\n",
            "Frame 221 of 744\n",
            "Loss: 2.8531925678253174\n",
            "Frame 222 of 744\n",
            "Loss: 2.7723400592803955\n",
            "Frame 223 of 744\n",
            "Loss: 2.7648661136627197\n",
            "Frame 224 of 744\n",
            "Loss: 2.736847162246704\n",
            "Frame 225 of 744\n",
            "Loss: 2.785885810852051\n",
            "Frame 226 of 744\n",
            "Loss: 2.7925100326538086\n",
            "Frame 227 of 744\n",
            "Loss: 2.782642364501953\n",
            "Frame 228 of 744\n",
            "Loss: 2.8082969188690186\n",
            "Frame 229 of 744\n",
            "Loss: 2.820531129837036\n",
            "Frame 230 of 744\n",
            "Loss: 2.775668144226074\n",
            "Frame 231 of 744\n",
            "Loss: 2.79086971282959\n",
            "Frame 232 of 744\n",
            "Loss: 2.7808239459991455\n",
            "Frame 233 of 744\n",
            "Loss: 2.7686688899993896\n",
            "Frame 234 of 744\n",
            "Loss: 2.860886573791504\n",
            "Frame 235 of 744\n",
            "Loss: 2.7284202575683594\n",
            "Frame 236 of 744\n",
            "Loss: 2.8080873489379883\n",
            "Frame 237 of 744\n",
            "Loss: 2.8224687576293945\n",
            "Frame 238 of 744\n",
            "Loss: 2.8456995487213135\n",
            "Frame 239 of 744\n",
            "Loss: 2.6989471912384033\n",
            "Frame 240 of 744\n",
            "Loss: 2.799067258834839\n",
            "Frame 241 of 744\n",
            "Loss: 2.8339126110076904\n",
            "Frame 242 of 744\n",
            "Loss: 2.7800838947296143\n",
            "Frame 243 of 744\n",
            "Loss: 2.7554819583892822\n",
            "Frame 244 of 744\n",
            "Loss: 2.7638704776763916\n",
            "Frame 245 of 744\n",
            "Loss: 2.769538640975952\n",
            "Frame 246 of 744\n",
            "Loss: 2.8125972747802734\n",
            "Frame 247 of 744\n",
            "Loss: 2.8439996242523193\n",
            "Training Loss: 2.7786881144969695\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.056451612903225805\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 6\n",
            "Frame 0 of 744\n",
            "Loss: 2.7879369258880615\n",
            "Frame 1 of 744\n",
            "Loss: 2.749964714050293\n",
            "Frame 2 of 744\n",
            "Loss: 2.7696714401245117\n",
            "Frame 3 of 744\n",
            "Loss: 2.7750072479248047\n",
            "Frame 4 of 744\n",
            "Loss: 2.7437431812286377\n",
            "Frame 5 of 744\n",
            "Loss: 2.827394485473633\n",
            "Frame 6 of 744\n",
            "Loss: 2.780306577682495\n",
            "Frame 7 of 744\n",
            "Loss: 2.806978225708008\n",
            "Frame 8 of 744\n",
            "Loss: 2.744267225265503\n",
            "Frame 9 of 744\n",
            "Loss: 2.836743116378784\n",
            "Frame 10 of 744\n",
            "Loss: 2.774554967880249\n",
            "Frame 11 of 744\n",
            "Loss: 2.801708221435547\n",
            "Frame 12 of 744\n",
            "Loss: 2.7508747577667236\n",
            "Frame 13 of 744\n",
            "Loss: 2.7548248767852783\n",
            "Frame 14 of 744\n",
            "Loss: 2.745868444442749\n",
            "Frame 15 of 744\n",
            "Loss: 2.78426194190979\n",
            "Frame 16 of 744\n",
            "Loss: 2.780531644821167\n",
            "Frame 17 of 744\n",
            "Loss: 2.752965211868286\n",
            "Frame 18 of 744\n",
            "Loss: 2.7909812927246094\n",
            "Frame 19 of 744\n",
            "Loss: 2.7411720752716064\n",
            "Frame 20 of 744\n",
            "Loss: 2.803327798843384\n",
            "Frame 21 of 744\n",
            "Loss: 2.7113027572631836\n",
            "Frame 22 of 744\n",
            "Loss: 2.7722723484039307\n",
            "Frame 23 of 744\n",
            "Loss: 2.806483030319214\n",
            "Frame 24 of 744\n",
            "Loss: 2.852921485900879\n",
            "Frame 25 of 744\n",
            "Loss: 2.7886009216308594\n",
            "Frame 26 of 744\n",
            "Loss: 2.697505235671997\n",
            "Frame 27 of 744\n",
            "Loss: 2.702092409133911\n",
            "Frame 28 of 744\n",
            "Loss: 2.7688148021698\n",
            "Frame 29 of 744\n",
            "Loss: 2.7751920223236084\n",
            "Frame 30 of 744\n",
            "Loss: 2.9006125926971436\n",
            "Frame 31 of 744\n",
            "Loss: 2.8033676147460938\n",
            "Frame 32 of 744\n",
            "Loss: 2.697686195373535\n",
            "Frame 33 of 744\n",
            "Loss: 2.836846113204956\n",
            "Frame 34 of 744\n",
            "Loss: 2.7035210132598877\n",
            "Frame 35 of 744\n",
            "Loss: 2.7915360927581787\n",
            "Frame 36 of 744\n",
            "Loss: 2.762312173843384\n",
            "Frame 37 of 744\n",
            "Loss: 2.7323532104492188\n",
            "Frame 38 of 744\n",
            "Loss: 2.731106996536255\n",
            "Frame 39 of 744\n",
            "Loss: 2.777228593826294\n",
            "Frame 40 of 744\n",
            "Loss: 2.7989299297332764\n",
            "Frame 41 of 744\n",
            "Loss: 2.749871015548706\n",
            "Frame 42 of 744\n",
            "Loss: 2.7954509258270264\n",
            "Frame 43 of 744\n",
            "Loss: 2.7565348148345947\n",
            "Frame 44 of 744\n",
            "Loss: 2.839938163757324\n",
            "Frame 45 of 744\n",
            "Loss: 2.817298650741577\n",
            "Frame 46 of 744\n",
            "Loss: 2.6862199306488037\n",
            "Frame 47 of 744\n",
            "Loss: 2.8021271228790283\n",
            "Frame 48 of 744\n",
            "Loss: 2.707190752029419\n",
            "Frame 49 of 744\n",
            "Loss: 2.782245635986328\n",
            "Frame 50 of 744\n",
            "Loss: 2.8462979793548584\n",
            "Frame 51 of 744\n",
            "Loss: 2.799253225326538\n",
            "Frame 52 of 744\n",
            "Loss: 2.736227035522461\n",
            "Frame 53 of 744\n",
            "Loss: 2.790268659591675\n",
            "Frame 54 of 744\n",
            "Loss: 2.7368431091308594\n",
            "Frame 55 of 744\n",
            "Loss: 2.7648041248321533\n",
            "Frame 56 of 744\n",
            "Loss: 2.768559217453003\n",
            "Frame 57 of 744\n",
            "Loss: 2.847001791000366\n",
            "Frame 58 of 744\n",
            "Loss: 2.7640647888183594\n",
            "Frame 59 of 744\n",
            "Loss: 2.734593629837036\n",
            "Frame 60 of 744\n",
            "Loss: 2.7010414600372314\n",
            "Frame 61 of 744\n",
            "Loss: 2.7585461139678955\n",
            "Frame 62 of 744\n",
            "Loss: 2.7873964309692383\n",
            "Frame 63 of 744\n",
            "Loss: 2.7275969982147217\n",
            "Frame 64 of 744\n",
            "Loss: 2.7868824005126953\n",
            "Frame 65 of 744\n",
            "Loss: 2.7764580249786377\n",
            "Frame 66 of 744\n",
            "Loss: 2.828394651412964\n",
            "Frame 67 of 744\n",
            "Loss: 2.80346417427063\n",
            "Frame 68 of 744\n",
            "Loss: 2.821746587753296\n",
            "Frame 69 of 744\n",
            "Loss: 2.803950071334839\n",
            "Frame 70 of 744\n",
            "Loss: 2.791135549545288\n",
            "Frame 71 of 744\n",
            "Loss: 2.750147819519043\n",
            "Frame 72 of 744\n",
            "Loss: 2.831273317337036\n",
            "Frame 73 of 744\n",
            "Loss: 2.830639600753784\n",
            "Frame 74 of 744\n",
            "Loss: 2.8098793029785156\n",
            "Frame 75 of 744\n",
            "Loss: 2.8204867839813232\n",
            "Frame 76 of 744\n",
            "Loss: 2.8194475173950195\n",
            "Frame 77 of 744\n",
            "Loss: 2.79486083984375\n",
            "Frame 78 of 744\n",
            "Loss: 2.727741003036499\n",
            "Frame 79 of 744\n",
            "Loss: 2.7569549083709717\n",
            "Frame 80 of 744\n",
            "Loss: 2.774759531021118\n",
            "Frame 81 of 744\n",
            "Loss: 2.7861413955688477\n",
            "Frame 82 of 744\n",
            "Loss: 2.7381088733673096\n",
            "Frame 83 of 744\n",
            "Loss: 2.7152252197265625\n",
            "Frame 84 of 744\n",
            "Loss: 2.7382452487945557\n",
            "Frame 85 of 744\n",
            "Loss: 2.8098247051239014\n",
            "Frame 86 of 744\n",
            "Loss: 2.7011783123016357\n",
            "Frame 87 of 744\n",
            "Loss: 2.8085145950317383\n",
            "Frame 88 of 744\n",
            "Loss: 2.704948663711548\n",
            "Frame 89 of 744\n",
            "Loss: 2.7426223754882812\n",
            "Frame 90 of 744\n",
            "Loss: 2.8290836811065674\n",
            "Frame 91 of 744\n",
            "Loss: 2.7978856563568115\n",
            "Frame 92 of 744\n",
            "Loss: 2.7470500469207764\n",
            "Frame 93 of 744\n",
            "Loss: 2.747849464416504\n",
            "Frame 94 of 744\n",
            "Loss: 2.7355759143829346\n",
            "Frame 95 of 744\n",
            "Loss: 2.7056190967559814\n",
            "Frame 96 of 744\n",
            "Loss: 2.780499219894409\n",
            "Frame 97 of 744\n",
            "Loss: 2.806152105331421\n",
            "Frame 98 of 744\n",
            "Loss: 2.8309853076934814\n",
            "Frame 99 of 744\n",
            "Loss: 2.7711517810821533\n",
            "Frame 100 of 744\n",
            "Loss: 2.7306880950927734\n",
            "Frame 101 of 744\n",
            "Loss: 2.774951696395874\n",
            "Frame 102 of 744\n",
            "Loss: 2.7102210521698\n",
            "Frame 103 of 744\n",
            "Loss: 2.782240867614746\n",
            "Frame 104 of 744\n",
            "Loss: 2.825579881668091\n",
            "Frame 105 of 744\n",
            "Loss: 2.8008081912994385\n",
            "Frame 106 of 744\n",
            "Loss: 2.884711980819702\n",
            "Frame 107 of 744\n",
            "Loss: 2.679088592529297\n",
            "Frame 108 of 744\n",
            "Loss: 2.846141815185547\n",
            "Frame 109 of 744\n",
            "Loss: 2.8248283863067627\n",
            "Frame 110 of 744\n",
            "Loss: 2.8299171924591064\n",
            "Frame 111 of 744\n",
            "Loss: 2.7242305278778076\n",
            "Frame 112 of 744\n",
            "Loss: 2.8773739337921143\n",
            "Frame 113 of 744\n",
            "Loss: 2.8064165115356445\n",
            "Frame 114 of 744\n",
            "Loss: 2.752422332763672\n",
            "Frame 115 of 744\n",
            "Loss: 2.74432635307312\n",
            "Frame 116 of 744\n",
            "Loss: 2.7204926013946533\n",
            "Frame 117 of 744\n",
            "Loss: 2.8896901607513428\n",
            "Frame 118 of 744\n",
            "Loss: 2.740750312805176\n",
            "Frame 119 of 744\n",
            "Loss: 2.705685615539551\n",
            "Frame 120 of 744\n",
            "Loss: 2.857389211654663\n",
            "Frame 121 of 744\n",
            "Loss: 2.774446487426758\n",
            "Frame 122 of 744\n",
            "Loss: 2.8516318798065186\n",
            "Frame 123 of 744\n",
            "Loss: 2.8115921020507812\n",
            "Frame 124 of 744\n",
            "Loss: 2.7695560455322266\n",
            "Frame 125 of 744\n",
            "Loss: 2.809725046157837\n",
            "Frame 126 of 744\n",
            "Loss: 2.6924169063568115\n",
            "Frame 127 of 744\n",
            "Loss: 2.7959766387939453\n",
            "Frame 128 of 744\n",
            "Loss: 2.7513139247894287\n",
            "Frame 129 of 744\n",
            "Loss: 2.7577579021453857\n",
            "Frame 130 of 744\n",
            "Loss: 2.8147993087768555\n",
            "Frame 131 of 744\n",
            "Loss: 2.7576684951782227\n",
            "Frame 132 of 744\n",
            "Loss: 2.800023317337036\n",
            "Frame 133 of 744\n",
            "Loss: 2.763716459274292\n",
            "Frame 134 of 744\n",
            "Loss: 2.777881622314453\n",
            "Frame 135 of 744\n",
            "Loss: 2.737175941467285\n",
            "Frame 136 of 744\n",
            "Loss: 2.818311929702759\n",
            "Frame 137 of 744\n",
            "Loss: 2.8179054260253906\n",
            "Frame 138 of 744\n",
            "Loss: 2.682584524154663\n",
            "Frame 139 of 744\n",
            "Loss: 2.692049980163574\n",
            "Frame 140 of 744\n",
            "Loss: 2.728388786315918\n",
            "Frame 141 of 744\n",
            "Loss: 2.872598886489868\n",
            "Frame 142 of 744\n",
            "Loss: 2.9043846130371094\n",
            "Frame 143 of 744\n",
            "Loss: 2.7999818325042725\n",
            "Frame 144 of 744\n",
            "Loss: 2.74462628364563\n",
            "Frame 145 of 744\n",
            "Loss: 2.833895444869995\n",
            "Frame 146 of 744\n",
            "Loss: 2.9254324436187744\n",
            "Frame 147 of 744\n",
            "Loss: 2.8112409114837646\n",
            "Frame 148 of 744\n",
            "Loss: 2.7283661365509033\n",
            "Frame 149 of 744\n",
            "Loss: 2.704131841659546\n",
            "Frame 150 of 744\n",
            "Loss: 2.7199466228485107\n",
            "Frame 151 of 744\n",
            "Loss: 2.7311770915985107\n",
            "Frame 152 of 744\n",
            "Loss: 2.8247640132904053\n",
            "Frame 153 of 744\n",
            "Loss: 2.8438150882720947\n",
            "Frame 154 of 744\n",
            "Loss: 2.8605518341064453\n",
            "Frame 155 of 744\n",
            "Loss: 2.7422192096710205\n",
            "Frame 156 of 744\n",
            "Loss: 2.787897825241089\n",
            "Frame 157 of 744\n",
            "Loss: 2.758326768875122\n",
            "Frame 158 of 744\n",
            "Loss: 2.7323646545410156\n",
            "Frame 159 of 744\n",
            "Loss: 2.834846258163452\n",
            "Frame 160 of 744\n",
            "Loss: 2.7323849201202393\n",
            "Frame 161 of 744\n",
            "Loss: 2.7971270084381104\n",
            "Frame 162 of 744\n",
            "Loss: 2.82535719871521\n",
            "Frame 163 of 744\n",
            "Loss: 2.766775131225586\n",
            "Frame 164 of 744\n",
            "Loss: 2.811589002609253\n",
            "Frame 165 of 744\n",
            "Loss: 2.7517173290252686\n",
            "Frame 166 of 744\n",
            "Loss: 2.805365800857544\n",
            "Frame 167 of 744\n",
            "Loss: 2.7254161834716797\n",
            "Frame 168 of 744\n",
            "Loss: 2.7759828567504883\n",
            "Frame 169 of 744\n",
            "Loss: 2.829327344894409\n",
            "Frame 170 of 744\n",
            "Loss: 2.831923246383667\n",
            "Frame 171 of 744\n",
            "Loss: 2.862421751022339\n",
            "Frame 172 of 744\n",
            "Loss: 2.8607871532440186\n",
            "Frame 173 of 744\n",
            "Loss: 2.760633707046509\n",
            "Frame 174 of 744\n",
            "Loss: 2.6955223083496094\n",
            "Frame 175 of 744\n",
            "Loss: 2.768101453781128\n",
            "Frame 176 of 744\n",
            "Loss: 2.739732027053833\n",
            "Frame 177 of 744\n",
            "Loss: 2.8083183765411377\n",
            "Frame 178 of 744\n",
            "Loss: 2.780795097351074\n",
            "Frame 179 of 744\n",
            "Loss: 2.8587722778320312\n",
            "Frame 180 of 744\n",
            "Loss: 2.7889983654022217\n",
            "Frame 181 of 744\n",
            "Loss: 2.8588192462921143\n",
            "Frame 182 of 744\n",
            "Loss: 2.8261072635650635\n",
            "Frame 183 of 744\n",
            "Loss: 2.772695541381836\n",
            "Frame 184 of 744\n",
            "Loss: 2.6977407932281494\n",
            "Frame 185 of 744\n",
            "Loss: 2.793447256088257\n",
            "Frame 186 of 744\n",
            "Loss: 2.7478694915771484\n",
            "Frame 187 of 744\n",
            "Loss: 2.74764084815979\n",
            "Frame 188 of 744\n",
            "Loss: 2.7718725204467773\n",
            "Frame 189 of 744\n",
            "Loss: 2.6977035999298096\n",
            "Frame 190 of 744\n",
            "Loss: 2.7345619201660156\n",
            "Frame 191 of 744\n",
            "Loss: 2.7072792053222656\n",
            "Frame 192 of 744\n",
            "Loss: 2.745624303817749\n",
            "Frame 193 of 744\n",
            "Loss: 2.7993221282958984\n",
            "Frame 194 of 744\n",
            "Loss: 2.780350923538208\n",
            "Frame 195 of 744\n",
            "Loss: 2.8255813121795654\n",
            "Frame 196 of 744\n",
            "Loss: 2.842064619064331\n",
            "Frame 197 of 744\n",
            "Loss: 2.727282762527466\n",
            "Frame 198 of 744\n",
            "Loss: 2.7965431213378906\n",
            "Frame 199 of 744\n",
            "Loss: 2.811426877975464\n",
            "Frame 200 of 744\n",
            "Loss: 2.872995615005493\n",
            "Frame 201 of 744\n",
            "Loss: 2.791271209716797\n",
            "Frame 202 of 744\n",
            "Loss: 2.772616147994995\n",
            "Frame 203 of 744\n",
            "Loss: 2.716372489929199\n",
            "Frame 204 of 744\n",
            "Loss: 2.8623626232147217\n",
            "Frame 205 of 744\n",
            "Loss: 2.7762110233306885\n",
            "Frame 206 of 744\n",
            "Loss: 2.7669928073883057\n",
            "Frame 207 of 744\n",
            "Loss: 2.8291842937469482\n",
            "Frame 208 of 744\n",
            "Loss: 2.794222593307495\n",
            "Frame 209 of 744\n",
            "Loss: 2.8650131225585938\n",
            "Frame 210 of 744\n",
            "Loss: 2.706476926803589\n",
            "Frame 211 of 744\n",
            "Loss: 2.795372724533081\n",
            "Frame 212 of 744\n",
            "Loss: 2.8148624897003174\n",
            "Frame 213 of 744\n",
            "Loss: 2.742349624633789\n",
            "Frame 214 of 744\n",
            "Loss: 2.771421194076538\n",
            "Frame 215 of 744\n",
            "Loss: 2.6957168579101562\n",
            "Frame 216 of 744\n",
            "Loss: 2.793684720993042\n",
            "Frame 217 of 744\n",
            "Loss: 2.7897491455078125\n",
            "Frame 218 of 744\n",
            "Loss: 2.788233518600464\n",
            "Frame 219 of 744\n",
            "Loss: 2.747709274291992\n",
            "Frame 220 of 744\n",
            "Loss: 2.76106333732605\n",
            "Frame 221 of 744\n",
            "Loss: 2.7697913646698\n",
            "Frame 222 of 744\n",
            "Loss: 2.7657277584075928\n",
            "Frame 223 of 744\n",
            "Loss: 2.7821309566497803\n",
            "Frame 224 of 744\n",
            "Loss: 2.8003032207489014\n",
            "Frame 225 of 744\n",
            "Loss: 2.7203760147094727\n",
            "Frame 226 of 744\n",
            "Loss: 2.754253387451172\n",
            "Frame 227 of 744\n",
            "Loss: 2.7989015579223633\n",
            "Frame 228 of 744\n",
            "Loss: 2.7749664783477783\n",
            "Frame 229 of 744\n",
            "Loss: 2.727627992630005\n",
            "Frame 230 of 744\n",
            "Loss: 2.742955446243286\n",
            "Frame 231 of 744\n",
            "Loss: 2.7761871814727783\n",
            "Frame 232 of 744\n",
            "Loss: 2.849883794784546\n",
            "Frame 233 of 744\n",
            "Loss: 2.762108564376831\n",
            "Frame 234 of 744\n",
            "Loss: 2.830080032348633\n",
            "Frame 235 of 744\n",
            "Loss: 2.764353036880493\n",
            "Frame 236 of 744\n",
            "Loss: 2.814661741256714\n",
            "Frame 237 of 744\n",
            "Loss: 2.8013103008270264\n",
            "Frame 238 of 744\n",
            "Loss: 2.8581974506378174\n",
            "Frame 239 of 744\n",
            "Loss: 2.7759971618652344\n",
            "Frame 240 of 744\n",
            "Loss: 2.726569890975952\n",
            "Frame 241 of 744\n",
            "Loss: 2.713454246520996\n",
            "Frame 242 of 744\n",
            "Loss: 2.835791826248169\n",
            "Frame 243 of 744\n",
            "Loss: 2.7296903133392334\n",
            "Frame 244 of 744\n",
            "Loss: 2.71142315864563\n",
            "Frame 245 of 744\n",
            "Loss: 2.8518011569976807\n",
            "Frame 246 of 744\n",
            "Loss: 2.773845672607422\n",
            "Frame 247 of 744\n",
            "Loss: 2.7621963024139404\n",
            "Training Loss: 2.7790359720107047\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.056451612903225805\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 7\n",
            "Frame 0 of 744\n",
            "Loss: 2.786370277404785\n",
            "Frame 1 of 744\n",
            "Loss: 2.8290891647338867\n",
            "Frame 2 of 744\n",
            "Loss: 2.737755537033081\n",
            "Frame 3 of 744\n",
            "Loss: 2.732830762863159\n",
            "Frame 4 of 744\n",
            "Loss: 2.8379383087158203\n",
            "Frame 5 of 744\n",
            "Loss: 2.7608346939086914\n",
            "Frame 6 of 744\n",
            "Loss: 2.7579987049102783\n",
            "Frame 7 of 744\n",
            "Loss: 2.7970972061157227\n",
            "Frame 8 of 744\n",
            "Loss: 2.8305861949920654\n",
            "Frame 9 of 744\n",
            "Loss: 2.7568299770355225\n",
            "Frame 10 of 744\n",
            "Loss: 2.772562265396118\n",
            "Frame 11 of 744\n",
            "Loss: 2.8283329010009766\n",
            "Frame 12 of 744\n",
            "Loss: 2.8235511779785156\n",
            "Frame 13 of 744\n",
            "Loss: 2.786053419113159\n",
            "Frame 14 of 744\n",
            "Loss: 2.863543748855591\n",
            "Frame 15 of 744\n",
            "Loss: 2.7760026454925537\n",
            "Frame 16 of 744\n",
            "Loss: 2.761988639831543\n",
            "Frame 17 of 744\n",
            "Loss: 2.7982730865478516\n",
            "Frame 18 of 744\n",
            "Loss: 2.736206293106079\n",
            "Frame 19 of 744\n",
            "Loss: 2.710103988647461\n",
            "Frame 20 of 744\n",
            "Loss: 2.804736375808716\n",
            "Frame 21 of 744\n",
            "Loss: 2.797457456588745\n",
            "Frame 22 of 744\n",
            "Loss: 2.8171281814575195\n",
            "Frame 23 of 744\n",
            "Loss: 2.805839776992798\n",
            "Frame 24 of 744\n",
            "Loss: 2.744295835494995\n",
            "Frame 25 of 744\n",
            "Loss: 2.7286176681518555\n",
            "Frame 26 of 744\n",
            "Loss: 2.800760269165039\n",
            "Frame 27 of 744\n",
            "Loss: 2.7952470779418945\n",
            "Frame 28 of 744\n",
            "Loss: 2.783964157104492\n",
            "Frame 29 of 744\n",
            "Loss: 2.742053270339966\n",
            "Frame 30 of 744\n",
            "Loss: 2.8498973846435547\n",
            "Frame 31 of 744\n",
            "Loss: 2.793156862258911\n",
            "Frame 32 of 744\n",
            "Loss: 2.789506673812866\n",
            "Frame 33 of 744\n",
            "Loss: 2.7370307445526123\n",
            "Frame 34 of 744\n",
            "Loss: 2.707155227661133\n",
            "Frame 35 of 744\n",
            "Loss: 2.698659896850586\n",
            "Frame 36 of 744\n",
            "Loss: 2.7518694400787354\n",
            "Frame 37 of 744\n",
            "Loss: 2.7847530841827393\n",
            "Frame 38 of 744\n",
            "Loss: 2.761040687561035\n",
            "Frame 39 of 744\n",
            "Loss: 2.8011934757232666\n",
            "Frame 40 of 744\n",
            "Loss: 2.790858030319214\n",
            "Frame 41 of 744\n",
            "Loss: 2.746082305908203\n",
            "Frame 42 of 744\n",
            "Loss: 2.768179178237915\n",
            "Frame 43 of 744\n",
            "Loss: 2.719362258911133\n",
            "Frame 44 of 744\n",
            "Loss: 2.745018720626831\n",
            "Frame 45 of 744\n",
            "Loss: 2.788604974746704\n",
            "Frame 46 of 744\n",
            "Loss: 2.7685821056365967\n",
            "Frame 47 of 744\n",
            "Loss: 2.725691080093384\n",
            "Frame 48 of 744\n",
            "Loss: 2.684054374694824\n",
            "Frame 49 of 744\n",
            "Loss: 2.7712485790252686\n",
            "Frame 50 of 744\n",
            "Loss: 2.8278744220733643\n",
            "Frame 51 of 744\n",
            "Loss: 2.774944305419922\n",
            "Frame 52 of 744\n",
            "Loss: 2.848942518234253\n",
            "Frame 53 of 744\n",
            "Loss: 2.7546818256378174\n",
            "Frame 54 of 744\n",
            "Loss: 2.7970283031463623\n",
            "Frame 55 of 744\n",
            "Loss: 2.804398536682129\n",
            "Frame 56 of 744\n",
            "Loss: 2.810523748397827\n",
            "Frame 57 of 744\n",
            "Loss: 2.837918996810913\n",
            "Frame 58 of 744\n",
            "Loss: 2.8324577808380127\n",
            "Frame 59 of 744\n",
            "Loss: 2.7737834453582764\n",
            "Frame 60 of 744\n",
            "Loss: 2.720649003982544\n",
            "Frame 61 of 744\n",
            "Loss: 2.8082275390625\n",
            "Frame 62 of 744\n",
            "Loss: 2.7733116149902344\n",
            "Frame 63 of 744\n",
            "Loss: 2.786038637161255\n",
            "Frame 64 of 744\n",
            "Loss: 2.774287462234497\n",
            "Frame 65 of 744\n",
            "Loss: 2.8358943462371826\n",
            "Frame 66 of 744\n",
            "Loss: 2.7279446125030518\n",
            "Frame 67 of 744\n",
            "Loss: 2.798156976699829\n",
            "Frame 68 of 744\n",
            "Loss: 2.789573907852173\n",
            "Frame 69 of 744\n",
            "Loss: 2.76438045501709\n",
            "Frame 70 of 744\n",
            "Loss: 2.7125635147094727\n",
            "Frame 71 of 744\n",
            "Loss: 2.7827138900756836\n",
            "Frame 72 of 744\n",
            "Loss: 2.77789044380188\n",
            "Frame 73 of 744\n",
            "Loss: 2.7694127559661865\n",
            "Frame 74 of 744\n",
            "Loss: 2.809290647506714\n",
            "Frame 75 of 744\n",
            "Loss: 2.800734758377075\n",
            "Frame 76 of 744\n",
            "Loss: 2.7745139598846436\n",
            "Frame 77 of 744\n",
            "Loss: 2.7792930603027344\n",
            "Frame 78 of 744\n",
            "Loss: 2.694227933883667\n",
            "Frame 79 of 744\n",
            "Loss: 2.8565475940704346\n",
            "Frame 80 of 744\n",
            "Loss: 2.8309576511383057\n",
            "Frame 81 of 744\n",
            "Loss: 2.805586576461792\n",
            "Frame 82 of 744\n",
            "Loss: 2.7935473918914795\n",
            "Frame 83 of 744\n",
            "Loss: 2.8065755367279053\n",
            "Frame 84 of 744\n",
            "Loss: 2.7800629138946533\n",
            "Frame 85 of 744\n",
            "Loss: 2.766443967819214\n",
            "Frame 86 of 744\n",
            "Loss: 2.7638165950775146\n",
            "Frame 87 of 744\n",
            "Loss: 2.8499648571014404\n",
            "Frame 88 of 744\n",
            "Loss: 2.809513807296753\n",
            "Frame 89 of 744\n",
            "Loss: 2.758262872695923\n",
            "Frame 90 of 744\n",
            "Loss: 2.792083740234375\n",
            "Frame 91 of 744\n",
            "Loss: 2.8065645694732666\n",
            "Frame 92 of 744\n",
            "Loss: 2.765535354614258\n",
            "Frame 93 of 744\n",
            "Loss: 2.73834228515625\n",
            "Frame 94 of 744\n",
            "Loss: 2.7816896438598633\n",
            "Frame 95 of 744\n",
            "Loss: 2.7257156372070312\n",
            "Frame 96 of 744\n",
            "Loss: 2.710153579711914\n",
            "Frame 97 of 744\n",
            "Loss: 2.7781383991241455\n",
            "Frame 98 of 744\n",
            "Loss: 2.7589521408081055\n",
            "Frame 99 of 744\n",
            "Loss: 2.7633235454559326\n",
            "Frame 100 of 744\n",
            "Loss: 2.8362109661102295\n",
            "Frame 101 of 744\n",
            "Loss: 2.73458194732666\n",
            "Frame 102 of 744\n",
            "Loss: 2.7879316806793213\n",
            "Frame 103 of 744\n",
            "Loss: 2.787649393081665\n",
            "Frame 104 of 744\n",
            "Loss: 2.7390830516815186\n",
            "Frame 105 of 744\n",
            "Loss: 2.7453830242156982\n",
            "Frame 106 of 744\n",
            "Loss: 2.7473719120025635\n",
            "Frame 107 of 744\n",
            "Loss: 2.821790933609009\n",
            "Frame 108 of 744\n",
            "Loss: 2.785956382751465\n",
            "Frame 109 of 744\n",
            "Loss: 2.759068250656128\n",
            "Frame 110 of 744\n",
            "Loss: 2.737157106399536\n",
            "Frame 111 of 744\n",
            "Loss: 2.761126756668091\n",
            "Frame 112 of 744\n",
            "Loss: 2.7882747650146484\n",
            "Frame 113 of 744\n",
            "Loss: 2.8229548931121826\n",
            "Frame 114 of 744\n",
            "Loss: 2.7053635120391846\n",
            "Frame 115 of 744\n",
            "Loss: 2.8025972843170166\n",
            "Frame 116 of 744\n",
            "Loss: 2.706026315689087\n",
            "Frame 117 of 744\n",
            "Loss: 2.759526014328003\n",
            "Frame 118 of 744\n",
            "Loss: 2.791330099105835\n",
            "Frame 119 of 744\n",
            "Loss: 2.7860660552978516\n",
            "Frame 120 of 744\n",
            "Loss: 2.764267683029175\n",
            "Frame 121 of 744\n",
            "Loss: 2.782670736312866\n",
            "Frame 122 of 744\n",
            "Loss: 2.7619686126708984\n",
            "Frame 123 of 744\n",
            "Loss: 2.7542784214019775\n",
            "Frame 124 of 744\n",
            "Loss: 2.7981326580047607\n",
            "Frame 125 of 744\n",
            "Loss: 2.703301191329956\n",
            "Frame 126 of 744\n",
            "Loss: 2.8379099369049072\n",
            "Frame 127 of 744\n",
            "Loss: 2.7065279483795166\n",
            "Frame 128 of 744\n",
            "Loss: 2.786928176879883\n",
            "Frame 129 of 744\n",
            "Loss: 2.7353885173797607\n",
            "Frame 130 of 744\n",
            "Loss: 2.7708959579467773\n",
            "Frame 131 of 744\n",
            "Loss: 2.7933387756347656\n",
            "Frame 132 of 744\n",
            "Loss: 2.7838144302368164\n",
            "Frame 133 of 744\n",
            "Loss: 2.8284857273101807\n",
            "Frame 134 of 744\n",
            "Loss: 2.8645200729370117\n",
            "Frame 135 of 744\n",
            "Loss: 2.823852777481079\n",
            "Frame 136 of 744\n",
            "Loss: 2.8124046325683594\n",
            "Frame 137 of 744\n",
            "Loss: 2.7876546382904053\n",
            "Frame 138 of 744\n",
            "Loss: 2.6894419193267822\n",
            "Frame 139 of 744\n",
            "Loss: 2.8136379718780518\n",
            "Frame 140 of 744\n",
            "Loss: 2.7558553218841553\n",
            "Frame 141 of 744\n",
            "Loss: 2.800048589706421\n",
            "Frame 142 of 744\n",
            "Loss: 2.7302873134613037\n",
            "Frame 143 of 744\n",
            "Loss: 2.7619991302490234\n",
            "Frame 144 of 744\n",
            "Loss: 2.7840449810028076\n",
            "Frame 145 of 744\n",
            "Loss: 2.7035114765167236\n",
            "Frame 146 of 744\n",
            "Loss: 2.7659194469451904\n",
            "Frame 147 of 744\n",
            "Loss: 2.819763422012329\n",
            "Frame 148 of 744\n",
            "Loss: 2.750627279281616\n",
            "Frame 149 of 744\n",
            "Loss: 2.7411587238311768\n",
            "Frame 150 of 744\n",
            "Loss: 2.709275007247925\n",
            "Frame 151 of 744\n",
            "Loss: 2.780385971069336\n",
            "Frame 152 of 744\n",
            "Loss: 2.760974168777466\n",
            "Frame 153 of 744\n",
            "Loss: 2.8012304306030273\n",
            "Frame 154 of 744\n",
            "Loss: 2.710021734237671\n",
            "Frame 155 of 744\n",
            "Loss: 2.7375290393829346\n",
            "Frame 156 of 744\n",
            "Loss: 2.7100555896759033\n",
            "Frame 157 of 744\n",
            "Loss: 2.713616371154785\n",
            "Frame 158 of 744\n",
            "Loss: 2.7586886882781982\n",
            "Frame 159 of 744\n",
            "Loss: 2.67673659324646\n",
            "Frame 160 of 744\n",
            "Loss: 2.749018907546997\n",
            "Frame 161 of 744\n",
            "Loss: 2.7188546657562256\n",
            "Frame 162 of 744\n",
            "Loss: 2.7017109394073486\n",
            "Frame 163 of 744\n",
            "Loss: 2.8106606006622314\n",
            "Frame 164 of 744\n",
            "Loss: 2.7777702808380127\n",
            "Frame 165 of 744\n",
            "Loss: 2.897268533706665\n",
            "Frame 166 of 744\n",
            "Loss: 2.788954973220825\n",
            "Frame 167 of 744\n",
            "Loss: 2.9398930072784424\n",
            "Frame 168 of 744\n",
            "Loss: 2.705441474914551\n",
            "Frame 169 of 744\n",
            "Loss: 2.7142693996429443\n",
            "Frame 170 of 744\n",
            "Loss: 2.870969772338867\n",
            "Frame 171 of 744\n",
            "Loss: 2.691777229309082\n",
            "Frame 172 of 744\n",
            "Loss: 2.661517858505249\n",
            "Frame 173 of 744\n",
            "Loss: 2.812175989151001\n",
            "Frame 174 of 744\n",
            "Loss: 2.7270326614379883\n",
            "Frame 175 of 744\n",
            "Loss: 2.6913585662841797\n",
            "Frame 176 of 744\n",
            "Loss: 2.786785125732422\n",
            "Frame 177 of 744\n",
            "Loss: 2.748807668685913\n",
            "Frame 178 of 744\n",
            "Loss: 2.749776840209961\n",
            "Frame 179 of 744\n",
            "Loss: 2.9303505420684814\n",
            "Frame 180 of 744\n",
            "Loss: 2.8399581909179688\n",
            "Frame 181 of 744\n",
            "Loss: 2.847456216812134\n",
            "Frame 182 of 744\n",
            "Loss: 2.765850067138672\n",
            "Frame 183 of 744\n",
            "Loss: 2.728135347366333\n",
            "Frame 184 of 744\n",
            "Loss: 2.756098508834839\n",
            "Frame 185 of 744\n",
            "Loss: 2.8218870162963867\n",
            "Frame 186 of 744\n",
            "Loss: 2.819695472717285\n",
            "Frame 187 of 744\n",
            "Loss: 2.7883875370025635\n",
            "Frame 188 of 744\n",
            "Loss: 2.7893428802490234\n",
            "Frame 189 of 744\n",
            "Loss: 2.8449790477752686\n",
            "Frame 190 of 744\n",
            "Loss: 2.896049737930298\n",
            "Frame 191 of 744\n",
            "Loss: 2.83615779876709\n",
            "Frame 192 of 744\n",
            "Loss: 2.763625383377075\n",
            "Frame 193 of 744\n",
            "Loss: 2.733250379562378\n",
            "Frame 194 of 744\n",
            "Loss: 2.924419641494751\n",
            "Frame 195 of 744\n",
            "Loss: 2.864131212234497\n",
            "Frame 196 of 744\n",
            "Loss: 2.730679512023926\n",
            "Frame 197 of 744\n",
            "Loss: 2.8056042194366455\n",
            "Frame 198 of 744\n",
            "Loss: 2.684830665588379\n",
            "Frame 199 of 744\n",
            "Loss: 2.7280797958374023\n",
            "Frame 200 of 744\n",
            "Loss: 2.7404897212982178\n",
            "Frame 201 of 744\n",
            "Loss: 2.8481178283691406\n",
            "Frame 202 of 744\n",
            "Loss: 2.790961980819702\n",
            "Frame 203 of 744\n",
            "Loss: 2.7435920238494873\n",
            "Frame 204 of 744\n",
            "Loss: 2.7952330112457275\n",
            "Frame 205 of 744\n",
            "Loss: 2.783959150314331\n",
            "Frame 206 of 744\n",
            "Loss: 2.854050874710083\n",
            "Frame 207 of 744\n",
            "Loss: 2.7098729610443115\n",
            "Frame 208 of 744\n",
            "Loss: 2.8071796894073486\n",
            "Frame 209 of 744\n",
            "Loss: 2.7180397510528564\n",
            "Frame 210 of 744\n",
            "Loss: 2.7343578338623047\n",
            "Frame 211 of 744\n",
            "Loss: 2.74731183052063\n",
            "Frame 212 of 744\n",
            "Loss: 2.7858784198760986\n",
            "Frame 213 of 744\n",
            "Loss: 2.7988383769989014\n",
            "Frame 214 of 744\n",
            "Loss: 2.8346545696258545\n",
            "Frame 215 of 744\n",
            "Loss: 2.877202033996582\n",
            "Frame 216 of 744\n",
            "Loss: 2.7807681560516357\n",
            "Frame 217 of 744\n",
            "Loss: 2.7826621532440186\n",
            "Frame 218 of 744\n",
            "Loss: 2.7953739166259766\n",
            "Frame 219 of 744\n",
            "Loss: 2.787412643432617\n",
            "Frame 220 of 744\n",
            "Loss: 2.7663135528564453\n",
            "Frame 221 of 744\n",
            "Loss: 2.869427442550659\n",
            "Frame 222 of 744\n",
            "Loss: 2.822284460067749\n",
            "Frame 223 of 744\n",
            "Loss: 2.7732861042022705\n",
            "Frame 224 of 744\n",
            "Loss: 2.7950923442840576\n",
            "Frame 225 of 744\n",
            "Loss: 2.7390902042388916\n",
            "Frame 226 of 744\n",
            "Loss: 2.771611452102661\n",
            "Frame 227 of 744\n",
            "Loss: 2.8923003673553467\n",
            "Frame 228 of 744\n",
            "Loss: 2.7429964542388916\n",
            "Frame 229 of 744\n",
            "Loss: 2.8777782917022705\n",
            "Frame 230 of 744\n",
            "Loss: 2.792433977127075\n",
            "Frame 231 of 744\n",
            "Loss: 2.7665328979492188\n",
            "Frame 232 of 744\n",
            "Loss: 2.714914321899414\n",
            "Frame 233 of 744\n",
            "Loss: 2.7303783893585205\n",
            "Frame 234 of 744\n",
            "Loss: 2.758216142654419\n",
            "Frame 235 of 744\n",
            "Loss: 2.7569596767425537\n",
            "Frame 236 of 744\n",
            "Loss: 2.860142946243286\n",
            "Frame 237 of 744\n",
            "Loss: 2.7502126693725586\n",
            "Frame 238 of 744\n",
            "Loss: 2.903838872909546\n",
            "Frame 239 of 744\n",
            "Loss: 2.7405710220336914\n",
            "Frame 240 of 744\n",
            "Loss: 2.734410285949707\n",
            "Frame 241 of 744\n",
            "Loss: 2.8000214099884033\n",
            "Frame 242 of 744\n",
            "Loss: 2.765655279159546\n",
            "Frame 243 of 744\n",
            "Loss: 2.825205087661743\n",
            "Frame 244 of 744\n",
            "Loss: 2.7747795581817627\n",
            "Frame 245 of 744\n",
            "Loss: 2.8289947509765625\n",
            "Frame 246 of 744\n",
            "Loss: 2.841878890991211\n",
            "Frame 247 of 744\n",
            "Loss: 2.7765066623687744\n",
            "Training Loss: 2.778938857778426\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.05376344086021505\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 8\n",
            "Frame 0 of 744\n",
            "Loss: 2.7373836040496826\n",
            "Frame 1 of 744\n",
            "Loss: 2.6812572479248047\n",
            "Frame 2 of 744\n",
            "Loss: 2.78022837638855\n",
            "Frame 3 of 744\n",
            "Loss: 2.8232667446136475\n",
            "Frame 4 of 744\n",
            "Loss: 2.7484524250030518\n",
            "Frame 5 of 744\n",
            "Loss: 2.658982038497925\n",
            "Frame 6 of 744\n",
            "Loss: 2.7700815200805664\n",
            "Frame 7 of 744\n",
            "Loss: 2.767322301864624\n",
            "Frame 8 of 744\n",
            "Loss: 2.780031204223633\n",
            "Frame 9 of 744\n",
            "Loss: 2.7210187911987305\n",
            "Frame 10 of 744\n",
            "Loss: 2.761042356491089\n",
            "Frame 11 of 744\n",
            "Loss: 2.7329180240631104\n",
            "Frame 12 of 744\n",
            "Loss: 2.8508923053741455\n",
            "Frame 13 of 744\n",
            "Loss: 2.769012451171875\n",
            "Frame 14 of 744\n",
            "Loss: 2.7852089405059814\n",
            "Frame 15 of 744\n",
            "Loss: 2.818910598754883\n",
            "Frame 16 of 744\n",
            "Loss: 2.720897912979126\n",
            "Frame 17 of 744\n",
            "Loss: 2.744218111038208\n",
            "Frame 18 of 744\n",
            "Loss: 2.759967803955078\n",
            "Frame 19 of 744\n",
            "Loss: 2.76901912689209\n",
            "Frame 20 of 744\n",
            "Loss: 2.8708114624023438\n",
            "Frame 21 of 744\n",
            "Loss: 2.8110320568084717\n",
            "Frame 22 of 744\n",
            "Loss: 2.7682697772979736\n",
            "Frame 23 of 744\n",
            "Loss: 2.6964104175567627\n",
            "Frame 24 of 744\n",
            "Loss: 2.7299082279205322\n",
            "Frame 25 of 744\n",
            "Loss: 2.7206971645355225\n",
            "Frame 26 of 744\n",
            "Loss: 2.8077399730682373\n",
            "Frame 27 of 744\n",
            "Loss: 2.7361114025115967\n",
            "Frame 28 of 744\n",
            "Loss: 2.7612178325653076\n",
            "Frame 29 of 744\n",
            "Loss: 2.799739122390747\n",
            "Frame 30 of 744\n",
            "Loss: 2.7217094898223877\n",
            "Frame 31 of 744\n",
            "Loss: 2.706057548522949\n",
            "Frame 32 of 744\n",
            "Loss: 2.7499148845672607\n",
            "Frame 33 of 744\n",
            "Loss: 2.732130765914917\n",
            "Frame 34 of 744\n",
            "Loss: 2.640246629714966\n",
            "Frame 35 of 744\n",
            "Loss: 2.8647773265838623\n",
            "Frame 36 of 744\n",
            "Loss: 2.8915834426879883\n",
            "Frame 37 of 744\n",
            "Loss: 2.7882697582244873\n",
            "Frame 38 of 744\n",
            "Loss: 2.806690216064453\n",
            "Frame 39 of 744\n",
            "Loss: 2.732609748840332\n",
            "Frame 40 of 744\n",
            "Loss: 2.8330307006835938\n",
            "Frame 41 of 744\n",
            "Loss: 2.7715747356414795\n",
            "Frame 42 of 744\n",
            "Loss: 2.7285478115081787\n",
            "Frame 43 of 744\n",
            "Loss: 2.821143865585327\n",
            "Frame 44 of 744\n",
            "Loss: 2.8170671463012695\n",
            "Frame 45 of 744\n",
            "Loss: 2.752107620239258\n",
            "Frame 46 of 744\n",
            "Loss: 2.7713959217071533\n",
            "Frame 47 of 744\n",
            "Loss: 2.7298736572265625\n",
            "Frame 48 of 744\n",
            "Loss: 2.8133420944213867\n",
            "Frame 49 of 744\n",
            "Loss: 2.714067220687866\n",
            "Frame 50 of 744\n",
            "Loss: 2.6470229625701904\n",
            "Frame 51 of 744\n",
            "Loss: 2.749664068222046\n",
            "Frame 52 of 744\n",
            "Loss: 2.7478950023651123\n",
            "Frame 53 of 744\n",
            "Loss: 2.7143781185150146\n",
            "Frame 54 of 744\n",
            "Loss: 2.711345911026001\n",
            "Frame 55 of 744\n",
            "Loss: 2.784942626953125\n",
            "Frame 56 of 744\n",
            "Loss: 2.7926692962646484\n",
            "Frame 57 of 744\n",
            "Loss: 2.8437411785125732\n",
            "Frame 58 of 744\n",
            "Loss: 2.75907826423645\n",
            "Frame 59 of 744\n",
            "Loss: 2.644561767578125\n",
            "Frame 60 of 744\n",
            "Loss: 2.749937057495117\n",
            "Frame 61 of 744\n",
            "Loss: 2.7440168857574463\n",
            "Frame 62 of 744\n",
            "Loss: 2.726644277572632\n",
            "Frame 63 of 744\n",
            "Loss: 2.8013064861297607\n",
            "Frame 64 of 744\n",
            "Loss: 2.7803313732147217\n",
            "Frame 65 of 744\n",
            "Loss: 2.765920877456665\n",
            "Frame 66 of 744\n",
            "Loss: 2.7604830265045166\n",
            "Frame 67 of 744\n",
            "Loss: 2.842742681503296\n",
            "Frame 68 of 744\n",
            "Loss: 2.8116095066070557\n",
            "Frame 69 of 744\n",
            "Loss: 2.782052993774414\n",
            "Frame 70 of 744\n",
            "Loss: 2.8396880626678467\n",
            "Frame 71 of 744\n",
            "Loss: 2.7713406085968018\n",
            "Frame 72 of 744\n",
            "Loss: 2.7650201320648193\n",
            "Frame 73 of 744\n",
            "Loss: 2.6957712173461914\n",
            "Frame 74 of 744\n",
            "Loss: 2.7750794887542725\n",
            "Frame 75 of 744\n",
            "Loss: 2.7997732162475586\n",
            "Frame 76 of 744\n",
            "Loss: 2.796649694442749\n",
            "Frame 77 of 744\n",
            "Loss: 2.715174913406372\n",
            "Frame 78 of 744\n",
            "Loss: 2.820699453353882\n",
            "Frame 79 of 744\n",
            "Loss: 2.5771703720092773\n",
            "Frame 80 of 744\n",
            "Loss: 2.8747074604034424\n",
            "Frame 81 of 744\n",
            "Loss: 2.7663586139678955\n",
            "Frame 82 of 744\n",
            "Loss: 2.780127763748169\n",
            "Frame 83 of 744\n",
            "Loss: 2.7735445499420166\n",
            "Frame 84 of 744\n",
            "Loss: 2.718167543411255\n",
            "Frame 85 of 744\n",
            "Loss: 2.7872650623321533\n",
            "Frame 86 of 744\n",
            "Loss: 2.7868642807006836\n",
            "Frame 87 of 744\n",
            "Loss: 2.8649237155914307\n",
            "Frame 88 of 744\n",
            "Loss: 2.7453832626342773\n",
            "Frame 89 of 744\n",
            "Loss: 2.7588043212890625\n",
            "Frame 90 of 744\n",
            "Loss: 2.8557631969451904\n",
            "Frame 91 of 744\n",
            "Loss: 2.679457664489746\n",
            "Frame 92 of 744\n",
            "Loss: 2.7751293182373047\n",
            "Frame 93 of 744\n",
            "Loss: 2.8260507583618164\n",
            "Frame 94 of 744\n",
            "Loss: 2.8668136596679688\n",
            "Frame 95 of 744\n",
            "Loss: 2.88189959526062\n",
            "Frame 96 of 744\n",
            "Loss: 2.783689498901367\n",
            "Frame 97 of 744\n",
            "Loss: 2.6778504848480225\n",
            "Frame 98 of 744\n",
            "Loss: 2.6862223148345947\n",
            "Frame 99 of 744\n",
            "Loss: 2.740727663040161\n",
            "Frame 100 of 744\n",
            "Loss: 2.811871290206909\n",
            "Frame 101 of 744\n",
            "Loss: 2.6875665187835693\n",
            "Frame 102 of 744\n",
            "Loss: 2.881732225418091\n",
            "Frame 103 of 744\n",
            "Loss: 2.8143370151519775\n",
            "Frame 104 of 744\n",
            "Loss: 2.6918065547943115\n",
            "Frame 105 of 744\n",
            "Loss: 2.945087432861328\n",
            "Frame 106 of 744\n",
            "Loss: 2.828181266784668\n",
            "Frame 107 of 744\n",
            "Loss: 2.805011749267578\n",
            "Frame 108 of 744\n",
            "Loss: 2.809799909591675\n",
            "Frame 109 of 744\n",
            "Loss: 2.737320899963379\n",
            "Frame 110 of 744\n",
            "Loss: 2.7564334869384766\n",
            "Frame 111 of 744\n",
            "Loss: 2.7615692615509033\n",
            "Frame 112 of 744\n",
            "Loss: 2.856394052505493\n",
            "Frame 113 of 744\n",
            "Loss: 2.6469576358795166\n",
            "Frame 114 of 744\n",
            "Loss: 2.7634379863739014\n",
            "Frame 115 of 744\n",
            "Loss: 2.833003282546997\n",
            "Frame 116 of 744\n",
            "Loss: 3.007266044616699\n",
            "Frame 117 of 744\n",
            "Loss: 2.717912435531616\n",
            "Frame 118 of 744\n",
            "Loss: 2.832139730453491\n",
            "Frame 119 of 744\n",
            "Loss: 2.7383272647857666\n",
            "Frame 120 of 744\n",
            "Loss: 2.8094236850738525\n",
            "Frame 121 of 744\n",
            "Loss: 2.7011337280273438\n",
            "Frame 122 of 744\n",
            "Loss: 2.8126800060272217\n",
            "Frame 123 of 744\n",
            "Loss: 2.7748801708221436\n",
            "Frame 124 of 744\n",
            "Loss: 2.71720290184021\n",
            "Frame 125 of 744\n",
            "Loss: 2.7733078002929688\n",
            "Frame 126 of 744\n",
            "Loss: 2.8872973918914795\n",
            "Frame 127 of 744\n",
            "Loss: 2.754889726638794\n",
            "Frame 128 of 744\n",
            "Loss: 2.759814500808716\n",
            "Frame 129 of 744\n",
            "Loss: 2.8097293376922607\n",
            "Frame 130 of 744\n",
            "Loss: 2.823206901550293\n",
            "Frame 131 of 744\n",
            "Loss: 2.7746808528900146\n",
            "Frame 132 of 744\n",
            "Loss: 2.77535343170166\n",
            "Frame 133 of 744\n",
            "Loss: 2.781118392944336\n",
            "Frame 134 of 744\n",
            "Loss: 2.8411285877227783\n",
            "Frame 135 of 744\n",
            "Loss: 2.8497378826141357\n",
            "Frame 136 of 744\n",
            "Loss: 2.7268311977386475\n",
            "Frame 137 of 744\n",
            "Loss: 2.8312606811523438\n",
            "Frame 138 of 744\n",
            "Loss: 2.7026119232177734\n",
            "Frame 139 of 744\n",
            "Loss: 2.875903844833374\n",
            "Frame 140 of 744\n",
            "Loss: 2.7125942707061768\n",
            "Frame 141 of 744\n",
            "Loss: 2.8901774883270264\n",
            "Frame 142 of 744\n",
            "Loss: 2.813671827316284\n",
            "Frame 143 of 744\n",
            "Loss: 2.722010374069214\n",
            "Frame 144 of 744\n",
            "Loss: 2.7362945079803467\n",
            "Frame 145 of 744\n",
            "Loss: 2.7706050872802734\n",
            "Frame 146 of 744\n",
            "Loss: 2.7696731090545654\n",
            "Frame 147 of 744\n",
            "Loss: 2.8758814334869385\n",
            "Frame 148 of 744\n",
            "Loss: 2.81719708442688\n",
            "Frame 149 of 744\n",
            "Loss: 2.8281383514404297\n",
            "Frame 150 of 744\n",
            "Loss: 2.7796125411987305\n",
            "Frame 151 of 744\n",
            "Loss: 2.7190961837768555\n",
            "Frame 152 of 744\n",
            "Loss: 2.8302040100097656\n",
            "Frame 153 of 744\n",
            "Loss: 2.8102786540985107\n",
            "Frame 154 of 744\n",
            "Loss: 2.7290573120117188\n",
            "Frame 155 of 744\n",
            "Loss: 2.7549736499786377\n",
            "Frame 156 of 744\n",
            "Loss: 2.6927621364593506\n",
            "Frame 157 of 744\n",
            "Loss: 2.770625114440918\n",
            "Frame 158 of 744\n",
            "Loss: 2.8469135761260986\n",
            "Frame 159 of 744\n",
            "Loss: 2.821984052658081\n",
            "Frame 160 of 744\n",
            "Loss: 2.791130304336548\n",
            "Frame 161 of 744\n",
            "Loss: 2.8593523502349854\n",
            "Frame 162 of 744\n",
            "Loss: 2.825784921646118\n",
            "Frame 163 of 744\n",
            "Loss: 2.8199822902679443\n",
            "Frame 164 of 744\n",
            "Loss: 2.7415847778320312\n",
            "Frame 165 of 744\n",
            "Loss: 2.7582740783691406\n",
            "Frame 166 of 744\n",
            "Loss: 2.7738542556762695\n",
            "Frame 167 of 744\n",
            "Loss: 2.8008830547332764\n",
            "Frame 168 of 744\n",
            "Loss: 2.73388934135437\n",
            "Frame 169 of 744\n",
            "Loss: 2.813021421432495\n",
            "Frame 170 of 744\n",
            "Loss: 2.764777421951294\n",
            "Frame 171 of 744\n",
            "Loss: 2.7717161178588867\n",
            "Frame 172 of 744\n",
            "Loss: 2.8859946727752686\n",
            "Frame 173 of 744\n",
            "Loss: 2.780217409133911\n",
            "Frame 174 of 744\n",
            "Loss: 2.754239082336426\n",
            "Frame 175 of 744\n",
            "Loss: 2.8134453296661377\n",
            "Frame 176 of 744\n",
            "Loss: 2.823589324951172\n",
            "Frame 177 of 744\n",
            "Loss: 2.7694091796875\n",
            "Frame 178 of 744\n",
            "Loss: 2.781057596206665\n",
            "Frame 179 of 744\n",
            "Loss: 2.8010456562042236\n",
            "Frame 180 of 744\n",
            "Loss: 2.7241899967193604\n",
            "Frame 181 of 744\n",
            "Loss: 2.7321975231170654\n",
            "Frame 182 of 744\n",
            "Loss: 2.879260301589966\n",
            "Frame 183 of 744\n",
            "Loss: 2.7470858097076416\n",
            "Frame 184 of 744\n",
            "Loss: 2.796844482421875\n",
            "Frame 185 of 744\n",
            "Loss: 2.772479295730591\n",
            "Frame 186 of 744\n",
            "Loss: 2.7709648609161377\n",
            "Frame 187 of 744\n",
            "Loss: 2.809647798538208\n",
            "Frame 188 of 744\n",
            "Loss: 2.8954250812530518\n",
            "Frame 189 of 744\n",
            "Loss: 2.753157615661621\n",
            "Frame 190 of 744\n",
            "Loss: 2.8293075561523438\n",
            "Frame 191 of 744\n",
            "Loss: 2.7774715423583984\n",
            "Frame 192 of 744\n",
            "Loss: 2.7688519954681396\n",
            "Frame 193 of 744\n",
            "Loss: 2.7500457763671875\n",
            "Frame 194 of 744\n",
            "Loss: 2.8464696407318115\n",
            "Frame 195 of 744\n",
            "Loss: 2.862476348876953\n",
            "Frame 196 of 744\n",
            "Loss: 2.8157217502593994\n",
            "Frame 197 of 744\n",
            "Loss: 2.77355694770813\n",
            "Frame 198 of 744\n",
            "Loss: 2.689458131790161\n",
            "Frame 199 of 744\n",
            "Loss: 2.761350631713867\n",
            "Frame 200 of 744\n",
            "Loss: 2.7530603408813477\n",
            "Frame 201 of 744\n",
            "Loss: 2.8818538188934326\n",
            "Frame 202 of 744\n",
            "Loss: 2.7684104442596436\n",
            "Frame 203 of 744\n",
            "Loss: 2.75915789604187\n",
            "Frame 204 of 744\n",
            "Loss: 2.7900655269622803\n",
            "Frame 205 of 744\n",
            "Loss: 2.9074888229370117\n",
            "Frame 206 of 744\n",
            "Loss: 2.826559066772461\n",
            "Frame 207 of 744\n",
            "Loss: 2.761007308959961\n",
            "Frame 208 of 744\n",
            "Loss: 2.7823867797851562\n",
            "Frame 209 of 744\n",
            "Loss: 2.7535903453826904\n",
            "Frame 210 of 744\n",
            "Loss: 2.763514280319214\n",
            "Frame 211 of 744\n",
            "Loss: 2.8107969760894775\n",
            "Frame 212 of 744\n",
            "Loss: 2.778865098953247\n",
            "Frame 213 of 744\n",
            "Loss: 2.786646604537964\n",
            "Frame 214 of 744\n",
            "Loss: 2.7373647689819336\n",
            "Frame 215 of 744\n",
            "Loss: 2.7060649394989014\n",
            "Frame 216 of 744\n",
            "Loss: 2.853928327560425\n",
            "Frame 217 of 744\n",
            "Loss: 2.7844507694244385\n",
            "Frame 218 of 744\n",
            "Loss: 2.7480621337890625\n",
            "Frame 219 of 744\n",
            "Loss: 2.7821667194366455\n",
            "Frame 220 of 744\n",
            "Loss: 2.746556043624878\n",
            "Frame 221 of 744\n",
            "Loss: 2.764275312423706\n",
            "Frame 222 of 744\n",
            "Loss: 2.772745370864868\n",
            "Frame 223 of 744\n",
            "Loss: 2.825141191482544\n",
            "Frame 224 of 744\n",
            "Loss: 2.7655627727508545\n",
            "Frame 225 of 744\n",
            "Loss: 2.852550745010376\n",
            "Frame 226 of 744\n",
            "Loss: 2.762808084487915\n",
            "Frame 227 of 744\n",
            "Loss: 2.800355911254883\n",
            "Frame 228 of 744\n",
            "Loss: 2.7536613941192627\n",
            "Frame 229 of 744\n",
            "Loss: 2.7807843685150146\n",
            "Frame 230 of 744\n",
            "Loss: 2.7264416217803955\n",
            "Frame 231 of 744\n",
            "Loss: 2.7483108043670654\n",
            "Frame 232 of 744\n",
            "Loss: 2.7545835971832275\n",
            "Frame 233 of 744\n",
            "Loss: 2.8090076446533203\n",
            "Frame 234 of 744\n",
            "Loss: 2.8222227096557617\n",
            "Frame 235 of 744\n",
            "Loss: 2.8110649585723877\n",
            "Frame 236 of 744\n",
            "Loss: 2.7267415523529053\n",
            "Frame 237 of 744\n",
            "Loss: 2.7640740871429443\n",
            "Frame 238 of 744\n",
            "Loss: 2.8242523670196533\n",
            "Frame 239 of 744\n",
            "Loss: 2.846637725830078\n",
            "Frame 240 of 744\n",
            "Loss: 2.825228452682495\n",
            "Frame 241 of 744\n",
            "Loss: 2.7235119342803955\n",
            "Frame 242 of 744\n",
            "Loss: 2.828172445297241\n",
            "Frame 243 of 744\n",
            "Loss: 2.777324676513672\n",
            "Frame 244 of 744\n",
            "Loss: 2.8164901733398438\n",
            "Frame 245 of 744\n",
            "Loss: 2.8041293621063232\n",
            "Frame 246 of 744\n",
            "Loss: 2.7957465648651123\n",
            "Frame 247 of 744\n",
            "Loss: 2.817211389541626\n",
            "Training Loss: 2.7798991847422814\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.06720430107526881\n",
            "Test Accuracy: 0.046296296296296294\n",
            "Epoch: 9\n",
            "Frame 0 of 744\n",
            "Loss: 2.7545154094696045\n",
            "Frame 1 of 744\n",
            "Loss: 2.8124115467071533\n",
            "Frame 2 of 744\n",
            "Loss: 2.7962024211883545\n",
            "Frame 3 of 744\n",
            "Loss: 2.753000259399414\n",
            "Frame 4 of 744\n",
            "Loss: 2.761075019836426\n",
            "Frame 5 of 744\n",
            "Loss: 2.8074092864990234\n",
            "Frame 6 of 744\n",
            "Loss: 2.7517712116241455\n",
            "Frame 7 of 744\n",
            "Loss: 2.778381586074829\n",
            "Frame 8 of 744\n",
            "Loss: 2.823833465576172\n",
            "Frame 9 of 744\n",
            "Loss: 2.7687885761260986\n",
            "Frame 10 of 744\n",
            "Loss: 2.795687437057495\n",
            "Frame 11 of 744\n",
            "Loss: 2.7297041416168213\n",
            "Frame 12 of 744\n",
            "Loss: 2.7793281078338623\n",
            "Frame 13 of 744\n",
            "Loss: 2.7691681385040283\n",
            "Frame 14 of 744\n",
            "Loss: 2.757065534591675\n",
            "Frame 15 of 744\n",
            "Loss: 2.739182233810425\n",
            "Frame 16 of 744\n",
            "Loss: 2.781285524368286\n",
            "Frame 17 of 744\n",
            "Loss: 2.7445411682128906\n",
            "Frame 18 of 744\n",
            "Loss: 2.7568442821502686\n",
            "Frame 19 of 744\n",
            "Loss: 2.755136251449585\n",
            "Frame 20 of 744\n",
            "Loss: 2.784741163253784\n",
            "Frame 21 of 744\n",
            "Loss: 2.800128936767578\n",
            "Frame 22 of 744\n",
            "Loss: 2.7437641620635986\n",
            "Frame 23 of 744\n",
            "Loss: 2.8207528591156006\n",
            "Frame 24 of 744\n",
            "Loss: 2.8016326427459717\n",
            "Frame 25 of 744\n",
            "Loss: 2.7545955181121826\n",
            "Frame 26 of 744\n",
            "Loss: 2.78991436958313\n",
            "Frame 27 of 744\n",
            "Loss: 2.780705690383911\n",
            "Frame 28 of 744\n",
            "Loss: 2.759176254272461\n",
            "Frame 29 of 744\n",
            "Loss: 2.7349488735198975\n",
            "Frame 30 of 744\n",
            "Loss: 2.7254762649536133\n",
            "Frame 31 of 744\n",
            "Loss: 2.7872726917266846\n",
            "Frame 32 of 744\n",
            "Loss: 2.802427291870117\n",
            "Frame 33 of 744\n",
            "Loss: 2.737421751022339\n",
            "Frame 34 of 744\n",
            "Loss: 2.838155746459961\n",
            "Frame 35 of 744\n",
            "Loss: 2.7615158557891846\n",
            "Frame 36 of 744\n",
            "Loss: 2.81284499168396\n",
            "Frame 37 of 744\n",
            "Loss: 2.7280614376068115\n",
            "Frame 38 of 744\n",
            "Loss: 2.800158739089966\n",
            "Frame 39 of 744\n",
            "Loss: 2.730724334716797\n",
            "Frame 40 of 744\n",
            "Loss: 2.8313074111938477\n",
            "Frame 41 of 744\n",
            "Loss: 2.8437652587890625\n",
            "Frame 42 of 744\n",
            "Loss: 2.8500816822052\n",
            "Frame 43 of 744\n",
            "Loss: 2.7747514247894287\n",
            "Frame 44 of 744\n",
            "Loss: 2.7772910594940186\n",
            "Frame 45 of 744\n",
            "Loss: 2.7584826946258545\n",
            "Frame 46 of 744\n",
            "Loss: 2.8364763259887695\n",
            "Frame 47 of 744\n",
            "Loss: 2.737619161605835\n",
            "Frame 48 of 744\n",
            "Loss: 2.8102056980133057\n",
            "Frame 49 of 744\n",
            "Loss: 2.7702598571777344\n",
            "Frame 50 of 744\n",
            "Loss: 2.754547119140625\n",
            "Frame 51 of 744\n",
            "Loss: 2.7220499515533447\n",
            "Frame 52 of 744\n",
            "Loss: 2.7387800216674805\n",
            "Frame 53 of 744\n",
            "Loss: 2.7731504440307617\n",
            "Frame 54 of 744\n",
            "Loss: 2.801406145095825\n",
            "Frame 55 of 744\n",
            "Loss: 2.785654306411743\n",
            "Frame 56 of 744\n",
            "Loss: 2.7219364643096924\n",
            "Frame 57 of 744\n",
            "Loss: 2.8091375827789307\n",
            "Frame 58 of 744\n",
            "Loss: 2.7555675506591797\n",
            "Frame 59 of 744\n",
            "Loss: 2.7609927654266357\n",
            "Frame 60 of 744\n",
            "Loss: 2.765958547592163\n",
            "Frame 61 of 744\n",
            "Loss: 2.852511405944824\n",
            "Frame 62 of 744\n",
            "Loss: 2.80766224861145\n",
            "Frame 63 of 744\n",
            "Loss: 2.7752084732055664\n",
            "Frame 64 of 744\n",
            "Loss: 2.7538063526153564\n",
            "Frame 65 of 744\n",
            "Loss: 2.789240598678589\n",
            "Frame 66 of 744\n",
            "Loss: 2.7367875576019287\n",
            "Frame 67 of 744\n",
            "Loss: 2.811774253845215\n",
            "Frame 68 of 744\n",
            "Loss: 2.769263982772827\n",
            "Frame 69 of 744\n",
            "Loss: 2.7647361755371094\n",
            "Frame 70 of 744\n",
            "Loss: 2.7669341564178467\n",
            "Frame 71 of 744\n",
            "Loss: 2.75205397605896\n",
            "Frame 72 of 744\n",
            "Loss: 2.758692502975464\n",
            "Frame 73 of 744\n",
            "Loss: 2.7251927852630615\n",
            "Frame 74 of 744\n",
            "Loss: 2.790093183517456\n",
            "Frame 75 of 744\n",
            "Loss: 2.7353270053863525\n",
            "Frame 76 of 744\n",
            "Loss: 2.738856554031372\n",
            "Frame 77 of 744\n",
            "Loss: 2.782579183578491\n",
            "Frame 78 of 744\n",
            "Loss: 2.731449842453003\n",
            "Frame 79 of 744\n",
            "Loss: 2.71028733253479\n",
            "Frame 80 of 744\n",
            "Loss: 2.751652956008911\n",
            "Frame 81 of 744\n",
            "Loss: 2.860980749130249\n",
            "Frame 82 of 744\n",
            "Loss: 2.744549512863159\n",
            "Frame 83 of 744\n",
            "Loss: 2.863352060317993\n",
            "Frame 84 of 744\n",
            "Loss: 2.7267417907714844\n",
            "Frame 85 of 744\n",
            "Loss: 2.7938759326934814\n",
            "Frame 86 of 744\n",
            "Loss: 2.8051764965057373\n",
            "Frame 87 of 744\n",
            "Loss: 2.8478825092315674\n",
            "Frame 88 of 744\n",
            "Loss: 2.7739810943603516\n",
            "Frame 89 of 744\n",
            "Loss: 2.7274487018585205\n",
            "Frame 90 of 744\n",
            "Loss: 2.716973304748535\n",
            "Frame 91 of 744\n",
            "Loss: 2.7446534633636475\n",
            "Frame 92 of 744\n",
            "Loss: 2.727216958999634\n",
            "Frame 93 of 744\n",
            "Loss: 2.8384387493133545\n",
            "Frame 94 of 744\n",
            "Loss: 2.83636474609375\n",
            "Frame 95 of 744\n",
            "Loss: 2.765583038330078\n",
            "Frame 96 of 744\n",
            "Loss: 2.7664458751678467\n",
            "Frame 97 of 744\n",
            "Loss: 2.878399133682251\n",
            "Frame 98 of 744\n",
            "Loss: 2.7437355518341064\n",
            "Frame 99 of 744\n",
            "Loss: 2.7075908184051514\n",
            "Frame 100 of 744\n",
            "Loss: 2.7393054962158203\n",
            "Frame 101 of 744\n",
            "Loss: 2.738581418991089\n",
            "Frame 102 of 744\n",
            "Loss: 2.777355909347534\n",
            "Frame 103 of 744\n",
            "Loss: 2.8917484283447266\n",
            "Frame 104 of 744\n",
            "Loss: 2.785097122192383\n",
            "Frame 105 of 744\n",
            "Loss: 2.8036844730377197\n",
            "Frame 106 of 744\n",
            "Loss: 2.83931827545166\n",
            "Frame 107 of 744\n",
            "Loss: 2.6963021755218506\n",
            "Frame 108 of 744\n",
            "Loss: 2.8179008960723877\n",
            "Frame 109 of 744\n",
            "Loss: 2.7844486236572266\n",
            "Frame 110 of 744\n",
            "Loss: 2.6872990131378174\n",
            "Frame 111 of 744\n",
            "Loss: 2.7777328491210938\n",
            "Frame 112 of 744\n",
            "Loss: 2.8580162525177\n",
            "Frame 113 of 744\n",
            "Loss: 2.732895851135254\n",
            "Frame 114 of 744\n",
            "Loss: 2.817035675048828\n",
            "Frame 115 of 744\n",
            "Loss: 2.772991180419922\n",
            "Frame 116 of 744\n",
            "Loss: 2.832737922668457\n",
            "Frame 117 of 744\n",
            "Loss: 2.8125734329223633\n",
            "Frame 118 of 744\n",
            "Loss: 2.7009150981903076\n",
            "Frame 119 of 744\n",
            "Loss: 2.7332401275634766\n",
            "Frame 120 of 744\n",
            "Loss: 2.7496893405914307\n",
            "Frame 121 of 744\n",
            "Loss: 2.793027877807617\n",
            "Frame 122 of 744\n",
            "Loss: 2.737792730331421\n",
            "Frame 123 of 744\n",
            "Loss: 2.792308807373047\n",
            "Frame 124 of 744\n",
            "Loss: 2.8149967193603516\n",
            "Frame 125 of 744\n",
            "Loss: 2.7097294330596924\n",
            "Frame 126 of 744\n",
            "Loss: 2.8144094944000244\n",
            "Frame 127 of 744\n",
            "Loss: 2.770249605178833\n",
            "Frame 128 of 744\n",
            "Loss: 2.726402997970581\n",
            "Frame 129 of 744\n",
            "Loss: 2.756258010864258\n",
            "Frame 130 of 744\n",
            "Loss: 2.8186042308807373\n",
            "Frame 131 of 744\n",
            "Loss: 2.7193872928619385\n",
            "Frame 132 of 744\n",
            "Loss: 2.756927728652954\n",
            "Frame 133 of 744\n",
            "Loss: 2.719489336013794\n",
            "Frame 134 of 744\n",
            "Loss: 2.860480308532715\n",
            "Frame 135 of 744\n",
            "Loss: 2.7808749675750732\n",
            "Frame 136 of 744\n",
            "Loss: 2.8011691570281982\n",
            "Frame 137 of 744\n",
            "Loss: 2.745011568069458\n",
            "Frame 138 of 744\n",
            "Loss: 2.8509321212768555\n",
            "Frame 139 of 744\n",
            "Loss: 2.846761703491211\n",
            "Frame 140 of 744\n",
            "Loss: 2.7304744720458984\n",
            "Frame 141 of 744\n",
            "Loss: 2.849039077758789\n",
            "Frame 142 of 744\n",
            "Loss: 2.7461345195770264\n",
            "Frame 143 of 744\n",
            "Loss: 2.7179887294769287\n",
            "Frame 144 of 744\n",
            "Loss: 2.7654800415039062\n",
            "Frame 145 of 744\n",
            "Loss: 2.6374471187591553\n",
            "Frame 146 of 744\n",
            "Loss: 2.7606375217437744\n",
            "Frame 147 of 744\n",
            "Loss: 2.7801449298858643\n",
            "Frame 148 of 744\n",
            "Loss: 2.8028554916381836\n",
            "Frame 149 of 744\n",
            "Loss: 2.838517904281616\n",
            "Frame 150 of 744\n",
            "Loss: 2.7679576873779297\n",
            "Frame 151 of 744\n",
            "Loss: 2.646639108657837\n",
            "Frame 152 of 744\n",
            "Loss: 2.7565157413482666\n",
            "Frame 153 of 744\n",
            "Loss: 2.832368850708008\n",
            "Frame 154 of 744\n",
            "Loss: 2.7734286785125732\n",
            "Frame 155 of 744\n",
            "Loss: 2.812199592590332\n",
            "Frame 156 of 744\n",
            "Loss: 2.748389482498169\n",
            "Frame 157 of 744\n",
            "Loss: 2.7474615573883057\n",
            "Frame 158 of 744\n",
            "Loss: 2.7862682342529297\n",
            "Frame 159 of 744\n",
            "Loss: 2.6976706981658936\n",
            "Frame 160 of 744\n",
            "Loss: 2.8245439529418945\n",
            "Frame 161 of 744\n",
            "Loss: 2.7676448822021484\n",
            "Frame 162 of 744\n",
            "Loss: 2.818370819091797\n",
            "Frame 163 of 744\n",
            "Loss: 2.724900960922241\n",
            "Frame 164 of 744\n",
            "Loss: 2.874436140060425\n",
            "Frame 165 of 744\n",
            "Loss: 2.7677462100982666\n",
            "Frame 166 of 744\n",
            "Loss: 2.6579723358154297\n",
            "Frame 167 of 744\n",
            "Loss: 2.8148739337921143\n",
            "Frame 168 of 744\n",
            "Loss: 2.686599016189575\n",
            "Frame 169 of 744\n",
            "Loss: 2.730130910873413\n",
            "Frame 170 of 744\n",
            "Loss: 2.7414743900299072\n",
            "Frame 171 of 744\n",
            "Loss: 2.6921145915985107\n",
            "Frame 172 of 744\n",
            "Loss: 2.853557586669922\n",
            "Frame 173 of 744\n",
            "Loss: 2.7634952068328857\n",
            "Frame 174 of 744\n",
            "Loss: 2.790884017944336\n",
            "Frame 175 of 744\n",
            "Loss: 2.6529977321624756\n",
            "Frame 176 of 744\n",
            "Loss: 2.8652498722076416\n",
            "Frame 177 of 744\n",
            "Loss: 2.818754196166992\n",
            "Frame 178 of 744\n",
            "Loss: 2.7890470027923584\n",
            "Frame 179 of 744\n",
            "Loss: 2.719932794570923\n",
            "Frame 180 of 744\n",
            "Loss: 2.904667854309082\n",
            "Frame 181 of 744\n",
            "Loss: 2.797048807144165\n",
            "Frame 182 of 744\n",
            "Loss: 2.7904560565948486\n",
            "Frame 183 of 744\n",
            "Loss: 2.806978225708008\n",
            "Frame 184 of 744\n",
            "Loss: 2.8411567211151123\n",
            "Frame 185 of 744\n",
            "Loss: 2.8662326335906982\n",
            "Frame 186 of 744\n",
            "Loss: 2.792273759841919\n",
            "Frame 187 of 744\n",
            "Loss: 2.8753445148468018\n",
            "Frame 188 of 744\n",
            "Loss: 2.8131725788116455\n",
            "Frame 189 of 744\n",
            "Loss: 2.809546709060669\n",
            "Frame 190 of 744\n",
            "Loss: 2.777627944946289\n",
            "Frame 191 of 744\n",
            "Loss: 2.7639663219451904\n",
            "Frame 192 of 744\n",
            "Loss: 2.810711622238159\n",
            "Frame 193 of 744\n",
            "Loss: 2.792367935180664\n",
            "Frame 194 of 744\n",
            "Loss: 2.7801849842071533\n",
            "Frame 195 of 744\n",
            "Loss: 2.7060325145721436\n",
            "Frame 196 of 744\n",
            "Loss: 2.7667407989501953\n",
            "Frame 197 of 744\n",
            "Loss: 2.804574966430664\n",
            "Frame 198 of 744\n",
            "Loss: 2.7273051738739014\n",
            "Frame 199 of 744\n",
            "Loss: 2.891770601272583\n",
            "Frame 200 of 744\n",
            "Loss: 2.767970323562622\n",
            "Frame 201 of 744\n",
            "Loss: 2.779078722000122\n",
            "Frame 202 of 744\n",
            "Loss: 2.8199470043182373\n",
            "Frame 203 of 744\n",
            "Loss: 2.7636289596557617\n",
            "Frame 204 of 744\n",
            "Loss: 2.7855281829833984\n",
            "Frame 205 of 744\n",
            "Loss: 2.7918264865875244\n",
            "Frame 206 of 744\n",
            "Loss: 2.7552976608276367\n",
            "Frame 207 of 744\n",
            "Loss: 2.7674214839935303\n",
            "Frame 208 of 744\n",
            "Loss: 2.783966302871704\n",
            "Frame 209 of 744\n",
            "Loss: 2.81219482421875\n",
            "Frame 210 of 744\n",
            "Loss: 2.7444446086883545\n",
            "Frame 211 of 744\n",
            "Loss: 2.759204626083374\n",
            "Frame 212 of 744\n",
            "Loss: 2.7201595306396484\n",
            "Frame 213 of 744\n",
            "Loss: 2.800208806991577\n",
            "Frame 214 of 744\n",
            "Loss: 2.7444095611572266\n",
            "Frame 215 of 744\n",
            "Loss: 2.8063392639160156\n",
            "Frame 216 of 744\n",
            "Loss: 2.7689788341522217\n",
            "Frame 217 of 744\n",
            "Loss: 2.7406890392303467\n",
            "Frame 218 of 744\n",
            "Loss: 2.711610794067383\n",
            "Frame 219 of 744\n",
            "Loss: 2.8075103759765625\n",
            "Frame 220 of 744\n",
            "Loss: 2.748565673828125\n",
            "Frame 221 of 744\n",
            "Loss: 2.8295488357543945\n",
            "Frame 222 of 744\n",
            "Loss: 2.7362124919891357\n",
            "Frame 223 of 744\n",
            "Loss: 2.720980405807495\n",
            "Frame 224 of 744\n",
            "Loss: 2.736431121826172\n",
            "Frame 225 of 744\n",
            "Loss: 2.8226654529571533\n",
            "Frame 226 of 744\n",
            "Loss: 2.871487617492676\n",
            "Frame 227 of 744\n",
            "Loss: 2.8293771743774414\n",
            "Frame 228 of 744\n",
            "Loss: 2.763845443725586\n",
            "Frame 229 of 744\n",
            "Loss: 2.90586256980896\n",
            "Frame 230 of 744\n",
            "Loss: 2.801858901977539\n",
            "Frame 231 of 744\n",
            "Loss: 2.7588260173797607\n",
            "Frame 232 of 744\n",
            "Loss: 2.803725481033325\n",
            "Frame 233 of 744\n",
            "Loss: 2.783330202102661\n",
            "Frame 234 of 744\n",
            "Loss: 2.8208818435668945\n",
            "Frame 235 of 744\n",
            "Loss: 2.8265981674194336\n",
            "Frame 236 of 744\n",
            "Loss: 2.7566158771514893\n",
            "Frame 237 of 744\n",
            "Loss: 2.8235156536102295\n",
            "Frame 238 of 744\n",
            "Loss: 2.8053767681121826\n",
            "Frame 239 of 744\n",
            "Loss: 2.7977283000946045\n",
            "Frame 240 of 744\n",
            "Loss: 2.7977685928344727\n",
            "Frame 241 of 744\n",
            "Loss: 2.738297700881958\n",
            "Frame 242 of 744\n",
            "Loss: 2.787827730178833\n",
            "Frame 243 of 744\n",
            "Loss: 2.7607080936431885\n",
            "Frame 244 of 744\n",
            "Loss: 2.810070037841797\n",
            "Frame 245 of 744\n",
            "Loss: 2.84856915473938\n",
            "Frame 246 of 744\n",
            "Loss: 2.789926290512085\n",
            "Frame 247 of 744\n",
            "Loss: 2.79453444480896\n",
            "Training Loss: 2.778219417218239\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.05241935483870968\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 10\n",
            "Frame 0 of 744\n",
            "Loss: 2.7326409816741943\n",
            "Frame 1 of 744\n",
            "Loss: 2.8005897998809814\n",
            "Frame 2 of 744\n",
            "Loss: 2.8504979610443115\n",
            "Frame 3 of 744\n",
            "Loss: 2.7928390502929688\n",
            "Frame 4 of 744\n",
            "Loss: 2.7514841556549072\n",
            "Frame 5 of 744\n",
            "Loss: 2.760582685470581\n",
            "Frame 6 of 744\n",
            "Loss: 2.7374048233032227\n",
            "Frame 7 of 744\n",
            "Loss: 2.7227470874786377\n",
            "Frame 8 of 744\n",
            "Loss: 2.8073835372924805\n",
            "Frame 9 of 744\n",
            "Loss: 2.7339582443237305\n",
            "Frame 10 of 744\n",
            "Loss: 2.763850212097168\n",
            "Frame 11 of 744\n",
            "Loss: 2.813843011856079\n",
            "Frame 12 of 744\n",
            "Loss: 2.851701021194458\n",
            "Frame 13 of 744\n",
            "Loss: 2.826331853866577\n",
            "Frame 14 of 744\n",
            "Loss: 2.757683515548706\n",
            "Frame 15 of 744\n",
            "Loss: 2.7557132244110107\n",
            "Frame 16 of 744\n",
            "Loss: 2.796747922897339\n",
            "Frame 17 of 744\n",
            "Loss: 2.81427264213562\n",
            "Frame 18 of 744\n",
            "Loss: 2.7916696071624756\n",
            "Frame 19 of 744\n",
            "Loss: 2.7578909397125244\n",
            "Frame 20 of 744\n",
            "Loss: 2.8135268688201904\n",
            "Frame 21 of 744\n",
            "Loss: 2.74424147605896\n",
            "Frame 22 of 744\n",
            "Loss: 2.7777187824249268\n",
            "Frame 23 of 744\n",
            "Loss: 2.7687642574310303\n",
            "Frame 24 of 744\n",
            "Loss: 2.7401533126831055\n",
            "Frame 25 of 744\n",
            "Loss: 2.7367076873779297\n",
            "Frame 26 of 744\n",
            "Loss: 2.783496856689453\n",
            "Frame 27 of 744\n",
            "Loss: 2.7882750034332275\n",
            "Frame 28 of 744\n",
            "Loss: 2.7606847286224365\n",
            "Frame 29 of 744\n",
            "Loss: 2.8020942211151123\n",
            "Frame 30 of 744\n",
            "Loss: 2.764962911605835\n",
            "Frame 31 of 744\n",
            "Loss: 2.769345998764038\n",
            "Frame 32 of 744\n",
            "Loss: 2.791810989379883\n",
            "Frame 33 of 744\n",
            "Loss: 2.770514488220215\n",
            "Frame 34 of 744\n",
            "Loss: 2.766296148300171\n",
            "Frame 35 of 744\n",
            "Loss: 2.749850034713745\n",
            "Frame 36 of 744\n",
            "Loss: 2.698578119277954\n",
            "Frame 37 of 744\n",
            "Loss: 2.73907732963562\n",
            "Frame 38 of 744\n",
            "Loss: 2.7396233081817627\n",
            "Frame 39 of 744\n",
            "Loss: 2.8187057971954346\n",
            "Frame 40 of 744\n",
            "Loss: 2.756164312362671\n",
            "Frame 41 of 744\n",
            "Loss: 2.7808122634887695\n",
            "Frame 42 of 744\n",
            "Loss: 2.8059208393096924\n",
            "Frame 43 of 744\n",
            "Loss: 2.7854483127593994\n",
            "Frame 44 of 744\n",
            "Loss: 2.7986812591552734\n",
            "Frame 45 of 744\n",
            "Loss: 2.8042354583740234\n",
            "Frame 46 of 744\n",
            "Loss: 2.8122575283050537\n",
            "Frame 47 of 744\n",
            "Loss: 2.7407195568084717\n",
            "Frame 48 of 744\n",
            "Loss: 2.740276336669922\n",
            "Frame 49 of 744\n",
            "Loss: 2.760263204574585\n",
            "Frame 50 of 744\n",
            "Loss: 2.7295734882354736\n",
            "Frame 51 of 744\n",
            "Loss: 2.8811588287353516\n",
            "Frame 52 of 744\n",
            "Loss: 2.7858762741088867\n",
            "Frame 53 of 744\n",
            "Loss: 2.7327053546905518\n",
            "Frame 54 of 744\n",
            "Loss: 2.7641689777374268\n",
            "Frame 55 of 744\n",
            "Loss: 2.738647222518921\n",
            "Frame 56 of 744\n",
            "Loss: 2.720627546310425\n",
            "Frame 57 of 744\n",
            "Loss: 2.901449203491211\n",
            "Frame 58 of 744\n",
            "Loss: 2.7976672649383545\n",
            "Frame 59 of 744\n",
            "Loss: 2.824010133743286\n",
            "Frame 60 of 744\n",
            "Loss: 2.8177833557128906\n",
            "Frame 61 of 744\n",
            "Loss: 2.7408218383789062\n",
            "Frame 62 of 744\n",
            "Loss: 2.821169853210449\n",
            "Frame 63 of 744\n",
            "Loss: 2.857222318649292\n",
            "Frame 64 of 744\n",
            "Loss: 2.835724115371704\n",
            "Frame 65 of 744\n",
            "Loss: 2.7781331539154053\n",
            "Frame 66 of 744\n",
            "Loss: 2.7450859546661377\n",
            "Frame 67 of 744\n",
            "Loss: 2.800018310546875\n",
            "Frame 68 of 744\n",
            "Loss: 2.7312610149383545\n",
            "Frame 69 of 744\n",
            "Loss: 2.8007431030273438\n",
            "Frame 70 of 744\n",
            "Loss: 2.7780628204345703\n",
            "Frame 71 of 744\n",
            "Loss: 2.8100030422210693\n",
            "Frame 72 of 744\n",
            "Loss: 2.7805354595184326\n",
            "Frame 73 of 744\n",
            "Loss: 2.713073968887329\n",
            "Frame 74 of 744\n",
            "Loss: 2.805187225341797\n",
            "Frame 75 of 744\n",
            "Loss: 2.818524122238159\n",
            "Frame 76 of 744\n",
            "Loss: 2.802393913269043\n",
            "Frame 77 of 744\n",
            "Loss: 2.754502058029175\n",
            "Frame 78 of 744\n",
            "Loss: 2.798370599746704\n",
            "Frame 79 of 744\n",
            "Loss: 2.8138515949249268\n",
            "Frame 80 of 744\n",
            "Loss: 2.790233612060547\n",
            "Frame 81 of 744\n",
            "Loss: 2.7508890628814697\n",
            "Frame 82 of 744\n",
            "Loss: 2.7269811630249023\n",
            "Frame 83 of 744\n",
            "Loss: 2.752936601638794\n",
            "Frame 84 of 744\n",
            "Loss: 2.793095350265503\n",
            "Frame 85 of 744\n",
            "Loss: 2.751382827758789\n",
            "Frame 86 of 744\n",
            "Loss: 2.7448203563690186\n",
            "Frame 87 of 744\n",
            "Loss: 2.7071340084075928\n",
            "Frame 88 of 744\n",
            "Loss: 2.7655179500579834\n",
            "Frame 89 of 744\n",
            "Loss: 2.7956154346466064\n",
            "Frame 90 of 744\n",
            "Loss: 2.7435500621795654\n",
            "Frame 91 of 744\n",
            "Loss: 2.8073999881744385\n",
            "Frame 92 of 744\n",
            "Loss: 2.7642593383789062\n",
            "Frame 93 of 744\n",
            "Loss: 2.7588207721710205\n",
            "Frame 94 of 744\n",
            "Loss: 2.8492534160614014\n",
            "Frame 95 of 744\n",
            "Loss: 2.763242721557617\n",
            "Frame 96 of 744\n",
            "Loss: 2.7695188522338867\n",
            "Frame 97 of 744\n",
            "Loss: 2.751495599746704\n",
            "Frame 98 of 744\n",
            "Loss: 2.7716903686523438\n",
            "Frame 99 of 744\n",
            "Loss: 2.741351366043091\n",
            "Frame 100 of 744\n",
            "Loss: 2.7351067066192627\n",
            "Frame 101 of 744\n",
            "Loss: 2.84804630279541\n",
            "Frame 102 of 744\n",
            "Loss: 2.709261655807495\n",
            "Frame 103 of 744\n",
            "Loss: 2.881793260574341\n",
            "Frame 104 of 744\n",
            "Loss: 2.7831954956054688\n",
            "Frame 105 of 744\n",
            "Loss: 2.7425975799560547\n",
            "Frame 106 of 744\n",
            "Loss: 2.7559330463409424\n",
            "Frame 107 of 744\n",
            "Loss: 2.8729209899902344\n",
            "Frame 108 of 744\n",
            "Loss: 2.8188886642456055\n",
            "Frame 109 of 744\n",
            "Loss: 2.8042421340942383\n",
            "Frame 110 of 744\n",
            "Loss: 2.768646240234375\n",
            "Frame 111 of 744\n",
            "Loss: 2.899327516555786\n",
            "Frame 112 of 744\n",
            "Loss: 2.8044793605804443\n",
            "Frame 113 of 744\n",
            "Loss: 2.7985432147979736\n",
            "Frame 114 of 744\n",
            "Loss: 2.7421576976776123\n",
            "Frame 115 of 744\n",
            "Loss: 2.753824472427368\n",
            "Frame 116 of 744\n",
            "Loss: 2.7882959842681885\n",
            "Frame 117 of 744\n",
            "Loss: 2.8310298919677734\n",
            "Frame 118 of 744\n",
            "Loss: 2.7293341159820557\n",
            "Frame 119 of 744\n",
            "Loss: 2.7543671131134033\n",
            "Frame 120 of 744\n",
            "Loss: 2.729346513748169\n",
            "Frame 121 of 744\n",
            "Loss: 2.7880189418792725\n",
            "Frame 122 of 744\n",
            "Loss: 2.814347505569458\n",
            "Frame 123 of 744\n",
            "Loss: 2.766960859298706\n",
            "Frame 124 of 744\n",
            "Loss: 2.753018379211426\n",
            "Frame 125 of 744\n",
            "Loss: 2.825852155685425\n",
            "Frame 126 of 744\n",
            "Loss: 2.783907175064087\n",
            "Frame 127 of 744\n",
            "Loss: 2.734764337539673\n",
            "Frame 128 of 744\n",
            "Loss: 2.7716095447540283\n",
            "Frame 129 of 744\n",
            "Loss: 2.805187940597534\n",
            "Frame 130 of 744\n",
            "Loss: 2.78332257270813\n",
            "Frame 131 of 744\n",
            "Loss: 2.778743028640747\n",
            "Frame 132 of 744\n",
            "Loss: 2.7667322158813477\n",
            "Frame 133 of 744\n",
            "Loss: 2.719302177429199\n",
            "Frame 134 of 744\n",
            "Loss: 2.743917465209961\n",
            "Frame 135 of 744\n",
            "Loss: 2.830052137374878\n",
            "Frame 136 of 744\n",
            "Loss: 2.734527349472046\n",
            "Frame 137 of 744\n",
            "Loss: 2.7686893939971924\n",
            "Frame 138 of 744\n",
            "Loss: 2.7734251022338867\n",
            "Frame 139 of 744\n",
            "Loss: 2.779029130935669\n",
            "Frame 140 of 744\n",
            "Loss: 2.7784135341644287\n",
            "Frame 141 of 744\n",
            "Loss: 2.7624480724334717\n",
            "Frame 142 of 744\n",
            "Loss: 2.843273162841797\n",
            "Frame 143 of 744\n",
            "Loss: 2.845900535583496\n",
            "Frame 144 of 744\n",
            "Loss: 2.7591583728790283\n",
            "Frame 145 of 744\n",
            "Loss: 2.6989314556121826\n",
            "Frame 146 of 744\n",
            "Loss: 2.746549606323242\n",
            "Frame 147 of 744\n",
            "Loss: 2.8121063709259033\n",
            "Frame 148 of 744\n",
            "Loss: 2.756002426147461\n",
            "Frame 149 of 744\n",
            "Loss: 2.7897167205810547\n",
            "Frame 150 of 744\n",
            "Loss: 2.7975451946258545\n",
            "Frame 151 of 744\n",
            "Loss: 2.778224229812622\n",
            "Frame 152 of 744\n",
            "Loss: 2.747760057449341\n",
            "Frame 153 of 744\n",
            "Loss: 2.754967451095581\n",
            "Frame 154 of 744\n",
            "Loss: 2.8194570541381836\n",
            "Frame 155 of 744\n",
            "Loss: 2.77714467048645\n",
            "Frame 156 of 744\n",
            "Loss: 2.781458854675293\n",
            "Frame 157 of 744\n",
            "Loss: 2.728208541870117\n",
            "Frame 158 of 744\n",
            "Loss: 2.794940948486328\n",
            "Frame 159 of 744\n",
            "Loss: 2.71905779838562\n",
            "Frame 160 of 744\n",
            "Loss: 2.7545764446258545\n",
            "Frame 161 of 744\n",
            "Loss: 2.774671792984009\n",
            "Frame 162 of 744\n",
            "Loss: 2.74187970161438\n",
            "Frame 163 of 744\n",
            "Loss: 2.6867306232452393\n",
            "Frame 164 of 744\n",
            "Loss: 2.8065249919891357\n",
            "Frame 165 of 744\n",
            "Loss: 2.764232635498047\n",
            "Frame 166 of 744\n",
            "Loss: 2.789015531539917\n",
            "Frame 167 of 744\n",
            "Loss: 2.8554847240448\n",
            "Frame 168 of 744\n",
            "Loss: 2.7287728786468506\n",
            "Frame 169 of 744\n",
            "Loss: 2.7475998401641846\n",
            "Frame 170 of 744\n",
            "Loss: 2.782283067703247\n",
            "Frame 171 of 744\n",
            "Loss: 2.812549352645874\n",
            "Frame 172 of 744\n",
            "Loss: 2.8038718700408936\n",
            "Frame 173 of 744\n",
            "Loss: 2.788925886154175\n",
            "Frame 174 of 744\n",
            "Loss: 2.759709596633911\n",
            "Frame 175 of 744\n",
            "Loss: 2.774261474609375\n",
            "Frame 176 of 744\n",
            "Loss: 2.8251495361328125\n",
            "Frame 177 of 744\n",
            "Loss: 2.8959436416625977\n",
            "Frame 178 of 744\n",
            "Loss: 2.7032687664031982\n",
            "Frame 179 of 744\n",
            "Loss: 2.7401959896087646\n",
            "Frame 180 of 744\n",
            "Loss: 2.8538239002227783\n",
            "Frame 181 of 744\n",
            "Loss: 2.695244073867798\n",
            "Frame 182 of 744\n",
            "Loss: 2.701357126235962\n",
            "Frame 183 of 744\n",
            "Loss: 2.7364795207977295\n",
            "Frame 184 of 744\n",
            "Loss: 2.854656457901001\n",
            "Frame 185 of 744\n",
            "Loss: 2.771195650100708\n",
            "Frame 186 of 744\n",
            "Loss: 2.818882703781128\n",
            "Frame 187 of 744\n",
            "Loss: 2.8723723888397217\n",
            "Frame 188 of 744\n",
            "Loss: 2.730178117752075\n",
            "Frame 189 of 744\n",
            "Loss: 2.871535062789917\n",
            "Frame 190 of 744\n",
            "Loss: 2.7401058673858643\n",
            "Frame 191 of 744\n",
            "Loss: 2.77372670173645\n",
            "Frame 192 of 744\n",
            "Loss: 2.8869705200195312\n",
            "Frame 193 of 744\n",
            "Loss: 2.8398139476776123\n",
            "Frame 194 of 744\n",
            "Loss: 2.86975359916687\n",
            "Frame 195 of 744\n",
            "Loss: 2.7482821941375732\n",
            "Frame 196 of 744\n",
            "Loss: 2.7980096340179443\n",
            "Frame 197 of 744\n",
            "Loss: 2.7349586486816406\n",
            "Frame 198 of 744\n",
            "Loss: 2.826969861984253\n",
            "Frame 199 of 744\n",
            "Loss: 2.827427625656128\n",
            "Frame 200 of 744\n",
            "Loss: 2.784438133239746\n",
            "Frame 201 of 744\n",
            "Loss: 2.767000913619995\n",
            "Frame 202 of 744\n",
            "Loss: 2.793614387512207\n",
            "Frame 203 of 744\n",
            "Loss: 2.786278486251831\n",
            "Frame 204 of 744\n",
            "Loss: 2.773076295852661\n",
            "Frame 205 of 744\n",
            "Loss: 2.7882843017578125\n",
            "Frame 206 of 744\n",
            "Loss: 2.772346258163452\n",
            "Frame 207 of 744\n",
            "Loss: 2.7556209564208984\n",
            "Frame 208 of 744\n",
            "Loss: 2.751727342605591\n",
            "Frame 209 of 744\n",
            "Loss: 2.749563217163086\n",
            "Frame 210 of 744\n",
            "Loss: 2.8489997386932373\n",
            "Frame 211 of 744\n",
            "Loss: 2.6970913410186768\n",
            "Frame 212 of 744\n",
            "Loss: 2.816688299179077\n",
            "Frame 213 of 744\n",
            "Loss: 2.8284542560577393\n",
            "Frame 214 of 744\n",
            "Loss: 2.7364327907562256\n",
            "Frame 215 of 744\n",
            "Loss: 2.7686359882354736\n",
            "Frame 216 of 744\n",
            "Loss: 2.784219741821289\n",
            "Frame 217 of 744\n",
            "Loss: 2.7064993381500244\n",
            "Frame 218 of 744\n",
            "Loss: 2.763970136642456\n",
            "Frame 219 of 744\n",
            "Loss: 2.841827392578125\n",
            "Frame 220 of 744\n",
            "Loss: 2.79583740234375\n",
            "Frame 221 of 744\n",
            "Loss: 2.7829105854034424\n",
            "Frame 222 of 744\n",
            "Loss: 2.6887285709381104\n",
            "Frame 223 of 744\n",
            "Loss: 2.7046451568603516\n",
            "Frame 224 of 744\n",
            "Loss: 2.818450689315796\n",
            "Frame 225 of 744\n",
            "Loss: 2.7081005573272705\n",
            "Frame 226 of 744\n",
            "Loss: 2.837573289871216\n",
            "Frame 227 of 744\n",
            "Loss: 2.797943115234375\n",
            "Frame 228 of 744\n",
            "Loss: 2.80243182182312\n",
            "Frame 229 of 744\n",
            "Loss: 2.776435136795044\n",
            "Frame 230 of 744\n",
            "Loss: 2.796569585800171\n",
            "Frame 231 of 744\n",
            "Loss: 2.725404739379883\n",
            "Frame 232 of 744\n",
            "Loss: 2.7968051433563232\n",
            "Frame 233 of 744\n",
            "Loss: 2.757014036178589\n",
            "Frame 234 of 744\n",
            "Loss: 2.775672197341919\n",
            "Frame 235 of 744\n",
            "Loss: 2.7979161739349365\n",
            "Frame 236 of 744\n",
            "Loss: 2.7580482959747314\n",
            "Frame 237 of 744\n",
            "Loss: 2.8670902252197266\n",
            "Frame 238 of 744\n",
            "Loss: 2.771188735961914\n",
            "Frame 239 of 744\n",
            "Loss: 2.7759199142456055\n",
            "Frame 240 of 744\n",
            "Loss: 2.8692586421966553\n",
            "Frame 241 of 744\n",
            "Loss: 2.733116388320923\n",
            "Frame 242 of 744\n",
            "Loss: 2.8040390014648438\n",
            "Frame 243 of 744\n",
            "Loss: 2.87850284576416\n",
            "Frame 244 of 744\n",
            "Loss: 2.77655291557312\n",
            "Frame 245 of 744\n",
            "Loss: 2.8141086101531982\n",
            "Frame 246 of 744\n",
            "Loss: 2.7946555614471436\n",
            "Frame 247 of 744\n",
            "Loss: 2.810617208480835\n",
            "Training Loss: 2.780194713223365\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.05510752688172043\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 11\n",
            "Frame 0 of 744\n",
            "Loss: 2.724195718765259\n",
            "Frame 1 of 744\n",
            "Loss: 2.794398069381714\n",
            "Frame 2 of 744\n",
            "Loss: 2.7499475479125977\n",
            "Frame 3 of 744\n",
            "Loss: 2.820652961730957\n",
            "Frame 4 of 744\n",
            "Loss: 2.7537777423858643\n",
            "Frame 5 of 744\n",
            "Loss: 2.748882532119751\n",
            "Frame 6 of 744\n",
            "Loss: 2.795405626296997\n",
            "Frame 7 of 744\n",
            "Loss: 2.6959283351898193\n",
            "Frame 8 of 744\n",
            "Loss: 2.7890851497650146\n",
            "Frame 9 of 744\n",
            "Loss: 2.7988815307617188\n",
            "Frame 10 of 744\n",
            "Loss: 2.8094406127929688\n",
            "Frame 11 of 744\n",
            "Loss: 2.7831268310546875\n",
            "Frame 12 of 744\n",
            "Loss: 2.7940165996551514\n",
            "Frame 13 of 744\n",
            "Loss: 2.729627847671509\n",
            "Frame 14 of 744\n",
            "Loss: 2.7421979904174805\n",
            "Frame 15 of 744\n",
            "Loss: 2.797985315322876\n",
            "Frame 16 of 744\n",
            "Loss: 2.725238561630249\n",
            "Frame 17 of 744\n",
            "Loss: 2.7427732944488525\n",
            "Frame 18 of 744\n",
            "Loss: 2.826502561569214\n",
            "Frame 19 of 744\n",
            "Loss: 2.7314612865448\n",
            "Frame 20 of 744\n",
            "Loss: 2.779073476791382\n",
            "Frame 21 of 744\n",
            "Loss: 2.788536787033081\n",
            "Frame 22 of 744\n",
            "Loss: 2.7514705657958984\n",
            "Frame 23 of 744\n",
            "Loss: 2.74008846282959\n",
            "Frame 24 of 744\n",
            "Loss: 2.724325180053711\n",
            "Frame 25 of 744\n",
            "Loss: 2.7284038066864014\n",
            "Frame 26 of 744\n",
            "Loss: 2.71726393699646\n",
            "Frame 27 of 744\n",
            "Loss: 2.757664442062378\n",
            "Frame 28 of 744\n",
            "Loss: 2.740703582763672\n",
            "Frame 29 of 744\n",
            "Loss: 2.7752199172973633\n",
            "Frame 30 of 744\n",
            "Loss: 2.74100399017334\n",
            "Frame 31 of 744\n",
            "Loss: 2.738079786300659\n",
            "Frame 32 of 744\n",
            "Loss: 2.774362564086914\n",
            "Frame 33 of 744\n",
            "Loss: 2.806732416152954\n",
            "Frame 34 of 744\n",
            "Loss: 2.721302032470703\n",
            "Frame 35 of 744\n",
            "Loss: 2.866624116897583\n",
            "Frame 36 of 744\n",
            "Loss: 2.7498481273651123\n",
            "Frame 37 of 744\n",
            "Loss: 2.76534104347229\n",
            "Frame 38 of 744\n",
            "Loss: 2.8036394119262695\n",
            "Frame 39 of 744\n",
            "Loss: 2.7742154598236084\n",
            "Frame 40 of 744\n",
            "Loss: 2.790027379989624\n",
            "Frame 41 of 744\n",
            "Loss: 2.7275772094726562\n",
            "Frame 42 of 744\n",
            "Loss: 2.8154687881469727\n",
            "Frame 43 of 744\n",
            "Loss: 2.766658067703247\n",
            "Frame 44 of 744\n",
            "Loss: 2.6897995471954346\n",
            "Frame 45 of 744\n",
            "Loss: 2.8290481567382812\n",
            "Frame 46 of 744\n",
            "Loss: 2.8680732250213623\n",
            "Frame 47 of 744\n",
            "Loss: 2.7301695346832275\n",
            "Frame 48 of 744\n",
            "Loss: 2.7845804691314697\n",
            "Frame 49 of 744\n",
            "Loss: 2.7197539806365967\n",
            "Frame 50 of 744\n",
            "Loss: 2.8867290019989014\n",
            "Frame 51 of 744\n",
            "Loss: 2.843679666519165\n",
            "Frame 52 of 744\n",
            "Loss: 2.7692573070526123\n",
            "Frame 53 of 744\n",
            "Loss: 2.713146448135376\n",
            "Frame 54 of 744\n",
            "Loss: 2.7400524616241455\n",
            "Frame 55 of 744\n",
            "Loss: 2.712428092956543\n",
            "Frame 56 of 744\n",
            "Loss: 2.776226282119751\n",
            "Frame 57 of 744\n",
            "Loss: 2.7824602127075195\n",
            "Frame 58 of 744\n",
            "Loss: 2.7895936965942383\n",
            "Frame 59 of 744\n",
            "Loss: 2.7268781661987305\n",
            "Frame 60 of 744\n",
            "Loss: 2.733692169189453\n",
            "Frame 61 of 744\n",
            "Loss: 2.73429799079895\n",
            "Frame 62 of 744\n",
            "Loss: 2.788884162902832\n",
            "Frame 63 of 744\n",
            "Loss: 2.810389280319214\n",
            "Frame 64 of 744\n",
            "Loss: 2.7953109741210938\n",
            "Frame 65 of 744\n",
            "Loss: 2.7423412799835205\n",
            "Frame 66 of 744\n",
            "Loss: 2.7589263916015625\n",
            "Frame 67 of 744\n",
            "Loss: 2.8340160846710205\n",
            "Frame 68 of 744\n",
            "Loss: 2.9139556884765625\n",
            "Frame 69 of 744\n",
            "Loss: 2.820126533508301\n",
            "Frame 70 of 744\n",
            "Loss: 2.7656586170196533\n",
            "Frame 71 of 744\n",
            "Loss: 2.7558772563934326\n",
            "Frame 72 of 744\n",
            "Loss: 2.7479724884033203\n",
            "Frame 73 of 744\n",
            "Loss: 2.770932197570801\n",
            "Frame 74 of 744\n",
            "Loss: 2.7336699962615967\n",
            "Frame 75 of 744\n",
            "Loss: 2.727029800415039\n",
            "Frame 76 of 744\n",
            "Loss: 2.791691780090332\n",
            "Frame 77 of 744\n",
            "Loss: 2.741339921951294\n",
            "Frame 78 of 744\n",
            "Loss: 2.723963737487793\n",
            "Frame 79 of 744\n",
            "Loss: 2.763484239578247\n",
            "Frame 80 of 744\n",
            "Loss: 2.786478281021118\n",
            "Frame 81 of 744\n",
            "Loss: 2.798760414123535\n",
            "Frame 82 of 744\n",
            "Loss: 2.7722463607788086\n",
            "Frame 83 of 744\n",
            "Loss: 2.7614996433258057\n",
            "Frame 84 of 744\n",
            "Loss: 2.7646725177764893\n",
            "Frame 85 of 744\n",
            "Loss: 2.8989925384521484\n",
            "Frame 86 of 744\n",
            "Loss: 2.7382171154022217\n",
            "Frame 87 of 744\n",
            "Loss: 2.7700459957122803\n",
            "Frame 88 of 744\n",
            "Loss: 2.87896728515625\n",
            "Frame 89 of 744\n",
            "Loss: 2.766455888748169\n",
            "Frame 90 of 744\n",
            "Loss: 2.874974012374878\n",
            "Frame 91 of 744\n",
            "Loss: 2.794299364089966\n",
            "Frame 92 of 744\n",
            "Loss: 2.765324354171753\n",
            "Frame 93 of 744\n",
            "Loss: 2.7601635456085205\n",
            "Frame 94 of 744\n",
            "Loss: 2.9077415466308594\n",
            "Frame 95 of 744\n",
            "Loss: 2.710369348526001\n",
            "Frame 96 of 744\n",
            "Loss: 2.738382577896118\n",
            "Frame 97 of 744\n",
            "Loss: 2.7674026489257812\n",
            "Frame 98 of 744\n",
            "Loss: 2.7197864055633545\n",
            "Frame 99 of 744\n",
            "Loss: 2.772902727127075\n",
            "Frame 100 of 744\n",
            "Loss: 2.78373122215271\n",
            "Frame 101 of 744\n",
            "Loss: 2.7526562213897705\n",
            "Frame 102 of 744\n",
            "Loss: 2.7223997116088867\n",
            "Frame 103 of 744\n",
            "Loss: 2.7772037982940674\n",
            "Frame 104 of 744\n",
            "Loss: 2.7866601943969727\n",
            "Frame 105 of 744\n",
            "Loss: 2.7391357421875\n",
            "Frame 106 of 744\n",
            "Loss: 2.7127716541290283\n",
            "Frame 107 of 744\n",
            "Loss: 2.8383514881134033\n",
            "Frame 108 of 744\n",
            "Loss: 2.750997543334961\n",
            "Frame 109 of 744\n",
            "Loss: 2.692736864089966\n",
            "Frame 110 of 744\n",
            "Loss: 2.727198362350464\n",
            "Frame 111 of 744\n",
            "Loss: 2.729947328567505\n",
            "Frame 112 of 744\n",
            "Loss: 2.7215802669525146\n",
            "Frame 113 of 744\n",
            "Loss: 2.8827850818634033\n",
            "Frame 114 of 744\n",
            "Loss: 2.839458465576172\n",
            "Frame 115 of 744\n",
            "Loss: 2.705216646194458\n",
            "Frame 116 of 744\n",
            "Loss: 2.7903640270233154\n",
            "Frame 117 of 744\n",
            "Loss: 2.885568618774414\n",
            "Frame 118 of 744\n",
            "Loss: 2.7717511653900146\n",
            "Frame 119 of 744\n",
            "Loss: 2.75338077545166\n",
            "Frame 120 of 744\n",
            "Loss: 2.7369956970214844\n",
            "Frame 121 of 744\n",
            "Loss: 2.8957207202911377\n",
            "Frame 122 of 744\n",
            "Loss: 2.8136675357818604\n",
            "Frame 123 of 744\n",
            "Loss: 2.7743282318115234\n",
            "Frame 124 of 744\n",
            "Loss: 2.870534658432007\n",
            "Frame 125 of 744\n",
            "Loss: 2.7563092708587646\n",
            "Frame 126 of 744\n",
            "Loss: 2.8237345218658447\n",
            "Frame 127 of 744\n",
            "Loss: 2.818646192550659\n",
            "Frame 128 of 744\n",
            "Loss: 2.8500163555145264\n",
            "Frame 129 of 744\n",
            "Loss: 2.7338578701019287\n",
            "Frame 130 of 744\n",
            "Loss: 2.8047876358032227\n",
            "Frame 131 of 744\n",
            "Loss: 2.8600082397460938\n",
            "Frame 132 of 744\n",
            "Loss: 2.741332769393921\n",
            "Frame 133 of 744\n",
            "Loss: 2.860363006591797\n",
            "Frame 134 of 744\n",
            "Loss: 2.781238317489624\n",
            "Frame 135 of 744\n",
            "Loss: 2.7277138233184814\n",
            "Frame 136 of 744\n",
            "Loss: 2.781803846359253\n",
            "Frame 137 of 744\n",
            "Loss: 2.739502191543579\n",
            "Frame 138 of 744\n",
            "Loss: 2.794464349746704\n",
            "Frame 139 of 744\n",
            "Loss: 2.7772159576416016\n",
            "Frame 140 of 744\n",
            "Loss: 2.8839492797851562\n",
            "Frame 141 of 744\n",
            "Loss: 2.7410409450531006\n",
            "Frame 142 of 744\n",
            "Loss: 2.827998399734497\n",
            "Frame 143 of 744\n",
            "Loss: 2.745310068130493\n",
            "Frame 144 of 744\n",
            "Loss: 2.7835423946380615\n",
            "Frame 145 of 744\n",
            "Loss: 2.798821210861206\n",
            "Frame 146 of 744\n",
            "Loss: 2.8262722492218018\n",
            "Frame 147 of 744\n",
            "Loss: 2.7140142917633057\n",
            "Frame 148 of 744\n",
            "Loss: 2.7993669509887695\n",
            "Frame 149 of 744\n",
            "Loss: 2.9114933013916016\n",
            "Frame 150 of 744\n",
            "Loss: 2.7911624908447266\n",
            "Frame 151 of 744\n",
            "Loss: 2.7738969326019287\n",
            "Frame 152 of 744\n",
            "Loss: 2.753519058227539\n",
            "Frame 153 of 744\n",
            "Loss: 2.7196428775787354\n",
            "Frame 154 of 744\n",
            "Loss: 2.7330777645111084\n",
            "Frame 155 of 744\n",
            "Loss: 2.6869964599609375\n",
            "Frame 156 of 744\n",
            "Loss: 2.7424004077911377\n",
            "Frame 157 of 744\n",
            "Loss: 2.8360674381256104\n",
            "Frame 158 of 744\n",
            "Loss: 2.815645456314087\n",
            "Frame 159 of 744\n",
            "Loss: 2.6992454528808594\n",
            "Frame 160 of 744\n",
            "Loss: 2.7813374996185303\n",
            "Frame 161 of 744\n",
            "Loss: 2.7914390563964844\n",
            "Frame 162 of 744\n",
            "Loss: 2.7373225688934326\n",
            "Frame 163 of 744\n",
            "Loss: 2.765845537185669\n",
            "Frame 164 of 744\n",
            "Loss: 2.741691827774048\n",
            "Frame 165 of 744\n",
            "Loss: 2.804199457168579\n",
            "Frame 166 of 744\n",
            "Loss: 2.761948585510254\n",
            "Frame 167 of 744\n",
            "Loss: 2.8082573413848877\n",
            "Frame 168 of 744\n",
            "Loss: 2.768345832824707\n",
            "Frame 169 of 744\n",
            "Loss: 2.7424252033233643\n",
            "Frame 170 of 744\n",
            "Loss: 2.7294673919677734\n",
            "Frame 171 of 744\n",
            "Loss: 2.7965221405029297\n",
            "Frame 172 of 744\n",
            "Loss: 2.7045364379882812\n",
            "Frame 173 of 744\n",
            "Loss: 2.7853810787200928\n",
            "Frame 174 of 744\n",
            "Loss: 2.7748310565948486\n",
            "Frame 175 of 744\n",
            "Loss: 2.8069136142730713\n",
            "Frame 176 of 744\n",
            "Loss: 2.871652603149414\n",
            "Frame 177 of 744\n",
            "Loss: 2.654120922088623\n",
            "Frame 178 of 744\n",
            "Loss: 2.729625940322876\n",
            "Frame 179 of 744\n",
            "Loss: 2.8426952362060547\n",
            "Frame 180 of 744\n",
            "Loss: 2.8208189010620117\n",
            "Frame 181 of 744\n",
            "Loss: 2.796013593673706\n",
            "Frame 182 of 744\n",
            "Loss: 2.871751070022583\n",
            "Frame 183 of 744\n",
            "Loss: 2.813192367553711\n",
            "Frame 184 of 744\n",
            "Loss: 2.7578697204589844\n",
            "Frame 185 of 744\n",
            "Loss: 2.7659151554107666\n",
            "Frame 186 of 744\n",
            "Loss: 2.8308229446411133\n",
            "Frame 187 of 744\n",
            "Loss: 2.7474162578582764\n",
            "Frame 188 of 744\n",
            "Loss: 2.8130695819854736\n",
            "Frame 189 of 744\n",
            "Loss: 2.786116361618042\n",
            "Frame 190 of 744\n",
            "Loss: 2.802398681640625\n",
            "Frame 191 of 744\n",
            "Loss: 2.809385061264038\n",
            "Frame 192 of 744\n",
            "Loss: 2.7471272945404053\n",
            "Frame 193 of 744\n",
            "Loss: 2.787999391555786\n",
            "Frame 194 of 744\n",
            "Loss: 2.9116179943084717\n",
            "Frame 195 of 744\n",
            "Loss: 2.8045904636383057\n",
            "Frame 196 of 744\n",
            "Loss: 2.7710163593292236\n",
            "Frame 197 of 744\n",
            "Loss: 2.7780635356903076\n",
            "Frame 198 of 744\n",
            "Loss: 2.8489761352539062\n",
            "Frame 199 of 744\n",
            "Loss: 2.85982608795166\n",
            "Frame 200 of 744\n",
            "Loss: 2.842977523803711\n",
            "Frame 201 of 744\n",
            "Loss: 2.8406131267547607\n",
            "Frame 202 of 744\n",
            "Loss: 2.7848854064941406\n",
            "Frame 203 of 744\n",
            "Loss: 2.776709794998169\n",
            "Frame 204 of 744\n",
            "Loss: 2.761328935623169\n",
            "Frame 205 of 744\n",
            "Loss: 2.753830909729004\n",
            "Frame 206 of 744\n",
            "Loss: 2.855135917663574\n",
            "Frame 207 of 744\n",
            "Loss: 2.7802207469940186\n",
            "Frame 208 of 744\n",
            "Loss: 2.7543373107910156\n",
            "Frame 209 of 744\n",
            "Loss: 2.7377402782440186\n",
            "Frame 210 of 744\n",
            "Loss: 2.868084669113159\n",
            "Frame 211 of 744\n",
            "Loss: 2.7692203521728516\n",
            "Frame 212 of 744\n",
            "Loss: 2.8074653148651123\n",
            "Frame 213 of 744\n",
            "Loss: 2.852863073348999\n",
            "Frame 214 of 744\n",
            "Loss: 2.829793691635132\n",
            "Frame 215 of 744\n",
            "Loss: 2.8444511890411377\n",
            "Frame 216 of 744\n",
            "Loss: 2.80657958984375\n",
            "Frame 217 of 744\n",
            "Loss: 2.7207632064819336\n",
            "Frame 218 of 744\n",
            "Loss: 2.703176259994507\n",
            "Frame 219 of 744\n",
            "Loss: 2.7448647022247314\n",
            "Frame 220 of 744\n",
            "Loss: 2.7940890789031982\n",
            "Frame 221 of 744\n",
            "Loss: 2.744717836380005\n",
            "Frame 222 of 744\n",
            "Loss: 2.7626664638519287\n",
            "Frame 223 of 744\n",
            "Loss: 2.813817024230957\n",
            "Frame 224 of 744\n",
            "Loss: 2.772310256958008\n",
            "Frame 225 of 744\n",
            "Loss: 2.779452323913574\n",
            "Frame 226 of 744\n",
            "Loss: 2.7473838329315186\n",
            "Frame 227 of 744\n",
            "Loss: 2.814884901046753\n",
            "Frame 228 of 744\n",
            "Loss: 2.866265058517456\n",
            "Frame 229 of 744\n",
            "Loss: 2.832538366317749\n",
            "Frame 230 of 744\n",
            "Loss: 2.795663833618164\n",
            "Frame 231 of 744\n",
            "Loss: 2.744344472885132\n",
            "Frame 232 of 744\n",
            "Loss: 2.8100640773773193\n",
            "Frame 233 of 744\n",
            "Loss: 2.8019046783447266\n",
            "Frame 234 of 744\n",
            "Loss: 2.8082237243652344\n",
            "Frame 235 of 744\n",
            "Loss: 2.73551869392395\n",
            "Frame 236 of 744\n",
            "Loss: 2.7484874725341797\n",
            "Frame 237 of 744\n",
            "Loss: 2.719148635864258\n",
            "Frame 238 of 744\n",
            "Loss: 2.8024027347564697\n",
            "Frame 239 of 744\n",
            "Loss: 2.738241195678711\n",
            "Frame 240 of 744\n",
            "Loss: 2.798103094100952\n",
            "Frame 241 of 744\n",
            "Loss: 2.758586883544922\n",
            "Frame 242 of 744\n",
            "Loss: 2.7692902088165283\n",
            "Frame 243 of 744\n",
            "Loss: 2.7667453289031982\n",
            "Frame 244 of 744\n",
            "Loss: 2.792262315750122\n",
            "Frame 245 of 744\n",
            "Loss: 2.794238328933716\n",
            "Frame 246 of 744\n",
            "Loss: 2.7712955474853516\n",
            "Frame 247 of 744\n",
            "Loss: 2.745373487472534\n",
            "Training Loss: 2.779578564628478\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.05510752688172043\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 12\n",
            "Frame 0 of 744\n",
            "Loss: 2.772433280944824\n",
            "Frame 1 of 744\n",
            "Loss: 2.6976325511932373\n",
            "Frame 2 of 744\n",
            "Loss: 2.787851333618164\n",
            "Frame 3 of 744\n",
            "Loss: 2.8046371936798096\n",
            "Frame 4 of 744\n",
            "Loss: 2.766131639480591\n",
            "Frame 5 of 744\n",
            "Loss: 2.8011691570281982\n",
            "Frame 6 of 744\n",
            "Loss: 2.7208728790283203\n",
            "Frame 7 of 744\n",
            "Loss: 2.760545015335083\n",
            "Frame 8 of 744\n",
            "Loss: 2.74088454246521\n",
            "Frame 9 of 744\n",
            "Loss: 2.7382020950317383\n",
            "Frame 10 of 744\n",
            "Loss: 2.7717487812042236\n",
            "Frame 11 of 744\n",
            "Loss: 2.6726467609405518\n",
            "Frame 12 of 744\n",
            "Loss: 2.7062675952911377\n",
            "Frame 13 of 744\n",
            "Loss: 2.796710968017578\n",
            "Frame 14 of 744\n",
            "Loss: 2.754534959793091\n",
            "Frame 15 of 744\n",
            "Loss: 2.8049211502075195\n",
            "Frame 16 of 744\n",
            "Loss: 2.745081663131714\n",
            "Frame 17 of 744\n",
            "Loss: 2.8032538890838623\n",
            "Frame 18 of 744\n",
            "Loss: 2.7282581329345703\n",
            "Frame 19 of 744\n",
            "Loss: 2.881397247314453\n",
            "Frame 20 of 744\n",
            "Loss: 2.824639081954956\n",
            "Frame 21 of 744\n",
            "Loss: 2.8156611919403076\n",
            "Frame 22 of 744\n",
            "Loss: 2.7218263149261475\n",
            "Frame 23 of 744\n",
            "Loss: 2.7778074741363525\n",
            "Frame 24 of 744\n",
            "Loss: 2.753946542739868\n",
            "Frame 25 of 744\n",
            "Loss: 2.7536518573760986\n",
            "Frame 26 of 744\n",
            "Loss: 2.7187652587890625\n",
            "Frame 27 of 744\n",
            "Loss: 2.7936365604400635\n",
            "Frame 28 of 744\n",
            "Loss: 2.665891408920288\n",
            "Frame 29 of 744\n",
            "Loss: 2.6929051876068115\n",
            "Frame 30 of 744\n",
            "Loss: 2.8338935375213623\n",
            "Frame 31 of 744\n",
            "Loss: 2.8324050903320312\n",
            "Frame 32 of 744\n",
            "Loss: 2.7773640155792236\n",
            "Frame 33 of 744\n",
            "Loss: 2.656385660171509\n",
            "Frame 34 of 744\n",
            "Loss: 2.7744390964508057\n",
            "Frame 35 of 744\n",
            "Loss: 2.743591547012329\n",
            "Frame 36 of 744\n",
            "Loss: 2.8694534301757812\n",
            "Frame 37 of 744\n",
            "Loss: 2.7450482845306396\n",
            "Frame 38 of 744\n",
            "Loss: 2.872360944747925\n",
            "Frame 39 of 744\n",
            "Loss: 2.817460060119629\n",
            "Frame 40 of 744\n",
            "Loss: 2.7005615234375\n",
            "Frame 41 of 744\n",
            "Loss: 2.836338758468628\n",
            "Frame 42 of 744\n",
            "Loss: 2.7269961833953857\n",
            "Frame 43 of 744\n",
            "Loss: 2.861583948135376\n",
            "Frame 44 of 744\n",
            "Loss: 2.8212316036224365\n",
            "Frame 45 of 744\n",
            "Loss: 2.802715301513672\n",
            "Frame 46 of 744\n",
            "Loss: 2.7649176120758057\n",
            "Frame 47 of 744\n",
            "Loss: 2.8922278881073\n",
            "Frame 48 of 744\n",
            "Loss: 2.798415184020996\n",
            "Frame 49 of 744\n",
            "Loss: 2.773075819015503\n",
            "Frame 50 of 744\n",
            "Loss: 2.8107736110687256\n",
            "Frame 51 of 744\n",
            "Loss: 2.774254083633423\n",
            "Frame 52 of 744\n",
            "Loss: 2.8396308422088623\n",
            "Frame 53 of 744\n",
            "Loss: 2.73938250541687\n",
            "Frame 54 of 744\n",
            "Loss: 2.693730592727661\n",
            "Frame 55 of 744\n",
            "Loss: 2.801778793334961\n",
            "Frame 56 of 744\n",
            "Loss: 2.7531707286834717\n",
            "Frame 57 of 744\n",
            "Loss: 2.7562482357025146\n",
            "Frame 58 of 744\n",
            "Loss: 2.713648796081543\n",
            "Frame 59 of 744\n",
            "Loss: 2.7040512561798096\n",
            "Frame 60 of 744\n",
            "Loss: 2.852076768875122\n",
            "Frame 61 of 744\n",
            "Loss: 2.7018630504608154\n",
            "Frame 62 of 744\n",
            "Loss: 2.762373685836792\n",
            "Frame 63 of 744\n",
            "Loss: 2.7674713134765625\n",
            "Frame 64 of 744\n",
            "Loss: 2.812145948410034\n",
            "Frame 65 of 744\n",
            "Loss: 2.8031044006347656\n",
            "Frame 66 of 744\n",
            "Loss: 2.778088331222534\n",
            "Frame 67 of 744\n",
            "Loss: 2.821845293045044\n",
            "Frame 68 of 744\n",
            "Loss: 2.7565619945526123\n",
            "Frame 69 of 744\n",
            "Loss: 2.79202938079834\n",
            "Frame 70 of 744\n",
            "Loss: 2.729301691055298\n",
            "Frame 71 of 744\n",
            "Loss: 2.765347719192505\n",
            "Frame 72 of 744\n",
            "Loss: 2.7163045406341553\n",
            "Frame 73 of 744\n",
            "Loss: 2.836440086364746\n",
            "Frame 74 of 744\n",
            "Loss: 2.7361514568328857\n",
            "Frame 75 of 744\n",
            "Loss: 2.755380868911743\n",
            "Frame 76 of 744\n",
            "Loss: 2.7396202087402344\n",
            "Frame 77 of 744\n",
            "Loss: 2.849583864212036\n",
            "Frame 78 of 744\n",
            "Loss: 2.774883985519409\n",
            "Frame 79 of 744\n",
            "Loss: 2.796254873275757\n",
            "Frame 80 of 744\n",
            "Loss: 2.7493321895599365\n",
            "Frame 81 of 744\n",
            "Loss: 2.7804527282714844\n",
            "Frame 82 of 744\n",
            "Loss: 2.6546638011932373\n",
            "Frame 83 of 744\n",
            "Loss: 2.8604061603546143\n",
            "Frame 84 of 744\n",
            "Loss: 2.774878740310669\n",
            "Frame 85 of 744\n",
            "Loss: 2.8260250091552734\n",
            "Frame 86 of 744\n",
            "Loss: 2.843186616897583\n",
            "Frame 87 of 744\n",
            "Loss: 2.7574880123138428\n",
            "Frame 88 of 744\n",
            "Loss: 2.7763373851776123\n",
            "Frame 89 of 744\n",
            "Loss: 2.786341905593872\n",
            "Frame 90 of 744\n",
            "Loss: 2.688555955886841\n",
            "Frame 91 of 744\n",
            "Loss: 2.760749101638794\n",
            "Frame 92 of 744\n",
            "Loss: 2.7618606090545654\n",
            "Frame 93 of 744\n",
            "Loss: 2.780787706375122\n",
            "Frame 94 of 744\n",
            "Loss: 2.766695976257324\n",
            "Frame 95 of 744\n",
            "Loss: 2.764472007751465\n",
            "Frame 96 of 744\n",
            "Loss: 2.685936689376831\n",
            "Frame 97 of 744\n",
            "Loss: 2.768157720565796\n",
            "Frame 98 of 744\n",
            "Loss: 2.8127033710479736\n",
            "Frame 99 of 744\n",
            "Loss: 2.7567615509033203\n",
            "Frame 100 of 744\n",
            "Loss: 2.6494545936584473\n",
            "Frame 101 of 744\n",
            "Loss: 2.7511441707611084\n",
            "Frame 102 of 744\n",
            "Loss: 2.81828236579895\n",
            "Frame 103 of 744\n",
            "Loss: 2.9353740215301514\n",
            "Frame 104 of 744\n",
            "Loss: 2.763136625289917\n",
            "Frame 105 of 744\n",
            "Loss: 2.675133466720581\n",
            "Frame 106 of 744\n",
            "Loss: 2.8494908809661865\n",
            "Frame 107 of 744\n",
            "Loss: 2.7720730304718018\n",
            "Frame 108 of 744\n",
            "Loss: 2.72580885887146\n",
            "Frame 109 of 744\n",
            "Loss: 2.667316198348999\n",
            "Frame 110 of 744\n",
            "Loss: 2.795076608657837\n",
            "Frame 111 of 744\n",
            "Loss: 2.793062925338745\n",
            "Frame 112 of 744\n",
            "Loss: 2.8397769927978516\n",
            "Frame 113 of 744\n",
            "Loss: 2.7214925289154053\n",
            "Frame 114 of 744\n",
            "Loss: 2.7476367950439453\n",
            "Frame 115 of 744\n",
            "Loss: 2.769319772720337\n",
            "Frame 116 of 744\n",
            "Loss: 2.7909271717071533\n",
            "Frame 117 of 744\n",
            "Loss: 2.7369754314422607\n",
            "Frame 118 of 744\n",
            "Loss: 2.8140151500701904\n",
            "Frame 119 of 744\n",
            "Loss: 2.7911465167999268\n",
            "Frame 120 of 744\n",
            "Loss: 2.820571184158325\n",
            "Frame 121 of 744\n",
            "Loss: 2.7419347763061523\n",
            "Frame 122 of 744\n",
            "Loss: 2.770066261291504\n",
            "Frame 123 of 744\n",
            "Loss: 2.8221511840820312\n",
            "Frame 124 of 744\n",
            "Loss: 2.6507532596588135\n",
            "Frame 125 of 744\n",
            "Loss: 2.798842668533325\n",
            "Frame 126 of 744\n",
            "Loss: 2.8222198486328125\n",
            "Frame 127 of 744\n",
            "Loss: 2.7512524127960205\n",
            "Frame 128 of 744\n",
            "Loss: 2.8180768489837646\n",
            "Frame 129 of 744\n",
            "Loss: 2.8137247562408447\n",
            "Frame 130 of 744\n",
            "Loss: 2.785329818725586\n",
            "Frame 131 of 744\n",
            "Loss: 2.7822043895721436\n",
            "Frame 132 of 744\n",
            "Loss: 2.888435125350952\n",
            "Frame 133 of 744\n",
            "Loss: 2.7366273403167725\n",
            "Frame 134 of 744\n",
            "Loss: 2.905890464782715\n",
            "Frame 135 of 744\n",
            "Loss: 2.819840431213379\n",
            "Frame 136 of 744\n",
            "Loss: 2.725226640701294\n",
            "Frame 137 of 744\n",
            "Loss: 2.730288505554199\n",
            "Frame 138 of 744\n",
            "Loss: 2.77591872215271\n",
            "Frame 139 of 744\n",
            "Loss: 2.8840930461883545\n",
            "Frame 140 of 744\n",
            "Loss: 2.7278759479522705\n",
            "Frame 141 of 744\n",
            "Loss: 2.9146728515625\n",
            "Frame 142 of 744\n",
            "Loss: 2.690093994140625\n",
            "Frame 143 of 744\n",
            "Loss: 2.7303545475006104\n",
            "Frame 144 of 744\n",
            "Loss: 2.831019163131714\n",
            "Frame 145 of 744\n",
            "Loss: 2.8281586170196533\n",
            "Frame 146 of 744\n",
            "Loss: 2.866147041320801\n",
            "Frame 147 of 744\n",
            "Loss: 2.806931734085083\n",
            "Frame 148 of 744\n",
            "Loss: 2.6647608280181885\n",
            "Frame 149 of 744\n",
            "Loss: 2.8372318744659424\n",
            "Frame 150 of 744\n",
            "Loss: 2.796255111694336\n",
            "Frame 151 of 744\n",
            "Loss: 2.805767059326172\n",
            "Frame 152 of 744\n",
            "Loss: 2.8457870483398438\n",
            "Frame 153 of 744\n",
            "Loss: 2.7866451740264893\n",
            "Frame 154 of 744\n",
            "Loss: 2.839813232421875\n",
            "Frame 155 of 744\n",
            "Loss: 2.841869354248047\n",
            "Frame 156 of 744\n",
            "Loss: 2.846630096435547\n",
            "Frame 157 of 744\n",
            "Loss: 2.8005168437957764\n",
            "Frame 158 of 744\n",
            "Loss: 2.7269020080566406\n",
            "Frame 159 of 744\n",
            "Loss: 2.7835142612457275\n",
            "Frame 160 of 744\n",
            "Loss: 2.854482412338257\n",
            "Frame 161 of 744\n",
            "Loss: 2.8179638385772705\n",
            "Frame 162 of 744\n",
            "Loss: 2.7355785369873047\n",
            "Frame 163 of 744\n",
            "Loss: 2.831285238265991\n",
            "Frame 164 of 744\n",
            "Loss: 2.800760269165039\n",
            "Frame 165 of 744\n",
            "Loss: 2.740560293197632\n",
            "Frame 166 of 744\n",
            "Loss: 2.7967326641082764\n",
            "Frame 167 of 744\n",
            "Loss: 2.769829034805298\n",
            "Frame 168 of 744\n",
            "Loss: 2.7513513565063477\n",
            "Frame 169 of 744\n",
            "Loss: 2.777020215988159\n",
            "Frame 170 of 744\n",
            "Loss: 2.7878990173339844\n",
            "Frame 171 of 744\n",
            "Loss: 2.778961420059204\n",
            "Frame 172 of 744\n",
            "Loss: 2.8688290119171143\n",
            "Frame 173 of 744\n",
            "Loss: 2.721472978591919\n",
            "Frame 174 of 744\n",
            "Loss: 2.7553482055664062\n",
            "Frame 175 of 744\n",
            "Loss: 2.8439509868621826\n",
            "Frame 176 of 744\n",
            "Loss: 2.724607467651367\n",
            "Frame 177 of 744\n",
            "Loss: 2.748131036758423\n",
            "Frame 178 of 744\n",
            "Loss: 2.8265068531036377\n",
            "Frame 179 of 744\n",
            "Loss: 2.791522741317749\n",
            "Frame 180 of 744\n",
            "Loss: 2.797071695327759\n",
            "Frame 181 of 744\n",
            "Loss: 2.808429718017578\n",
            "Frame 182 of 744\n",
            "Loss: 2.714432716369629\n",
            "Frame 183 of 744\n",
            "Loss: 2.8217365741729736\n",
            "Frame 184 of 744\n",
            "Loss: 2.8686676025390625\n",
            "Frame 185 of 744\n",
            "Loss: 2.8113908767700195\n",
            "Frame 186 of 744\n",
            "Loss: 2.8577849864959717\n",
            "Frame 187 of 744\n",
            "Loss: 2.7120208740234375\n",
            "Frame 188 of 744\n",
            "Loss: 2.7601375579833984\n",
            "Frame 189 of 744\n",
            "Loss: 2.817826509475708\n",
            "Frame 190 of 744\n",
            "Loss: 2.75573468208313\n",
            "Frame 191 of 744\n",
            "Loss: 2.8214404582977295\n",
            "Frame 192 of 744\n",
            "Loss: 2.7353813648223877\n",
            "Frame 193 of 744\n",
            "Loss: 2.7256338596343994\n",
            "Frame 194 of 744\n",
            "Loss: 2.7756574153900146\n",
            "Frame 195 of 744\n",
            "Loss: 2.8190548419952393\n",
            "Frame 196 of 744\n",
            "Loss: 2.7527427673339844\n",
            "Frame 197 of 744\n",
            "Loss: 2.770956039428711\n",
            "Frame 198 of 744\n",
            "Loss: 2.814037322998047\n",
            "Frame 199 of 744\n",
            "Loss: 2.769113540649414\n",
            "Frame 200 of 744\n",
            "Loss: 2.7703800201416016\n",
            "Frame 201 of 744\n",
            "Loss: 2.7715721130371094\n",
            "Frame 202 of 744\n",
            "Loss: 2.7480735778808594\n",
            "Frame 203 of 744\n",
            "Loss: 2.753122329711914\n",
            "Frame 204 of 744\n",
            "Loss: 2.807424306869507\n",
            "Frame 205 of 744\n",
            "Loss: 2.7794883251190186\n",
            "Frame 206 of 744\n",
            "Loss: 2.803788185119629\n",
            "Frame 207 of 744\n",
            "Loss: 2.810647964477539\n",
            "Frame 208 of 744\n",
            "Loss: 2.8514347076416016\n",
            "Frame 209 of 744\n",
            "Loss: 2.773284912109375\n",
            "Frame 210 of 744\n",
            "Loss: 2.731269121170044\n",
            "Frame 211 of 744\n",
            "Loss: 2.815938949584961\n",
            "Frame 212 of 744\n",
            "Loss: 2.862741470336914\n",
            "Frame 213 of 744\n",
            "Loss: 2.8468916416168213\n",
            "Frame 214 of 744\n",
            "Loss: 2.708494186401367\n",
            "Frame 215 of 744\n",
            "Loss: 2.7234106063842773\n",
            "Frame 216 of 744\n",
            "Loss: 2.749163866043091\n",
            "Frame 217 of 744\n",
            "Loss: 2.787046432495117\n",
            "Frame 218 of 744\n",
            "Loss: 2.8625190258026123\n",
            "Frame 219 of 744\n",
            "Loss: 2.714940071105957\n",
            "Frame 220 of 744\n",
            "Loss: 2.8191845417022705\n",
            "Frame 221 of 744\n",
            "Loss: 2.805006742477417\n",
            "Frame 222 of 744\n",
            "Loss: 2.7078278064727783\n",
            "Frame 223 of 744\n",
            "Loss: 2.819732666015625\n",
            "Frame 224 of 744\n",
            "Loss: 2.7325363159179688\n",
            "Frame 225 of 744\n",
            "Loss: 2.767613649368286\n",
            "Frame 226 of 744\n",
            "Loss: 2.759049654006958\n",
            "Frame 227 of 744\n",
            "Loss: 2.7861757278442383\n",
            "Frame 228 of 744\n",
            "Loss: 2.727802276611328\n",
            "Frame 229 of 744\n",
            "Loss: 2.8087337017059326\n",
            "Frame 230 of 744\n",
            "Loss: 2.811457395553589\n",
            "Frame 231 of 744\n",
            "Loss: 2.7561397552490234\n",
            "Frame 232 of 744\n",
            "Loss: 2.773218870162964\n",
            "Frame 233 of 744\n",
            "Loss: 2.8300940990448\n",
            "Frame 234 of 744\n",
            "Loss: 2.765477418899536\n",
            "Frame 235 of 744\n",
            "Loss: 2.7978031635284424\n",
            "Frame 236 of 744\n",
            "Loss: 2.7360353469848633\n",
            "Frame 237 of 744\n",
            "Loss: 2.8570241928100586\n",
            "Frame 238 of 744\n",
            "Loss: 2.784050941467285\n",
            "Frame 239 of 744\n",
            "Loss: 2.732454299926758\n",
            "Frame 240 of 744\n",
            "Loss: 2.7944142818450928\n",
            "Frame 241 of 744\n",
            "Loss: 2.7134664058685303\n",
            "Frame 242 of 744\n",
            "Loss: 2.7520816326141357\n",
            "Frame 243 of 744\n",
            "Loss: 2.7248964309692383\n",
            "Frame 244 of 744\n",
            "Loss: 2.732846260070801\n",
            "Frame 245 of 744\n",
            "Loss: 2.8224337100982666\n",
            "Frame 246 of 744\n",
            "Loss: 2.812758684158325\n",
            "Frame 247 of 744\n",
            "Loss: 2.828829526901245\n",
            "Training Loss: 2.7792239121852385\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.05913978494623656\n",
            "Test Accuracy: 0.041666666666666664\n",
            "Epoch: 13\n",
            "Frame 0 of 744\n",
            "Loss: 2.8723080158233643\n",
            "Frame 1 of 744\n",
            "Loss: 2.7295234203338623\n",
            "Frame 2 of 744\n",
            "Loss: 2.8527896404266357\n",
            "Frame 3 of 744\n",
            "Loss: 2.705580949783325\n",
            "Frame 4 of 744\n",
            "Loss: 2.808730363845825\n",
            "Frame 5 of 744\n",
            "Loss: 2.7023403644561768\n",
            "Frame 6 of 744\n",
            "Loss: 2.8006656169891357\n",
            "Frame 7 of 744\n",
            "Loss: 2.7772839069366455\n",
            "Frame 8 of 744\n",
            "Loss: 2.742804765701294\n",
            "Frame 9 of 744\n",
            "Loss: 2.6845176219940186\n",
            "Frame 10 of 744\n",
            "Loss: 2.7645957469940186\n",
            "Frame 11 of 744\n",
            "Loss: 2.7409164905548096\n",
            "Frame 12 of 744\n",
            "Loss: 2.8268892765045166\n",
            "Frame 13 of 744\n",
            "Loss: 2.8017261028289795\n",
            "Frame 14 of 744\n",
            "Loss: 2.748161554336548\n",
            "Frame 15 of 744\n",
            "Loss: 2.816479444503784\n",
            "Frame 16 of 744\n",
            "Loss: 2.7689974308013916\n",
            "Frame 17 of 744\n",
            "Loss: 2.8375351428985596\n",
            "Frame 18 of 744\n",
            "Loss: 2.7540481090545654\n",
            "Frame 19 of 744\n",
            "Loss: 2.8324520587921143\n",
            "Frame 20 of 744\n",
            "Loss: 2.7478818893432617\n",
            "Frame 21 of 744\n",
            "Loss: 2.7912609577178955\n",
            "Frame 22 of 744\n",
            "Loss: 2.8236382007598877\n",
            "Frame 23 of 744\n",
            "Loss: 2.667884111404419\n",
            "Frame 24 of 744\n",
            "Loss: 2.8009872436523438\n",
            "Frame 25 of 744\n",
            "Loss: 2.812899589538574\n",
            "Frame 26 of 744\n",
            "Loss: 2.6746864318847656\n",
            "Frame 27 of 744\n",
            "Loss: 2.7654926776885986\n",
            "Frame 28 of 744\n",
            "Loss: 2.825542449951172\n",
            "Frame 29 of 744\n",
            "Loss: 2.710709810256958\n",
            "Frame 30 of 744\n",
            "Loss: 2.7997004985809326\n",
            "Frame 31 of 744\n",
            "Loss: 2.8323357105255127\n",
            "Frame 32 of 744\n",
            "Loss: 2.7435081005096436\n",
            "Frame 33 of 744\n",
            "Loss: 2.841435194015503\n",
            "Frame 34 of 744\n",
            "Loss: 2.8384783267974854\n",
            "Frame 35 of 744\n",
            "Loss: 2.809865713119507\n",
            "Frame 36 of 744\n",
            "Loss: 2.7038328647613525\n",
            "Frame 37 of 744\n",
            "Loss: 2.742840528488159\n",
            "Frame 38 of 744\n",
            "Loss: 2.73272705078125\n",
            "Frame 39 of 744\n",
            "Loss: 2.7894668579101562\n",
            "Frame 40 of 744\n",
            "Loss: 2.8289718627929688\n",
            "Frame 41 of 744\n",
            "Loss: 2.769817352294922\n",
            "Frame 42 of 744\n",
            "Loss: 2.782263994216919\n",
            "Frame 43 of 744\n",
            "Loss: 2.794405937194824\n",
            "Frame 44 of 744\n",
            "Loss: 2.7537050247192383\n",
            "Frame 45 of 744\n",
            "Loss: 2.711440086364746\n",
            "Frame 46 of 744\n",
            "Loss: 2.808871030807495\n",
            "Frame 47 of 744\n",
            "Loss: 2.7408931255340576\n",
            "Frame 48 of 744\n",
            "Loss: 2.8735225200653076\n",
            "Frame 49 of 744\n",
            "Loss: 2.7152678966522217\n",
            "Frame 50 of 744\n",
            "Loss: 2.7073519229888916\n",
            "Frame 51 of 744\n",
            "Loss: 2.7635717391967773\n",
            "Frame 52 of 744\n",
            "Loss: 2.7356300354003906\n",
            "Frame 53 of 744\n",
            "Loss: 2.7215499877929688\n",
            "Frame 54 of 744\n",
            "Loss: 2.8314778804779053\n",
            "Frame 55 of 744\n",
            "Loss: 2.787177801132202\n",
            "Frame 56 of 744\n",
            "Loss: 2.807819366455078\n",
            "Frame 57 of 744\n",
            "Loss: 2.733691930770874\n",
            "Frame 58 of 744\n",
            "Loss: 2.8166351318359375\n",
            "Frame 59 of 744\n",
            "Loss: 2.7596664428710938\n",
            "Frame 60 of 744\n",
            "Loss: 2.8293144702911377\n",
            "Frame 61 of 744\n",
            "Loss: 2.8117897510528564\n",
            "Frame 62 of 744\n",
            "Loss: 2.9268815517425537\n",
            "Frame 63 of 744\n",
            "Loss: 2.77693247795105\n",
            "Frame 64 of 744\n",
            "Loss: 2.803468704223633\n",
            "Frame 65 of 744\n",
            "Loss: 2.723187208175659\n",
            "Frame 66 of 744\n",
            "Loss: 2.8436005115509033\n",
            "Frame 67 of 744\n",
            "Loss: 2.6759021282196045\n",
            "Frame 68 of 744\n",
            "Loss: 2.7777318954467773\n",
            "Frame 69 of 744\n",
            "Loss: 2.8270137310028076\n",
            "Frame 70 of 744\n",
            "Loss: 2.8440380096435547\n",
            "Frame 71 of 744\n",
            "Loss: 2.7024316787719727\n",
            "Frame 72 of 744\n",
            "Loss: 2.70880389213562\n",
            "Frame 73 of 744\n",
            "Loss: 2.7387588024139404\n",
            "Frame 74 of 744\n",
            "Loss: 2.721867322921753\n",
            "Frame 75 of 744\n",
            "Loss: 2.811372756958008\n",
            "Frame 76 of 744\n",
            "Loss: 2.7650375366210938\n",
            "Frame 77 of 744\n",
            "Loss: 2.748520612716675\n",
            "Frame 78 of 744\n",
            "Loss: 2.7659380435943604\n",
            "Frame 79 of 744\n",
            "Loss: 2.765432596206665\n",
            "Frame 80 of 744\n",
            "Loss: 2.770610809326172\n",
            "Frame 81 of 744\n",
            "Loss: 2.8204081058502197\n",
            "Frame 82 of 744\n",
            "Loss: 2.7949111461639404\n",
            "Frame 83 of 744\n",
            "Loss: 2.851877212524414\n",
            "Frame 84 of 744\n",
            "Loss: 2.8847217559814453\n",
            "Frame 85 of 744\n",
            "Loss: 2.7787857055664062\n",
            "Frame 86 of 744\n",
            "Loss: 2.776742696762085\n",
            "Frame 87 of 744\n",
            "Loss: 2.7784669399261475\n",
            "Frame 88 of 744\n",
            "Loss: 2.71579909324646\n",
            "Frame 89 of 744\n",
            "Loss: 2.786191701889038\n",
            "Frame 90 of 744\n",
            "Loss: 2.8040740489959717\n",
            "Frame 91 of 744\n",
            "Loss: 2.8124916553497314\n",
            "Frame 92 of 744\n",
            "Loss: 2.8341596126556396\n",
            "Frame 93 of 744\n",
            "Loss: 2.759845495223999\n",
            "Frame 94 of 744\n",
            "Loss: 2.905970335006714\n",
            "Frame 95 of 744\n",
            "Loss: 2.7812719345092773\n",
            "Frame 96 of 744\n",
            "Loss: 2.715113639831543\n",
            "Frame 97 of 744\n",
            "Loss: 2.7670958042144775\n",
            "Frame 98 of 744\n",
            "Loss: 2.873765707015991\n",
            "Frame 99 of 744\n",
            "Loss: 2.7609360218048096\n",
            "Frame 100 of 744\n",
            "Loss: 2.7185375690460205\n",
            "Frame 101 of 744\n",
            "Loss: 2.748237371444702\n",
            "Frame 102 of 744\n",
            "Loss: 2.7882492542266846\n",
            "Frame 103 of 744\n",
            "Loss: 2.769523859024048\n",
            "Frame 104 of 744\n",
            "Loss: 2.7920753955841064\n",
            "Frame 105 of 744\n",
            "Loss: 2.7844550609588623\n",
            "Frame 106 of 744\n",
            "Loss: 2.8283941745758057\n",
            "Frame 107 of 744\n",
            "Loss: 2.7774837017059326\n",
            "Frame 108 of 744\n",
            "Loss: 2.755143165588379\n",
            "Frame 109 of 744\n",
            "Loss: 2.87290358543396\n",
            "Frame 110 of 744\n",
            "Loss: 2.7578704357147217\n",
            "Frame 111 of 744\n",
            "Loss: 2.8106889724731445\n",
            "Frame 112 of 744\n",
            "Loss: 2.847578287124634\n",
            "Frame 113 of 744\n",
            "Loss: 2.816546678543091\n",
            "Frame 114 of 744\n",
            "Loss: 2.7668533325195312\n",
            "Frame 115 of 744\n",
            "Loss: 2.761445999145508\n",
            "Frame 116 of 744\n",
            "Loss: 2.7767393589019775\n",
            "Frame 117 of 744\n",
            "Loss: 2.7668142318725586\n",
            "Frame 118 of 744\n",
            "Loss: 2.735915422439575\n",
            "Frame 119 of 744\n",
            "Loss: 2.787602186203003\n",
            "Frame 120 of 744\n",
            "Loss: 2.8054988384246826\n",
            "Frame 121 of 744\n",
            "Loss: 2.7348973751068115\n",
            "Frame 122 of 744\n",
            "Loss: 2.748552083969116\n",
            "Frame 123 of 744\n",
            "Loss: 2.827113151550293\n",
            "Frame 124 of 744\n",
            "Loss: 2.7298707962036133\n",
            "Frame 125 of 744\n",
            "Loss: 2.8117458820343018\n",
            "Frame 126 of 744\n",
            "Loss: 2.786252737045288\n",
            "Frame 127 of 744\n",
            "Loss: 2.7606866359710693\n",
            "Frame 128 of 744\n",
            "Loss: 2.761084794998169\n",
            "Frame 129 of 744\n",
            "Loss: 2.738292932510376\n",
            "Frame 130 of 744\n",
            "Loss: 2.743713617324829\n",
            "Frame 131 of 744\n",
            "Loss: 2.7761428356170654\n",
            "Frame 132 of 744\n",
            "Loss: 2.767808675765991\n",
            "Frame 133 of 744\n",
            "Loss: 2.7266883850097656\n",
            "Frame 134 of 744\n",
            "Loss: 2.7952346801757812\n",
            "Frame 135 of 744\n",
            "Loss: 2.8741037845611572\n",
            "Frame 136 of 744\n",
            "Loss: 2.7173373699188232\n",
            "Frame 137 of 744\n",
            "Loss: 2.738581418991089\n",
            "Frame 138 of 744\n",
            "Loss: 2.7533576488494873\n",
            "Frame 139 of 744\n",
            "Loss: 2.7663238048553467\n",
            "Frame 140 of 744\n",
            "Loss: 2.7310101985931396\n",
            "Frame 141 of 744\n",
            "Loss: 2.794529914855957\n",
            "Frame 142 of 744\n",
            "Loss: 2.723846435546875\n",
            "Frame 143 of 744\n",
            "Loss: 2.742020606994629\n",
            "Frame 144 of 744\n",
            "Loss: 2.8097126483917236\n",
            "Frame 145 of 744\n",
            "Loss: 2.763543128967285\n",
            "Frame 146 of 744\n",
            "Loss: 2.7542035579681396\n",
            "Frame 147 of 744\n",
            "Loss: 2.766122817993164\n",
            "Frame 148 of 744\n",
            "Loss: 2.843400239944458\n",
            "Frame 149 of 744\n",
            "Loss: 2.7626407146453857\n",
            "Frame 150 of 744\n",
            "Loss: 2.8568782806396484\n",
            "Frame 151 of 744\n",
            "Loss: 2.8581018447875977\n",
            "Frame 152 of 744\n",
            "Loss: 2.755152702331543\n",
            "Frame 153 of 744\n",
            "Loss: 2.8791017532348633\n",
            "Frame 154 of 744\n",
            "Loss: 2.7355897426605225\n",
            "Frame 155 of 744\n",
            "Loss: 2.7449753284454346\n",
            "Frame 156 of 744\n",
            "Loss: 2.8212015628814697\n",
            "Frame 157 of 744\n",
            "Loss: 2.7388622760772705\n",
            "Frame 158 of 744\n",
            "Loss: 2.802724838256836\n",
            "Frame 159 of 744\n",
            "Loss: 2.7614691257476807\n",
            "Frame 160 of 744\n",
            "Loss: 2.8800604343414307\n",
            "Frame 161 of 744\n",
            "Loss: 2.715937852859497\n",
            "Frame 162 of 744\n",
            "Loss: 2.850613832473755\n",
            "Frame 163 of 744\n",
            "Loss: 2.902859687805176\n",
            "Frame 164 of 744\n",
            "Loss: 2.877481460571289\n",
            "Frame 165 of 744\n",
            "Loss: 2.890561103820801\n",
            "Frame 166 of 744\n",
            "Loss: 2.7820770740509033\n",
            "Frame 167 of 744\n",
            "Loss: 2.8318850994110107\n",
            "Frame 168 of 744\n",
            "Loss: 2.777092695236206\n",
            "Frame 169 of 744\n",
            "Loss: 2.8209686279296875\n",
            "Frame 170 of 744\n",
            "Loss: 2.7229137420654297\n",
            "Frame 171 of 744\n",
            "Loss: 2.810715913772583\n",
            "Frame 172 of 744\n",
            "Loss: 2.786968946456909\n",
            "Frame 173 of 744\n",
            "Loss: 2.7340304851531982\n",
            "Frame 174 of 744\n",
            "Loss: 2.786022901535034\n",
            "Frame 175 of 744\n",
            "Loss: 2.776324987411499\n",
            "Frame 176 of 744\n",
            "Loss: 2.734161615371704\n",
            "Frame 177 of 744\n",
            "Loss: 2.824312925338745\n",
            "Frame 178 of 744\n",
            "Loss: 2.7988345623016357\n",
            "Frame 179 of 744\n",
            "Loss: 2.7893781661987305\n",
            "Frame 180 of 744\n",
            "Loss: 2.7243759632110596\n",
            "Frame 181 of 744\n",
            "Loss: 2.7922275066375732\n",
            "Frame 182 of 744\n",
            "Loss: 2.7757322788238525\n",
            "Frame 183 of 744\n",
            "Loss: 2.7422351837158203\n",
            "Frame 184 of 744\n",
            "Loss: 2.810612916946411\n",
            "Frame 185 of 744\n",
            "Loss: 2.7734105587005615\n",
            "Frame 186 of 744\n",
            "Loss: 2.8216359615325928\n",
            "Frame 187 of 744\n",
            "Loss: 2.795356512069702\n",
            "Frame 188 of 744\n",
            "Loss: 2.7818031311035156\n",
            "Frame 189 of 744\n",
            "Loss: 2.7457115650177\n",
            "Frame 190 of 744\n",
            "Loss: 2.8024051189422607\n",
            "Frame 191 of 744\n",
            "Loss: 2.757127046585083\n",
            "Frame 192 of 744\n",
            "Loss: 2.737377166748047\n",
            "Frame 193 of 744\n",
            "Loss: 2.7997448444366455\n",
            "Frame 194 of 744\n",
            "Loss: 2.7650864124298096\n",
            "Frame 195 of 744\n",
            "Loss: 2.814486503601074\n",
            "Frame 196 of 744\n",
            "Loss: 2.778531074523926\n",
            "Frame 197 of 744\n",
            "Loss: 2.77258038520813\n",
            "Frame 198 of 744\n",
            "Loss: 2.7429769039154053\n",
            "Frame 199 of 744\n",
            "Loss: 2.800567865371704\n",
            "Frame 200 of 744\n",
            "Loss: 2.7408809661865234\n",
            "Frame 201 of 744\n",
            "Loss: 2.711160898208618\n",
            "Frame 202 of 744\n",
            "Loss: 2.8143889904022217\n",
            "Frame 203 of 744\n",
            "Loss: 2.794135808944702\n",
            "Frame 204 of 744\n",
            "Loss: 2.7969095706939697\n",
            "Frame 205 of 744\n",
            "Loss: 2.769418716430664\n",
            "Frame 206 of 744\n",
            "Loss: 2.7222957611083984\n",
            "Frame 207 of 744\n",
            "Loss: 2.8243486881256104\n",
            "Frame 208 of 744\n",
            "Loss: 2.745656967163086\n",
            "Frame 209 of 744\n",
            "Loss: 2.7248382568359375\n",
            "Frame 210 of 744\n",
            "Loss: 2.7882678508758545\n",
            "Frame 211 of 744\n",
            "Loss: 2.8051204681396484\n",
            "Frame 212 of 744\n",
            "Loss: 2.7576920986175537\n",
            "Frame 213 of 744\n",
            "Loss: 2.787274122238159\n",
            "Frame 214 of 744\n",
            "Loss: 2.753535509109497\n",
            "Frame 215 of 744\n",
            "Loss: 2.774038076400757\n",
            "Frame 216 of 744\n",
            "Loss: 2.79294753074646\n",
            "Frame 217 of 744\n",
            "Loss: 2.817927360534668\n",
            "Frame 218 of 744\n",
            "Loss: 2.751331329345703\n",
            "Frame 219 of 744\n",
            "Loss: 2.7817211151123047\n",
            "Frame 220 of 744\n",
            "Loss: 2.7993829250335693\n",
            "Frame 221 of 744\n",
            "Loss: 2.748640298843384\n",
            "Frame 222 of 744\n",
            "Loss: 2.7556378841400146\n",
            "Frame 223 of 744\n",
            "Loss: 2.733365297317505\n",
            "Frame 224 of 744\n",
            "Loss: 2.7648611068725586\n",
            "Frame 225 of 744\n",
            "Loss: 2.75846791267395\n",
            "Frame 226 of 744\n",
            "Loss: 2.7596518993377686\n",
            "Frame 227 of 744\n",
            "Loss: 2.789940118789673\n",
            "Frame 228 of 744\n",
            "Loss: 2.808583974838257\n",
            "Frame 229 of 744\n",
            "Loss: 2.736250638961792\n",
            "Frame 230 of 744\n",
            "Loss: 2.772223472595215\n",
            "Frame 231 of 744\n",
            "Loss: 2.7210817337036133\n",
            "Frame 232 of 744\n",
            "Loss: 2.8454182147979736\n",
            "Frame 233 of 744\n",
            "Loss: 2.7104709148406982\n",
            "Frame 234 of 744\n",
            "Loss: 2.7895896434783936\n",
            "Frame 235 of 744\n",
            "Loss: 2.8401191234588623\n",
            "Frame 236 of 744\n",
            "Loss: 2.730480194091797\n",
            "Frame 237 of 744\n",
            "Loss: 2.740337610244751\n",
            "Frame 238 of 744\n",
            "Loss: 2.864435911178589\n",
            "Frame 239 of 744\n",
            "Loss: 2.8212382793426514\n",
            "Frame 240 of 744\n",
            "Loss: 2.7951934337615967\n",
            "Frame 241 of 744\n",
            "Loss: 2.75716233253479\n",
            "Frame 242 of 744\n",
            "Loss: 2.726470947265625\n",
            "Frame 243 of 744\n",
            "Loss: 2.7857744693756104\n",
            "Frame 244 of 744\n",
            "Loss: 2.7825090885162354\n",
            "Frame 245 of 744\n",
            "Loss: 2.8508870601654053\n",
            "Frame 246 of 744\n",
            "Loss: 2.7637574672698975\n",
            "Frame 247 of 744\n",
            "Loss: 2.7710676193237305\n",
            "Training Loss: 2.7801775172833474\n",
            "Validation Loss: nan\n",
            "Train Accuracy: 0.06048387096774193\n",
            "Test Accuracy: 0.046296296296296294\n",
            "Epoch: 14\n",
            "Frame 0 of 744\n",
            "Loss: 2.775787115097046\n",
            "Frame 1 of 744\n",
            "Loss: 2.73807430267334\n",
            "Frame 2 of 744\n",
            "Loss: 2.7571942806243896\n",
            "Frame 3 of 744\n",
            "Loss: 2.762688398361206\n",
            "Frame 4 of 744\n",
            "Loss: 2.740121841430664\n",
            "Frame 5 of 744\n",
            "Loss: 2.715390205383301\n",
            "Frame 6 of 744\n",
            "Loss: 2.7724549770355225\n",
            "Frame 7 of 744\n",
            "Loss: 2.797883987426758\n",
            "Frame 8 of 744\n",
            "Loss: 2.7765579223632812\n",
            "Frame 9 of 744\n",
            "Loss: 2.9066689014434814\n",
            "Frame 10 of 744\n",
            "Loss: 2.806067705154419\n",
            "Frame 11 of 744\n",
            "Loss: 2.760563611984253\n",
            "Frame 12 of 744\n",
            "Loss: 2.8008840084075928\n",
            "Frame 13 of 744\n",
            "Loss: 2.8583710193634033\n",
            "Frame 14 of 744\n",
            "Loss: 2.8093385696411133\n",
            "Frame 15 of 744\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-adbf78f4d54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;31m#print(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m#print(outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "\n",
        "data = mat73.loadmat('data_unmixed_and_averaged.mat')\n",
        "data = data['data_unmixed']\n",
        "windows = np.zeros([330, 330, 960])\n",
        "tones = np.zeros([16, 960])\n",
        "\n",
        "k = 0\n",
        "for i in range(16) :\n",
        "    for j in range(2) :\n",
        "        for l in range(30) :\n",
        "            windows[:, :, k] = data[:, :, l, i, j]\n",
        "            one_hot = np.zeros(16)\n",
        "            one_hot[i] = 1\n",
        "            tones[:, k] = one_hot\n",
        "            k += 1\n",
        "\n",
        "print(\"Input shape:\", windows[:, :, 0].shape)\n",
        "\n",
        "transform = transforms.Resize((150,150))\n",
        "\n",
        "trainFraction = .8\n",
        "sample = np.random.uniform(size = 960) < trainFraction\n",
        "xtrain = torch.from_numpy(windows[:, :, sample])\n",
        "ytrain = torch.from_numpy(tones[:, sample])\n",
        "xtest = torch.from_numpy(windows[:, :, ~sample])\n",
        "ytest = torch.from_numpy(tones[:, ~sample])\n",
        "\n",
        "#print(len(xtest[1, 1, :]))\n",
        "\n",
        "print(\"Training dataset size:\", len(xtrain[1, 1, :]), \"Testing dataset size:\", len(xtest[1, 1, :]))\n",
        "\n",
        "train_toneDataset = NeuralDataset(xtrain, ytrain, transforms = transform)\n",
        "test_toneDataset = NeuralDataset(xtest, ytest, transforms= transform)\n",
        "\n",
        "training_loader = DataLoader(train_toneDataset, batch_size=3, shuffle=True, num_workers=2)\n",
        "testing_loader = DataLoader(test_toneDataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "\n",
        "class Classifier(nn.Module) :\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 32, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2,2),\n",
        "        \n",
        "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            \n",
        "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(430336,1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,16)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.network(x) \n",
        "\n",
        "\n",
        "trainLoss = []\n",
        "valLoss = []\n",
        "trainAcc = []\n",
        "valAcc = []\n",
        "testAcc = []\n",
        "\n",
        "model = Classifier()\n",
        "optimizer =  torch.optim.Adam(model.parameters(), lr = .01, betas = [.9, .999])\n",
        "loss= torch.nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "\n",
        "def getAcc(gt, out) :\n",
        "  correct = 0\n",
        "  wrong = 0\n",
        "  for i, k in zip(gt, out) :\n",
        "    if i == k :\n",
        "      correct += 1\n",
        "    else :\n",
        "      wrong += 1\n",
        "  accuracy = correct / (correct + wrong)\n",
        "  return accuracy\n",
        "\n",
        "for epoch in range(50):  # loop over the dataset multiple times\n",
        "    print(\"Epoch:\", epoch)\n",
        "    trainOuts = []\n",
        "    valOuts = []\n",
        "    epochLossT = []\n",
        "    epochLossV = []\n",
        "      \n",
        "    trainEpochAccs = []\n",
        "    model.train()\n",
        "    model = model.float()\n",
        "\n",
        "    idx = torch.randperm(xtrain.size(2))\n",
        "    xtrain = xtrain[:, :, idx]\n",
        "    ytrain = ytrain[:, idx]\n",
        "\n",
        "    for i, (input, label) in enumerate(training_loader):\n",
        "        print(\"Frame\", i, \"of\", len(xtrain[1, 1, :]))\n",
        "        #print(input.shape)\n",
        "        #print(label.shape)\n",
        "        #inputs = xtrain[:, :, i]\n",
        "        #label = ytrain[:, i]\n",
        "        #input = torch.unsqueeze(input, 0)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        \n",
        "        outputs = model(input.float().cuda())\n",
        "        #print(outputs)\n",
        "        #print(outputs.shape)\n",
        "        #print(label)\n",
        "        #print(label.shape)\n",
        "\n",
        "        l = loss(outputs, torch.argmax(label.cuda(), dim = 1))\n",
        "        print(\"Loss:\", l.item())\n",
        "        epochLossT.append(l.item())\n",
        "        a = getAcc(torch.argmax(label, dim = 1), torch.argmax(outputs, dim = 1))\n",
        "        trainEpochAccs.append(a)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "\n",
        "    testOuts = []\n",
        "    testLabels = []\n",
        "    model.eval()\n",
        "    for i, (input, label) in enumerate(testing_loader):\n",
        "        #inputs = xtest[:, :, k]\n",
        "        #labels = ytest[:, k]\n",
        "        #input = torch.unsqueeze(input, 0)\n",
        "        testOut = model(input.float().cuda())\n",
        "        testOuts.append(torch.argmax(testOut))\n",
        "        testLabels.append(torch.argmax(label))\n",
        "\n",
        "    #report stats every epoch\n",
        "    print(\"Training Loss:\", np.mean(epochLossT))\n",
        "    trainLoss.append(np.mean(epochLossT))\n",
        "    print(\"Validation Loss:\", np.mean(epochLossV))\n",
        "    valLoss.append(np.mean(epochLossV))\n",
        "\n",
        "    trainingAcc = np.mean(trainEpochAccs)\n",
        "    testingAcc = getAcc(testLabels, testOuts)\n",
        "    print(\"Train Accuracy:\", trainingAcc)\n",
        "    trainAcc.append(trainingAcc)\n",
        "    print(\"Test Accuracy:\", testingAcc)\n",
        "    testAcc.append(testingAcc)\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(50), trainLoss, color='darkorange')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs Epoch')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(50), testAcc, color='darkblue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Test Accuracy vs Epoch')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(range(14), trainLoss, color='darkorange')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs Epoch')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(14), testAcc, color='darkblue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Test Accuracy vs Epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "TCr_oZ6Qn83f",
        "outputId": "c796a6d3-e419-4d50-d4ad-2081026e5dd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Test Accuracy vs Epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29e3glV3Xg+1t6v/up7la3VKc91wbSNmOb9Ng8gi/BZMYmxOYGEwyBmAkJQybm4gESA8PHGLjhG8hcmwR7whBI8BCDIZ0w40sajGPzCC/jBszD2A4du09JanW3ut2tI6n11rp/VJV1fPpIOkc6VbXraP2+T5/qdarWOVW119prr7WXqCqGYRiGUSkNaQtgGIZhZAtTHIZhGEZVmOIwDMMwqsIUh2EYhlEVpjgMwzCMqjDFYRiGYVSFKQ7DMFJBRF4iIkNpy2FUjykOIxFEZKLob1FEporWf3sN5/u6iPxeBcd1hdf48tok3xiIyF4R0ZL7NCEir0lbNsM9mtIWwNgYqGpXtCwiR4DfU9V/TODSrwJmgF8TkV2qeiyBawIgIk2qOp/U9WrE5gzKbCSM9TiMVBGRBhF5l4j8i4icEpEviMjWcF+biPxNuP2MiDwkIjtF5E+AFwO3h1bx7Stc4gbg48BPgNeXXPtXROQ74bkHReSN4fZ2Efl/RSQvImMi8q1w2zmuFRE5IiIvC5dvEZEDocwF4I0icpmIfDe8xoiI3C4iLUWfv1BE7hORp0TkuIi8R0R2ichZEdlWdNzzRGRURJpLrr877L1tLdp2qYicFJFmETlfRL4Rfo+TIvL5au5P0Tk/LSIfD2UdD8+ZK9r/wvD+jIX/X1i0b6uI/LWIHBWR0yLyv0rO/Q4RORH+Pv9+LfIZyWKKw0ibtwKvBP5PYDdwGrgj3HcDsAkYALYBbwGmVPU/A/8E3KiqXap6Y7kThw3bS4C7wr/fKdn3ZeBjQC9wCfBwuPu/Ab8MvBDYCvwxsFjh97kWOABsDq+5APwnYDvwAuBK4D+GMnQD/wh8Jfzu5wP3h72irwO/VXTeNwB3q+pc8cVU9SjwXYKeVcTrgAPhsR8EvgpsAfrD77tWfjs833aC3+qu8HtsBf4B+HOC+3Qr8A9Fiu8zQAdwIbADuK3onLsI7vEe4E3AHSKyZR0yGkmgqvZnf4n+AUeAl4XLjwJXFu3rA+YI3Ki/C3wH+NdlzvF1AnfXStd5L/BwuLyHoBG/NFx/N/DFMp9pAKaAi8vsewkwtMJ3uQX45ioy3RRdF3gt8KNljnsN8O1wuRE4Bly2zLG/BzwQLgswCFwRrv9P4BNA/ypy7QUUOFPy90vh/k8TKK7o+K7w9xwgUGrfLznfd4E3hvdzEdiyzO85BTQVbTsBPD/tZ9T+Vv6zHoeRNjngi6Er5wyBIlkAdhJYqvcCd4dujo+UumpW4XcIrWJVHQa+QdCLgaDB+5cyn9kOtC2zrxIGi1dE5Fki8iURORa6rz4UXmMlGQD+N7BPRM4Dfg0YU9XvL3Ps3wEvEJE+4AqChvqfwn1/TKBMvi8ij4jI764i/3ZV3Vz092i576aqE8BTBD2l3UC+5Dx5AmU9ADylqqeXud4pfeaYylkCpWQ4jCkOI20GgatLGqs2VR1W1TlVfb+q7iNwG72CJXfTitM6hz72C4B3h432MeBy4HUi0hRe9/8o89GTwPQy+yYJXC7RNRoJ3FzFlMr1F8BjwAWq2gO8h6Ahj777vyonv6pOA18gGJd5A4ESLUvYKH+VoJfyOoKegYb7jqnq76vqbuA/AP9dRM5f7lyrMBAtiEgXgRvvaPiXKznWA4YJvuNWEdm8xmsaDmKKw0ibjwN/Eg20ikiviFwbLv+qiDw3bKALBC6saKzhOMs0uiE3APcB+wjGLy4BLgLagasJeiIvE5HfEpEmEdkmIpeo6iLwV8Ct4cBzo4i8QERagX8G2kTk18Oez3uB1lW+X3co+4SIPAf4g6J9XwL6ROQmEWkVkW4Rubxo//8kcPdcwwqKI+SzBEr1unAZABF5tYj0h6unCRRbpeM1pbw8DChoIRjr+J6qDgIHgWeJyOvC3/I1BL/7l1R1hGAs6b+LyJZwwP6KNV7fcARTHEba/BlwD/BVERkHvkfQM4Bg4PQAQcP7KIGr6TNFn7sujNL58+ITikgbwcDyx0KLO/p7Mvz8DarqAy8H3kHgcnkYuDg8xTuBnwIPhfs+DDSo6hjBwPYnCazpSWC1BLZ3EvQCxoG/BJ6OalLVcQI31G8QjGH8AvjVov3fJmjkf6iqpa6gUu4h6GEdU9UfF23/N8CDIjIRHvM2VX1ihfOckWfmcby9aN9ngf9C8Jv8MmGUmqqeIugNvgM4ReAee4Wqngw/9wYCpf8YwRjGTat8F8NxJOzRGobhICLyAPBZVf1kynJ8miAw4L1pymG4gSUAGoajiMi/AZ5HEOJrGM5grirDcBARuZMgx+Om0KVlGM5grirDMAyjKqzHYRiGYVTFhhjj2L59u+7duzdtMQzDMDLDD37wg5OqWpqnBGwQxbF3714OHTqUthiGYRiZQUSWDQE3V5VhGIZRFaY4DMMwjKowxWEYhmFUhSkOwzAMoypMcRiGYRhVYYrDMAzDqApTHIZhGEZVbIg8jrXywQ9+l7m5hdjOf9FF2/mt33pObOePi+997ygHD640M/f62LSplZtu+mUaG82uSYqf/WyUkyeneMlLvLRFMWrEPfcc5vHHn+KP/uiymp/bFMcKfPjD3+fs2blYzq0Kzc0NvOpVz8pcA3nzzd/km98cQmT1Y6slmjrthS/cwwtesLv2FzDK8t73fpuHHz7BkSNvTlsUo0YcOPDPfOMbg6Y4kmZi4m2xnft//I8f85a33MexY5Ps2dMd23XiIJ8v8PrX7+Mzn3l5zc/985+f5MILP00+XzDFkSBHjowxNDTO/PwiTU3ZMmSM8vh+Ac/rieXc9oSkhOcFyiKfL6QsSXXMzy8yNDT+tPy1ZmAgeNDz+bFYzm+UJ58vsLCgHD06kbYoRo3w/XFyOVMcdUVkCfh+tkotjIxMsLCgsVky3d0tbNnSlrnfJcsUCjOcOTMDBFaqkX0WFhYZHBy3Hke9saQ4svWiRg16XJZMdO6s/S5ZZnBwSUmbwq4Pjh2bZH5+MTbPgCmOlIgs66y5qiJ543ogo3Nn7XfJMsW/tf3u9UHcBp4pjhTxvO7MWdaRvHF1gaNzm+WbHNE9bWyUzD2PRnmWDDxTHHVH4JLJVgPp+wW2bm2jq6sltmvkcj2Mjc0wNjYT2zWMJXx/nKamBi68cLspjjohbgPPFEeKeF5P5lwD+Xx8IX4RkRvMGrFkyOcL9Pd3cd55mzL3PBrl8f0CW7a00d0dj4FniiNFPK87c5a178cXihuR1cCBrOL7BXK5HnK5wJDRKAvTyCyBgRffexqr4hCRq0TkcRE5LCLvKrO/VUQ+H+5/UET2luz3RGRCRN5ZtG2ziBwQkcdE5FEReUGc3yFOooGrwcHsNJBRIxMn0fmz5sbLKlGimOd1MzExlylDxihPYODF957GpjhEpBG4A7ga2Ae8VkT2lRz2JuC0qp4P3AZ8uGT/rcCXS7b9GfAVVX0OcDHwaK1lT4roxmbFPXDmzDSFwmzsrqqdOztpbm7IzO+SZebnFxkenggVR7aeR2N54jbw4uxxXAYcVtUnVHUWuBu4tuSYa4E7w+UDwJUiwQxIIvJK4EngkehgEdkEXAF8CkBVZ1X1TIzfIVaylgQYyRm3q6qhQRgYyF7EWRY5ejRI6IxcVZCd59EoT5TQmVVX1R5gsGh9KNxW9hhVnQfGgG0i0gXcDLy/5PjzgFHgr0XkRyLySRHpLHdxEXmziBwSkUOjo6Pr/zYxsGtXYFlnpYGM5MzlNsV+rSxGnGWRpeibbhtbqhOSCJl3dXD8FuA2VS2dOKcJeB7wF6p6KTAJnDN2AqCqn1DV/aq6v7e3N1Zh10pkWWfFNZBE8l9EFiPOskhxvP+OHR20tDTa755xkpjdIc7ZcYeBgaL1/nBbuWOGRKQJ2AScAi4HrhORjwCbgUURmSZwZw2p6oPh5w+wjOLICllKdvP9Ai0tjezcWbaTV1M8r5ujRyeYm1ugubkx9uttVIrdjw0NksmkVOOZxJ38B/H2OB4CLhCR80SkBbgeuKfkmHuAG8Ll64AHNODFqrpXVfcCHwU+pKq3q+oxYFBEnh1+5krg5zF+h9jJ0rxMvj/OwEDQwMRNLreJxUWbrTVufL/Atm3tdHYG8f5ZMmSM8vh+gebmBnbtis/Ai01xhGMWNwL3EkQ+fUFVHxGRD4jINeFhnyIY0zgMvJ3Keg9vBe4SkZ8AlwAfqr30yeF53QwPT8RaabBWxB0bXkxWp53PGkEo7tI9tR5H9vH9cfr74zXwYi3kpKoHgYMl295XtDwNvHqVc9xSsv4wsL92UqaL5/U8bVknMei8Hny/wMtelkvkWlmLOMsq+XyBCy7Y8vR6LtfD0aMTzM4u0NJiLsIskkSulauD4xuGrIRAzs0thMot3gcyYmDAph2JG1U9ZwoZz+tBFYaH3X4ejeVJwjNgiiNlspJ0NTQ0jmq8A27FdHQ009vb7vzvkmXGxmaYmJgrcVVlw5AxylOc0BknpjhSJiuWdVLJf8UEA7Vu/y5Zplz0jY0tZZujRydYXFRzVdU7kWXtuoW3lPyXTI8DLMInbsrF+2fFkDHKk0QoLpjicIIsWNZRIxM1LElgs7XGS7kM4/b2Znbs6DCFnVGKZwKIE1McDpCFLOl8vkBvbzvt7c2JXdPzupmcnOP06enErrmRyOeDhM4dOzqesd1K92aXJZey9Tjqnih23mXLOpp6O0lsoDZeohyO0nj/LCWlGs8kny+wfXs7HR3xGnimOBwgl+thYmKOM2fcrYOQRGx4KUuhytaIxcFyNRsi16nLhoxRnqQMPFMcDuB6SG65eP8ksAifeFku3t/zejh7dp5Tp6ZSkMpYD0kZeKY4HMD1GttPPTXN2bPziYbiAvT2dtDW1uTs75JlZmcXGBkpn9CZlaRU45ksGXjxv6emOBzAdZdMGqG4ACLRbK3WgNWa4eHlEzpdN2SM8pw5EyV0Wo9jQ9Db20Frq7t1EJKKDS9HFiLOsshK99R116lRniQNPFMcDhBY1u4mu6WRNR5hs7XGw0rFfrZvb6e93VyEWSPJQmumOBzB5RBI3y/Q1tZEb2/H6gfXmFyuh5GRSWZm5hO/dj0TPWv9/V3n7HPdkDHKk0TJ2AhTHI7gctJVNOAmEn8Bp1Kil2BoyAo61ZJ8vsCOHR3LJnS6/Dwa5fH9cVpbz03ojANTHI7gee5a1mkk/0UsJQFaI1ZLfH98RV+4yz1gozxRyHwSBp4pDkeIXuLhYfcs69UamThxPeIsq5RW/ivF83o4fvws09PuGTJGeVa7p7XEFIcjuBrJMj09z7Fjk6kMjMOSD9613yXLVJLQGd3vwUEb58gKSRp4pjgcwdXY+aGhZCZNW47W1iZ27eq0gdoacurUFFNT86u6qsC959EoT5TQmdR7aorDEZbqILjVQK4UtpkU5m+vLZXMoGpjS9liqUKnuao2FJFl7ZpLJp8fA9LrcQTXtgifWlJJzYb+/m5E3DNkjPIsJf9tSuR6pjgcwsVkt6jhKBfvnxRRToHN1lobIiW8Ui+ypaWRvr4uU9gZIcnkPzDF4RSBS8YtC8/3C/T1ddLa2pSaDJ7Xw/T0PCdP2myttcD3C7S3N7FtW/uKx7loyBjlWTLwTHFsOFysg5DGdOqlRJaxWb+1IarDsVq8v2WPZwffL7BzZzCbdBKY4nAIz+thasotyzpoZNIJxY1wNeIsq+TzldVsiIISFhfdMWSM8iSda2WKwyFcC4FU1VQq/5ViJWRrS6WJYp7XzczMAqOjZxOQylgPSXsGTHE4hGsV706cOMvMzELqrqqtW9vo7Gx25nfJMtPT8xw/fraie2ohudkgMvCS9AyY4nAI1yzrJGfbXImlgk7WgK2XKBO8UlcVuGPIGOVZSuhMJhQXTHE4RWRZu9JAupD8FxEFDhjro5IcjgjXDBmjPEmH4oIpDqeILGtXLLw0HsjlyOWsEmAtqKYXuXlzK11d7hgyRnkqmQmg1pjicAyXLGvfL9DZ2cyWLW1pi4Ln9TA6OsXU1FzaomSafL6ASGXx/lFBJ1PYbpNkydgIUxyO4VISYBTil0YBp1Jsttba4Pvj9PV10dLSWNHxLj2PRnny+QIdHU1s3ZqcgWeKwzE8r4cTJ846YVknHamxEjZQWxuqvacu9YCN8kSF1pI08GJVHCJylYg8LiKHReRdZfa3isjnw/0Pisjekv2eiEyIyDuLth0RkZ+KyMMicihO+dPAJcvahazxCBuorQ3V3lPP6+bkySkmJ2djlMpYD2kUWotNcYhII3AHcDWwD3itiOwrOexNwGlVPR+4Dfhwyf5bgS+XOf2vquolqrq/xmKnzlISYLoN5Nmzc5w8OeVERBXAnj1dNDSIWb/rYHFRGRysrpGJjnXBkDHKk4aBF2eP4zLgsKo+oaqzwN3AtSXHXAvcGS4fAK6UsL8lIq8EngQeiVFG53Al6SpqKFzpcTQ3N7J7t83Wuh5GR6OEzupcVZC+IWOUZ2pqjhMnzibuUo5TcewBBovWh8JtZY9R1XlgDNgmIl3AzcD7y5xXga+KyA9E5M01lzplIss67QbSpVDcCEsCXB9L97Q6V1XxZw23GBqaAJLPtXJ1cPwW4DZVnSiz71dU9XkELrA/FJEryp1ARN4sIodE5NDo6GiMotaWyLJOu4FMI8RvNWy21vWxlnu6Z0+3uQgdZi3GQC2IU3EMAwNF6/3htrLHiEgTsAk4BVwOfEREjgA3Ae8RkRsBVHU4/H8C+CKBS+wcVPUTqrpfVff39vbW6jslQmBZp9tA+n6BhgZh9+70CjiVksv1MDg4brO1rpG1JIo1NTWwZ0/6hoxRnmpmAqglcSqOh4ALROQ8EWkBrgfuKTnmHuCGcPk64AENeLGq7lXVvcBHgQ+p6u0i0iki3QAi0gn8W+BnMX6HVHAh6SqfL7B7dxfNzZXF+yeB53UzO7vA8eOTaYuSSfL5Al1dzWze3FrV51x4Ho3y+H7lCZ21JDbFEY5Z3AjcCzwKfEFVHxGRD4jINeFhnyIY0zgMvB04J2S3hJ3At0Tkx8D3gX9Q1a/E8w3Sw/O6U7esXajDUYoN1K6PaIr8auP9LQnQXdIy8GItF6WqB4GDJdveV7Q8Dbx6lXPcUrT8BHBxbaV0j1yuh9nZBU6cOMuuXZ2pyOD7BS6/vC+Vay9HccSZa7JlgajyX7V4Xjd/+7fjLCws0tjo6rDoxmSt93S92FPgINGDkJZ7IIr3dyUUN8Kyx9dHlGFcLZ7Xw9zcIsePW0En10ir0JopDgdJO5fj2LFJ5uYWnXNVbdrUSk9Piw3UroHJydk1J3SawnaTxUVNzaVsisNB0i4h62IoboSF5K6NpYTO6hsZq/nuJidOnGV2Np0KnaY4HCSyrNOy8NKKDa8Eq8uxNtZTsyHtHrBRnjQNPFMcjpKmZe1KydhyWPb42oiU7VoamZ6eVjZvbjWF7RhpvqemOBwlCIFMy1U1zqZNrWzaVF28fxJ4Xg9PPTXNxITN1loN603oNBehe6Q5LZApDkdJs4RsMNumWwPjEWmP/2QV3y+wZ08XTU1re+Wtp+cevj9Od3dLKgaeKQ5HSdOyXmvYZhJYEuDayOfXF7ZpY0vusdaEzlpgisNR0qyDkEZhmEqxCJ+1sd5EMc/r4cyZGQqFmRpKZayHND0DpjgcJa0kwPHxWU6fnnbWVbV7dxeNjelPO58lFhYWGRpaX7x/9DxaQSd3SCtrHExxOEtalrXLEVUAjY0N9PenP3twlogSOtfrqgJLAnSFyclZTp1Kr0KnKQ5HiSzrpBtIl5P/IoIIH2vAKmU9ORwR5iJ0i1rc0/VgisNRIss6aQvP5eS/CBuorY5a1GzYtauTpqYG6+k5Qlp1OCJMcThMGpa174/T1NRAX186s/JWgud1MzQUzNZqrE4tjIHGxgYGBtILETeeSaTAzVVlnEMaSYC+X6C/v8vp6bM9r4eFBWVkxAo6VYLvF9i8uZWenvXF+1suhzvk8wUaG4W+vnQqdLrbOhihZT2RqGUdhPi566YCG6itllpF39jYkjusN6FzvZjicBjP62F+fjFRy9rl5L8IG6itjlrF+3teD8PDE8zPm4swbYLkv02pXd8Uh8MkPb3G/Pwiw8MTTkdUgc3WWi21KvaTywUuwqNHJ2oglbEe0p4WaFXFISK/ISKmYFJgybJOJpJlZGSChQV1Nvkvoqurha1b28xVVQGFwgxnzszUyFVlPT0XCBI6J1L1DFSiEF4D/EJEPiIiz4lbIGOJpezxsUSul4VQ3AibrbUyapnQmXZJYyPg2LFJ5ufXl9C5XlZVHKr6euBS4F+AT4vId0XkzSLitllaB0SWdVINZNohftVgET6VUct7mnQP2ChPmtOpR1TkglLVAnAAuBvoA/4v4Ici8tYYZTNINpIlus7AgPs2gedZEmAl1DJRrLOzhW3b2k1hp0zaWeNQ2RjHNSLyReDrQDNwmapeDVwMvCNe8Ywk63Lk8wW2bm2jq6slkeuth1yuh0JhlrExm611JaKEzl27apPQaT299HFhPrlKehyvAm5T1eeq6p+q6gkAVT0LvClW6YwwCTApV1Vtom+SwAZqKyOfLzAw0F2zhE6b7iV98vkCW7a00d2dnoFXydN0C/D9aEVE2kVkL4Cq3h+LVMbTeF4PY2MziVjWaU7TXC02UFsZQV5O7VyPkYtQVWt2TqM6an1P10IliuNvgeKMn4Vwm5EASVnWqpp6bHg1WAnZyqh1QqfndTMxMWcuwhRxodBaJYqjSVWfrl8aLrvvBK8TouzQuBvIsbEZxsdnU38gK2Xnzk6am2221pWII6HTpntJHxemBapEcYyKyDXRiohcC5yMTySjmKRCIF2I1KiGhgax2VpX4ejRKKGzlj0Oq/meJpHbOm3PQFMFx7wFuEtEbgcEGAR+J1apjKeJLOu4G8gsJf9FpDF7cJaIo2aDTfeSLoODbhRaW1VxqOq/AM8Xka5w3SaqSZDIso77RU27MMxa8Lwe7r/fT1sMZ4mMgVo2Mjt2dNDa2mg9vZRwxTNQSY8DEfl14EKgTUQAUNUPxCiXUUQSIbm+X6ClpZGdO90t4FSK53Vz9OgEc3MLNDc3pi2Oc0TPTC0TOpMyZIzyuOIZqCQB8OME81W9lcBV9WogF7NcRhFJZElH8f4NDRLrdWpJLreJxUVleNg6weXw/QLbtrXT2VnbWBabJyw9fL9Ac3PtEjrXSiWD4y9U1d8BTqvq+4EXAM+KVyyjmGLLOi6CHI7suKnAkgBXI5+PJ6HTkgDTw/fHnTDwKlEc0+H/syKyG5gjmK/KSIjIso6zDkKWssYjLMJnZeJKFPO8bkZGJpidjc+QMcrjQiguVKY4/j8R2Qz8KfBD4Ajw2UpOLiJXicjjInJYRN5VZn+riHw+3P9glJFetN8TkQkReWfJ9kYR+ZGIfKkSObJO9PLHZeXNzi5w9Gi68/uvhbh/lyyzlNBZ+3vqeT2owvCwKeykcSFrHFZRHGEBp/tV9Yyq/h3B2MZzVPV9q51YRBqBO4CrgX3Aa0VkX8lhbyJwgZ0P3AZ8uGT/rcCXy5z+bcCjq8lQL8RtWQ8Pj6Oa/oBbtbS3N9Pba7O1luPMmRkmJuZic1WBKeykcalC54qKQ1UXCRr/aH1GVSutKnQZcFhVnwizze8Gri055lrgznD5AHClhGFbIvJK4EngkeIPiEg/8OvAJyuUI/PE7cvPUh2OUpKcdj5LxBlebS7CdBgeHmdxsbYJnWulElfV/SLyqqhBr4I9BMmCEUPhtrLHqOo8MAZsC3NGbgbeX+a8HwX+mGfOn3UOYbGpQyJyaHR0tErR3SKyrOOy8FwoDLNWbKC2PHHG+0fhvaawk8WVHA6oTHH8B4JJDWdEpCAi4yIS9xNzC8FU7s8YDRaRVwAnVPUHq51AVT+hqvtVdX9vb29MYiZHnJZ1lgo4lRKFhtpsrc8kKjccRy+yra2JnTs7TGEnTPSeuuAZqCRzfK2tyTAwULTeH24rd8yQiDQBm4BTwOXAdSLyEWAzsCgi0wQ9lGtE5OVAG9AjIn8Tlreta3K5Hh577KlYzu374+zY0UF7e3Ms548Tz+tmcnKO06en2bq1PW1xnMH3x2ltbaS3tyOW81suR/JEitoFA29VxSEiV5TbrqrfXOWjDwEXiMh5BArieuB1JcfcA9wAfBe4DnhAA9PxxUXXvwWYUNXbw03vDre/BHjnRlAaELyo9957BFWleq/hymRpOvVSigdqTXEs4fvxJnR6XjePPHIqlnMb5fH9cbZvb6ejI30Dr5IpR/6oaLmNYND7B8BLV/qQqs6LyI3AvUAj8Feq+oiIfAA4pKr3AJ8CPiMih4GnCJSLUYY4LWvfL7Bv37aanjMpigdqL710Z8rSuENcyX8RuVwPBw8+GYshY5THpVyrSlxVv1G8LiIDBAPUq6KqB4GDJdveV7Q8TTCFyUrnuGWZ7V8nqIO+IVgqXDReU8Whqvh+gauvPq9m50wSyx4vj++P8+/+3d7Yzu95PUxNzXPq1BTbt8fjDjOeST5f4NnP3pq2GEBlg+OlDAG/VGtBjJWJq1TqqVNTnD0770Skxlro7e2gra3JBmqLmJ1dYGRkIlb3o4XkJktk4LniUq5kjONjQBSy0gBcQpBBbiRIXJb1UoifGw9ktYgInmeztRaTREJn8fP4vOeZizBu4kzoXAuVjHEcKlqeBz6nqt+OSR5jGSLLuvaKw50Qv7ViET7PJI46HKVY9niyuDKdekQliuMAMK2qC/D0PFEdqno2XtGMYpYs69o2kC4lFa0Vz+vm4MEn0xbDGZK4p9u2tdPeXntDxiiPa4XWKsocB4pHY9uBf4xHHGMl4qjLkc+P0d7exPbt2Q1lzeV6OHZskpmZ+bRFcYIkEjoDQ8Z6eknhmmegEsXRVpzBHS5bGEUKxFFjO6jD0ZPpkMrIsh4asoJOELg1du4MXJtxYtO9JEc+X4g1ofR+zFMAABhKSURBVLNaKlEckyLyvGhFRH4ZmIpPJGM5gjoItbWsXYrUWCtxRZxllcgYiBsLSkgO1wy8ShTHTcDfisg/ici3gM8DN8YrllGOOCxrVwrDrIelHBdrxCA5Y8Dzejh+/CzT0+YijBuXkv+gAsWhqg8BzwH+AHgL8EuVTDJo1J5aN5DT0/McP37WqQdyLfT3dwGmOGCpgFMS9zS6xuCgjXPEjWvTAq2qOETkD4FOVf2Zqv4M6BKR/xi/aEYpS0lXtWkgh4ayncMR0draxK5dneaqIkjonJpKJqHTsvaTYWZmnpGRSac8A5W4qn5fVc9EK6p6Gvj9+EQyliOyrGvVQLoWG74egsABs3yTDK+utSFjlGd4OHBNu+QZqERxNBYXcQpLwrbEJ5KxHK2tTfT1ddasgXQtxG892EBtQBLJfxH9/d2IWFBC3CzlcLjznlaiOL4CfF5ErhSRK4HPUb4OuJEAtSzo5PvjiMCePV01OV+aWEGngCQTxVpaGunr67KeXsy4WKGzEsVxM/AAwcD4W4Cf8syEQCNBPK+7pq6qXbs6aW2NN94/CXK5Hqan5xkd3dgTGvh+gfb2JrZtS+YVtZ5e/ESKub8/Q4pDVReBB4EjBLU4Xgo8Gq9YxnJEvvxaWNauhfitB5utNSCKqEoq3t+SAOPH9wMDL+6EzmpYVnGIyLNE5L+IyGPAxwAfQFV/tagan5EwnhdY1idPrj8HM6lEsSSIuvEbvRFL+p56Xg+Dg+MsLm5sF2GcuBaKCyv3OB4j6F28QlV/RVU/BiwkI5axHLXKkl5cdGt+//ViSYABSd9Tz+tmZmZhw7sI48RFA28lxfGbwAjwNRH5y3Bg3I189w1MrRrI0dGzzMws1I2rasuWNjo7mze0qyqNhM5cbhNgPb24iAo4ufaeLqs4VPV/qer1BFnjXyOYemSHiPyFiPzbpAQ0nslS0tX6GkgXQ/zWgxV0WsrgTtZVZUmAcXLyZHIJndVQyeD4pKp+Nqw93g/8iCDSykiByLJer4VXT8l/ERt9oDaNmg0WlBAvrtXhiKiq5riqnlbVT6jqlXEJZKxMrSzrrJeMLUctc1yySJLJfxGbN7fS3d2yoRV2nETvaWZcVYa71KIuh+8X6OpqZsuWthpJlT6e18Po6BRTU3Npi5IKvl8IEzqTMwbMRRgvrnoGTHFkkFpUAoymU3dlfv9aUKvxn6zi++P09XXR0tKY6HWtEmB8+H6Bjo4mtm51y8AzxZFBamFZByF+9eOmAgvJTSv6Jo7KlEZAdE9dM/BMcWSQWtRBCB7ITbUSyQk2+kBtWolintfDyZNTTE7OJn7tesfVQmumODLIerOkJydnOXlyqu56HHv2dNHQIOTzY2mLkjiLi8rgYDqJYtFzZAWdao+LyX9giiOTrNeyTiPePwmamxvZvXtjztaaZkLnkotw4/3ucTI1NceJE25W6DTFkUEiy3qtfmVXQ/xqwUaN8Ekz+qZW0+AYz2TJwHPPM2CKI4NElvVaX1QX5/evFbWIOMsiaSaK7d69PkPGKE+S1RyrxRRHRlmPZe37BRoahN27s1/AqZRcbmPO1ppmI9PU1MCePV2mOGqMyxU6TXFklPXU2Pb9Anv2dNHcnGy8fxJ4Xjdzc4scPz6ZtiiJks8X6O5uYfPm1lSuv9Gne4mDfL7gbIVOUxwZZT11EFyN1KgFG9XfHk2nnla8vyUB1h7fL7B7t5sGnimOjOJ53czOLqzJsnaxMEyt2KhJgGkbA57XzdDQOAsLi6nJUG/4/riTbiowxZFZ1hoCubCwyNCQuw/ketmoSYBRydi0yOV6mJtb5NixjeUijBNXk/8gZsUhIleJyOMiclhE3lVmf6uIfD7c/6CI7C3Z74nIhIi8M1xvE5Hvi8iPReQREXl/nPK7zFIDWZ1lffz4WebmFp19INfLpk2t9PRsrNlaJydnOXVqKuUex8ZU2HGxlNDppmcgNsUhIo3AHcDVwD7gtSKyr+SwNwGnVfV84DbgwyX7bwW+XLQ+A7xUVS8GLgGuEpHnxyG/66zVl1/PobgRG23uJBfi/a2gU205ceIss7PuVuiMs8dxGXBYVZ9Q1VngbuDakmOuBe4Mlw8AV0o4uicirwSeBB6JDtaAiXC1OfzbWHGXIZs2tbJpU2vVL6rLIX61YqMN1KZRh6OUjRqUEBeuV+iMU3HsAQaL1ofCbWWPUdV5YAzYJiJdBFUGz3FFiUijiDwMnADuU9UHy11cRN4sIodE5NDo6Oi6v4yLBLkc1TWQrj+QtcDzujdUA+ZColhPTyubN1dvyBjlcbUOR4Srg+O3ALcV9S6eRlUXVPUSgjK2l4nIReVOEFYq3K+q+3t7e+OVNiXWkiWdzxfCcYB04v2TIJfr4fTpacbHN8Zsrb5foLEx/YTOjdbTixNXS8ZGxKk4hoGBovX+cFvZY0SkCdgEnAIuBz4iIkeAm4D3iMiNxR9U1TPA14Cr4hA+C6zFl+9yiF+tiKy0wcGNYf3m80FCZ1NTunagJQHWDt8fp6enhc2b3SrgFBHnk/YQcIGInCciLcD1wD0lx9wD3BAuXwc8EI5jvFhV96rqXuCjwIdU9XYR6RWRzQAi0g78GvBYjN/BaTyvm6eemmZionLLOkoUq2c2mr89uKfpGwMbdYLJOHA5FBdiVBzhmMWNwL3Ao8AXVPUREfmAiFwTHvYpgjGNw8DbgXNCdkvoA74mIj8hUEz3qeqX4vkG7rOWkFzXH8hasNGm+U47+S/C83o4c2aGQmEmbVEyj+sGXlOcJ1fVg8DBkm3vK1qeBl69yjluKVr+CXBpbaXMLsUN5L5921c9vlCY4cyZmbp3VfX1ddLYuDFma11YWGRwcJzrr0//nhZn7V90UX2OKyaF74/z/Of3pS3Gsrg6OG5UQLU9jnot4FRKY2MD/f0bI7Lq2LFJ5ucXnbBOLQmwNriQ0LkapjgyTF9fJ01NDRU3kBsh+S9io0T4uBCKG2FJgLXBpXu6HKY4MkxgWVdeKnUjJP9FbJTscZfuaV9fF83NDRtCYceJS/d0OUxxZJzAsq6sgfT9cZqaGti1qzNmqdInmq11fr6+Z2uNepEDA+n3IhsaZMO4COMkC54BUxwZp5okwHy+QH9/F42N9X/bPa+HhQVlZOScHNK6wvcLbN7sTkKnheSuH98fp7FR6Otzr4BTRP23IHVOLtdTcR0E30936u0k2Sghua4ldG4UF2Gc+H6B/v7u1BM6V8JdyYyK8Lzu0LJevQ6CK4liSRB18+vdbeJaXo7n9TA8PFH3LsI4ce2elsMUR8apNEt6fn6R4eEJ5x/IWrHWeiVZw7VEschFePRofbsI48S1e1oOUxwZp9IQyKNHJ1hYUOcfyFrR1dXC1q1tda04XEzo3Kile2tFUKFzwql7Wg5THBmnUss6CyF+tabeczlcnCJ/o7gI42JkJErodOeelsMUR8aJLOvVXlTX5/ePg3qvy+FiolgUFlzPCjtOXJ9OPcIURx1QiWW91Mi4/UDWknqP8HGxF9nZ2cL27e11/bvHSfSeunRPy2GKow6opIH0/QLbtrXT2dmSkFTp43k9FAqzjI3V52yt+XyB5mb3EjrXUmDMCMjnxwAYGDDFYcRMJS6ZIMRv4/Q2oP797b4/Tn9/Nw0NkrYoz8CSANeO74+zZUsb3d1uG3imOOqASizrjZTDEZHLbQLqN8LH1bDNqMehqmmLkjmykqRriqMOWC0EUlXJ57PxQNaSep+t1dV7msv1MDExx5kz9ekijJOseAZMcdQBq4Xkjo3NMDExl4kHspbs3NlJS0tjXbqqXE7orHeFHSeuVHNcDVMcdcBqvvyNGIoLwWytAwPddRkaevToBIuL6uQ9tYJOa2NsbIaxMbcSOpfDFEcdEFnWy72oWQnxi4N6HaiNjAEX72kkUxQhZFTG4GA2cjjAFEddsGRZl28gXcwwTop6DQ11OVGst7eD1tblDRmjPFnyDJjiqBNWCsnN5wu0tDSyY0dHwlKlTy7Xw9GjE8zNLaQtSk2JGmUXCjiVspohY5THxZkAlsMUR50QJAEu56oKIjVci/dPAs/rQRWGh+trttZ8vsD27e4mdOZy9dnTixPfdzOhsxymOOoEz1vess5KpEYc1GsSoOt5OfU+wWQc5PMFBgayYeCZ4qgTPK+HxUUta1lnJTY8Duq1LoeryX8RntfNyMgEs7P15SKMkywZeKY46oTlkgBnZxcYGXF/fv+4WMopqB/rNwsJnblc5CKsn989brKSNQ6mOOqG5RrI4eFxVLMx4BYH7e3N9Pa215Wr6syZKKHT3XtaaWVKI2BubiFM6HS3F1mMKY46IYquKX1RsxTiFxeBv71+GjCXQ3EjLAmwOlxO6CyHKY46ob29mR07Os5pIDdy8l9EvdXlyMI9XSroVD+/e5xk4Z4WY4qjjiiXJR2t9/d3pSGSE9TbbK1RRrbL1mlbWxM7d3aYq6pCsuYZMMVRR5TLks7nC+zY0UF7e3NKUqWP53Vz9uw8Tz01nbYoNcH3x2ltbaS31+2ETgvJrZzIwHMxobMcpjjqiCgJsNiy9v3xzHR/42K1aeezRpTD4Xq8f725COPE98fp7W2noyMbBp4pjjrC83qYnJzj9Okly9r1eP8kqLcIn6zk5UTT4NSLizBO8vmxzLipwBRHXVGaJR3F+2fpgYyDesvlyEqimOf1MDU1z6lTU2mL4jxZuacRpjjqiCWXTNBAnjo1xdTU/IZ3VfX2dtDW1lQXbpMsJXSWPo9GeVQ1U8l/ELPiEJGrRORxETksIu8qs79VRD4f7n9QRPaW7PdEZEJE3hmuD4jI10Tk5yLyiIi8LU75s0bp9BpZmm0zTkRkxdmDs8TQUJTQmQVXVX25COPi9OnpzFXojE1xiEgjcAdwNbAPeK2I7Cs57E3AaVU9H7gN+HDJ/luBLxetzwPvUNV9wPOBPyxzzg3L9u3ttLc3Pf2iLoX4ZeeBjIt6SQLMUm0VKyFbGVk08OLscVwGHFbVJ1R1FrgbuLbkmGuBO8PlA8CVIiIAIvJK4EngkehgVR1R1R+Gy+PAo8CeGL9Dpggs656iHoe7VeKSZqVp57NElhLFtm1rp6OjPlyEcZLF9zROxbEHGCxaH+LcRv7pY1R1HhgDtolIF3Az8P7lTh66tS4FHlxm/5tF5JCIHBodHV3jV8geQRJg0Lj4foH29ia2bWtPWar08bxujh2bZHp6Pm1R1kXUi+zvd78XGRky5qpamSx6BlwdHL8FuE1Vy1bfCRXL3wE3qWrZp1JVP6Gq+1V1f29vb3ySOkbxixpFVIWduA1N5AYYGsp2r8P3C+zcGQz2ZwFLAlwd3y/Q1tbkfEJnMXEqjmFgoGi9P9xW9hgRaQI2AaeAy4GPiMgR4CbgPSJyY3hcM4HSuEtV/z5G+TNJLtfDsWOTzMzMW/JfEfUS4ZO1e2pJgKsThOJ2Z8rAi1NxPARcICLniUgLcD1wT8kx9wA3hMvXAQ9owItVda+q7gU+CnxIVW8Pxz8+BTyqqrfGKHtmibq7Q0MTlvxXRL0UdMpaXo7ndXP8+NnMuwjjJGv3FGJUHOGYxY3AvQSD2F9Q1UdE5AMick142KcIxjQOA28HzgnZLeFFwBuAl4rIw+Hfy2P6CpkkegAff/wpjh8/m7kHMi6iSR6z7G+P4v2zZAxEz9/gYLZ7enGStXsKEKujVFUPAgdLtr2vaHkaePUq57ilaPlbQHb6cykQvajf/vZwuJ6tBzIuWlub6OvrzHSPI0rozJIxUBySe8EFW1KWxj1mZuYZGZnMlPsR3B0cN9ZIf38XIvCtbwWKI2sPZJxkfaA2S6G4EfU2wWStGR4O4n+yZAyAKY66o7W1iV27OnnwwREgew9knGQ9ezxrNRsA9uzpRiTbLsI4yeI9BVMcdYnn9TAzs4BINuL9kyJKjszqbK1ZKBlbSktLI319XZnu6cVJFu8pmOKoSyL3QF9fFy0tjSlL4w65XKBQR0fPpi3KmvD9Ah0d2UvotJDc5YkUalYKOEWY4qhDIusla1ZM3GR90r2sJnRm3UUYJ/l8gV27OmltzUZCZ4QpjjokaiCz5jeNm6zX5chazYYIz+thcHCcxcVsugjjJIuhuGCKoy6JXFVZir5JgqxH+GStZkNE1l2EcZK1mQAistU/MipiqceRPUsmTrZsaaOzs5k/+ZMH+eQnf5q2OFUTJHRm755Gz+OLXvQ5WlttzK2YX/ziNK94xb9KW4yqMcVRh1x00XZuvvkyfvM3n5W2KE4hInzwgy/iO985mrYoa+Lii3t59aufnbYYVXPFFf288Y0XMjExl7YozvHc527n9a/PXkkhyWpoYjXs379fDx06lLYYhmEYmUFEfqCq+8vtszEOwzAMoypMcRiGYRhVYYrDMAzDqApTHIZhGEZVmOIwDMMwqsIUh2EYhlEVpjgMwzCMqjDFYRiGYVTFhkgAFJFRIL/Gj28HTtZQnCTJquxZlRtM9rQw2WtPTlV7y+3YEIpjPYjIoeWyJ10nq7JnVW4w2dPCZE8Wc1UZhmEYVWGKwzAMw6gKUxyr84m0BVgHWZU9q3KDyZ4WJnuC2BiHYRiGURXW4zAMwzCqwhSHYRiGURWmOJZBRK4SkcdF5LCIvCtteSpFRAZE5Gsi8nMReURE3pa2TNUiIo0i8iMR+VLaslSDiGwWkQMi8piIPCoiL0hbpkoRkf8UPi8/E5HPiUhb2jIth4j8lYicEJGfFW3bKiL3icgvwv9b0pSxHMvI/afh8/ITEfmiiGxOU8ZKMcVRBhFpBO4Argb2Aa8VkazUd5wH3qGq+4DnA3+YIdkj3gY8mrYQa+DPgK+o6nOAi8nIdxCRPcD/DexX1YuARuD6dKVakU8DV5Vsexdwv6peANwfrrvGpzlX7vuAi1T1XwP/DLw7aaHWgimO8lwGHFbVJ1R1FrgbuDZlmSpCVUdU9Yfh8jhB47UnXakqR0T6gV8HPpm2LNUgIpuAK4BPAajqrKqeSVeqqmgC2kWkCegAnC3MrqrfBJ4q2XwtcGe4fCfwykSFqoBycqvqV1V1Plz9HtCfuGBrwBRHefYAg0XrQ2So8Y0Qkb3ApcCD6UpSFR8F/hhYTFuQKjkPGAX+OnSzfVJEOtMWqhJUdRj4b4APjABjqvrVdKWqmp2qOhIuHwN2pinMGvld4MtpC1EJpjjqFBHpAv4OuElVC2nLUwki8grghKr+IG1Z1kAT8DzgL1T1UmASN90l5xCOB1xLoPx2A50i8vp0pVo7GuQYZCrPQET+M4Gb+a60ZakEUxzlGQYGitb7w22ZQESaCZTGXar692nLUwUvAq4RkSME7sGXisjfpCtSxQwBQ6oa9e4OECiSLPAy4ElVHVXVOeDvgRemLFO1HBeRPoDw/4mU5akYEXkj8ArgtzUjiXWmOMrzEHCBiJwnIi0EA4X3pCxTRYiIEPjZH1XVW9OWpxpU9d2q2q+qewl+8wdUNROWr6oeAwZF5NnhpiuBn6coUjX4wPNFpCN8fq4kIwP7RdwD3BAu3wD87xRlqRgRuYrANXuNqp5NW55KMcVRhnCw6kbgXoIX6Auq+ki6UlXMi4A3EFjrD4d/L09bqA3CW4G7ROQnwCXAh1KWpyLCXtIB4IfATwnaBWenwRCRzwHfBZ4tIkMi8ibgvwK/JiK/IOhB/dc0ZSzHMnLfDnQD94Xv6sdTFbJCbMoRwzAMoyqsx2EYhmFUhSkOwzAMoypMcRiGYRhVYYrDMAzDqApTHIZhGEZVmOIwjBogIgtF4c8P13JGZRHZWzyjqmGkTVPaAhhGnTClqpekLYRhJIH1OAwjRkTkiIh8RER+KiLfF5Hzw+17ReSBsA7D/SLihdt3hnUZfhz+RVN/NIrIX4Y1M74qIu2pfSljw2OKwzBqQ3uJq+o1RfvGVPW5BFnCHw23fQy4M6zDcBfw5+H2Pwe+oaoXE8x1Fc1YcAFwh6peCJwBXhXz9zGMZbHMccOoASIyoapdZbYfAV6qqk+Ek08eU9VtInIS6FPVuXD7iKpuF5FRoF9VZ4rOsRe4LyxShIjcDDSr6v8T/zczjHOxHodhxI8us1wNM0XLC9j4pJEipjgMI35eU/T/u+Hyd1gqz/rbwD+Fy/cDfwBP117flJSQhlEpZrUYRm1oF5GHi9a/oqpRSO6WcMbcGeC14ba3ElQL/COCyoH/Ptz+NuAT4cypCwRKZATDcAgb4zCMGAnHOPar6sm0ZTGMWmGuKsMwDKMqrMdhGIZhVIX1OAzDMIyqMMVhGIZhVIUpDsMwDKMqTHEYhmEYVWGKwzAMw6iK/x+KyjG9RvtlpAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}